[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Visualizing Information and Spatial Analysis with ggplot2 Extensions",
    "section": "",
    "text": "Welcome to V.I.S.A.G.E., a resource for extending ggplot2 and the tidyverse to create stunning visualizations, perform geo-computation, and analyze complex data. Built using R and RStudio, this site demonstrates how packages like sf, various ggplot2 extensions, and other tools in the tidyverse enhance data manipulation and visualization. Explore dynamic graphs, interactive maps, and reproducible workflows built with Quarto to see how modern tools can turn data into insights."
  },
  {
    "objectID": "geocomputation.html",
    "href": "geocomputation.html",
    "title": "Geocomputation",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nSubtitle\n\n\n\n\n\n\nDec 14, 2024\n\n\nVarious CRS projections for use with {sf} plots in {ggplot2}\n\n\nA ready reckoner for different projections that we can plot the World, Continents and Countries with using {ggplot2} in R.\n\n\n\n\nDec 10, 2024\n\n\nUsing {geodata} to get elevation raster maps\n\n\nExploring Global and Country-Specific Elevation Maps with {geodata}: high-resolution raster elevation data using functions like elevation_30s() and elevation_global(). Simplify geospatial analysis and visualization.\n\n\n\n\nNov 20, 2024\n\n\nUsing the power of {sf} to plot stores / outlets along a calculated route using sf::st_is_within_distance()\n\n\nHarnessing the power of {osmr} for route directions, store locations from www.alltheplaces.xyz, and raster base maps from {ggmaps}\n\n\n\n\nOct 26, 2024\n\n\nDriving Directions using Open Street Maps Routing Service\n\n\nUsing {tidygeocoder}, {osrm}, {sf}, {tidyverse} and {ggmap} along with Open Source Techniques to plot driving directions along various cities in Europe in the norther-Mediterranean region\n\n\n\n\nOct 25, 2024\n\n\n3 types of Cartograms in R with {sf} and {cartogram}\n\n\nCreating Cartograms – contiguous, non-contiguous and packed-circles – in R with {cartogram}, and making non-overlapping text annotations in maps, and custom callouts in Quarto.\n\n\n\n\nOct 20, 2024\n\n\nComputing shortest routes in the sea that avoid land\n\n\nUsing data from Killer Whales encounters in Salish Sea to plot routes of their recorded encounters, and showing those routes that dont intersect land - i.e., removing erroneous data.\n\n\n\n\nOct 16, 2024\n\n\nCreating Maps in R with ggplot2 having background Raster Images using ggmap\n\n\nLearning how to create maps in R using the {ggmap} package, integrating custom raster base maps with {ggplot2} for geospatial data visualization. This page covers the setup, API authentication, and plotting functions to map data effectively.\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "Welcome to my little corner of the internet! I’m Dr. Aditya Dahiya, your friendly neighborhood data enthusiast. With an MBBS from AIIMS, New Delhi and a Master of Public Health from Harvard University, I’ve always had a penchant for diving deep into the intricacies of data—and what better way to do that than with ggplot2, its myriad extensions and other open-source packages.\nWhen I’m not navigating the labyrinth of Haryana’s bureaucracy (don’t worry, I have a map!), I channel my experiences as a Fulbright Fellow into making data visualization a captivating storytelling tool. Think of me as your data-wrangling, file-taming, bureaucracy-battling guide with a slightly skewed sense of humor. Need more bureaucratic banter or data insights? Connect with me on LinkedIn or shoot me an email — I promise it won’t be as formal as a government memo!"
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About Me",
    "section": "Education",
    "text": "Education\nHarvard University | Boston, MA | MPH in Global Health | Aug 2021 - May 2022\nAll India Institute of Medical Sciences | New Delhi, India | M.B.B.S. | Aug 2005-Dec 2010"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "About Me",
    "section": "Experience",
    "text": "Experience\nIndian Administrative Service | Director | Aug 2011 - present\nNeuro-Radiology, AIIMS New Delhi | Junior Resident Doctor | Jan 2011 - Aug 2011"
  },
  {
    "objectID": "geocomputation/ggmap_rasters.html",
    "href": "geocomputation/ggmap_rasters.html",
    "title": "Creating Maps in R with ggplot2 having background Raster Images using ggmap",
    "section": "",
    "text": "On this page, we’ll explore how to create visually appealing maps in R using the ggmap package (ggmap?), a popular extension of ggplot2 designed for easy integration of raster map tiles from online mapping services. Let us see how to set up the required tools and generate maps with custom base layers, using both ggmap and functions like get_stadiamap().\nggmap is an extension of the ggplot2 package that enables users to overlay data on geographic maps. It retrieves raster map tiles from sources such as Google Maps, Stamen Maps, and Stadia Maps, making it easier to create maps and integrate geospatial data visualization with familiar ggplot2 workflows.\nCode\nlibrary(tidyverse)\nlibrary(ggmap)\nlibrary(sf)\n\nsysfonts::font_add_google(\"Saira Condensed\", \"caption_font\")\nsysfonts::font_add_google(\"Saira\", \"body_font\")\nshowtext::showtext_auto()\nAbout the Sample Dataset: The lnd dataset, part of the spData package (Bivand, Nowosad, and Lovelace 2024) in R, contains polygons representing the large administrative boroughs of London. This dataset includes attributes such as the borough name (NAME), official code (GSS_CODE), land area in hectares (HECTARES), and geometry data in the sfc_MULTIPOLYGON format. You can explore the dataset’s source here.\nCode\n# Data on The boroughs of London\ng &lt;- spData::lnd |&gt; \n  ggplot(\n    aes(\n      fill = NAME,\n      label = NAME,\n      size = HECTARES\n    )\n  ) +\n  geom_sf(\n    alpha = 0.75\n  ) +\n  geom_sf_text(\n    check_overlap = TRUE,\n    family = \"caption_font\"\n  ) +\n  scale_size_continuous(\n    range = c(8, 15)\n  ) +\n  coord_sf() +\n  labs(x = NULL, y = NULL) +\n  theme_grey(\n    base_size = 20\n  ) +\n  theme(\n    legend.position = \"none\",\n    axis.ticks.length = unit(0, \"mm\")\n  )\n\nggsave(\n  plot = g,\n  filename = here::here(\"geocomputation\",\n                        \"images\",\n                        \"ggmap_rasters_1.png\")\n)"
  },
  {
    "objectID": "geocomputation/ggmap_rasters.html#getting-started-with-ggmap",
    "href": "geocomputation/ggmap_rasters.html#getting-started-with-ggmap",
    "title": "Creating Maps in R with ggplot2 having background Raster Images using ggmap",
    "section": "Getting Started with ggmap",
    "text": "Getting Started with ggmap\nBefore creating maps, you’ll need to install the ggmap package, which is available through CRAN.\ninstall.packages(\"ggmap\")\nTo ensure that you can access map tiles from Stadia Maps, you will need an API key. This key allows you to authenticate and use their map services within your R scripts.\nSetting Up API Key Authentication: To access Stadia Maps, follow these steps:\n\nSign up for a free Stadia Maps account and generate an API key.\nSave the API key securely in your environment using the register_stadiamaps() function.\n\nregister_stadiamaps(\"YOUR-API-KEY-HERE\", write = TRUE)\nBy saving the key in your .Renviron file, you ensure it will automatically load in new R sessions, avoiding the need to hard code it into your script."
  },
  {
    "objectID": "geocomputation/ggmap_rasters.html#retrieving-a-base-map-with-get_stadiamap",
    "href": "geocomputation/ggmap_rasters.html#retrieving-a-base-map-with-get_stadiamap",
    "title": "Creating Maps in R with ggplot2 having background Raster Images using ggmap",
    "section": "Retrieving a Base-map with get_stadiamap()",
    "text": "Retrieving a Base-map with get_stadiamap()\nOnce your API key is set, you can start generating maps using functions such as get_stadiamap() etc. This function allows you to fetch base maps by specifying the bounding box coordinates of your area of interest. The function will return a ggmap object that you can further customize using ggplot2 syntax."
  },
  {
    "objectID": "geocomputation/ggmap_rasters.html#exploring-various-ggmap-functions",
    "href": "geocomputation/ggmap_rasters.html#exploring-various-ggmap-functions",
    "title": "Creating Maps in R with ggplot2 having background Raster Images using ggmap",
    "section": "Exploring various ggmap Functions",
    "text": "Exploring various ggmap Functions\n\nBase functions: get_stadiamap() & ggmap()\nFetches map tiles from Stadia Maps and Stamen Design, after choosing the design from Map Style Library, for a specified bounding box or region and zoom level, and displays them using ggmap(). The various map styles available under the get_stadiamap(maptype = \"your-map-type-here\") argument are: —\n\n\n\n\n\n\n\nMap Type\nDescription\n\n\n\n\nstamen_terrain\nA detailed terrain map highlighting elevation and natural features like hills and rivers.\n\n\nstamen_toner\nA bold, high-contrast map design with stark black-and-white features, ideal for print or urban areas.\n\n\nstamen_toner_lite\nA lighter version of the toner map, providing clearer backgrounds with less emphasis on contrast.\n\n\nstamen_watercolor\nA unique, artistic map style that looks like a watercolor painting, perfect for creative visualizations.\n\n\nstamen_terrain_background\nA terrain map focusing only on the background without labels, useful for overlaying custom data.\n\n\nstamen_toner_background\nA simplified toner map background without labels, ideal for adding data layers on top.\n\n\nstamen_terrain_lines\nTerrain map with added contour lines to emphasize elevation changes.\n\n\nstamen_terrain_labels\nTerrain map that includes place labels, enhancing context for geographic features.\n\n\nstamen_toner_lines\nToner map with a focus on roads and paths, outlined clearly against the background.\n\n\nstamen_toner_labels\nA toner map style with added labels for places, roads, and other key features.\n\n\n\nNote: It is very important is to add the inherit.aes = FALSE argument in geom_sf() if overlaying sf objects on the the {ggmap} raster tiles.\nThe R code below demonstrates how to overlay spatial geometries from sf objects onto raster base maps using ggmap and geom_sf(). The get_stadiamap() function from Stadia Maps is used to fetch raster tiles (specifically with the stamen_toner_lines style) for the London area, which are then transformed into EPSG:3857 (Web Mercator) using a custom function ggmap_bbox() (credits: andyteuchner on stackoverflow post) to ensure the map tiles align correctly with the CRS of the spatial data. The London Boroughs dataset (spData::lnd) is similarly projected to EPSG:3857, and the boroughs are visualized with semi-transparent polygons and labeled with their names using geom_sf() and geom_sf_text(). This approach ensures the raster background and vector geometries are properly aligned.\n\n\nCode\n# Obtain the bounding box of London Boroughs\nlondon_bbox &lt;- sf::st_bbox(spData::lnd)\n\n# A bounding box in the format c(lowerleftlon, lowerleftlat, upperrightlon, upperrightlat)\nlondon_bbox &lt;- c(\n  left = london_bbox$xmin,\n  right = london_bbox$xmax,\n  bottom = london_bbox$ymin,\n  top = london_bbox$ymax\n)\nnames(london_bbox) &lt;- c(\"left\", \"right\", \"bottom\", \"top\")\n\n\n# Getting the map tiles\nlondon_base1 &lt;- get_stadiamap(\n  bbox = london_bbox,\n  zoom = 10,\n  maptype = \"stamen_toner_lines\"\n)\n\nst_crs(london_base1)\n# As we can see the raster images have no CRS system\n# Empirically we know that the coordinate refence system is 3857\n\n# Getting London Boroughs Data\ndf &lt;- spData::lnd |&gt;\n  st_transform(crs = st_crs(3857))\n\n\n# Starting the process of Overlaying the geom_sf() data on this\n# Most important is to add the inherit.aes = FALSE argument.\n\n# Step: 1: \n# Credits: https://stackoverflow.com/questions/47749078/how-to-put-a-geom-sf-produced-map-on-top-of-a-ggmap-produced-raster by andyteucher on StackOverFlow (https://stackoverflow.com/users/1736291/andyteucher)\n\n# Define a function to fix the bbox to be in CRS EPSG:3857\nggmap_bbox &lt;- function(map) {\n  # Extract the bounding box (in lat/lon) from the ggmap\n  # to a numeric vector, and set the names to what\n  # sf::st_bbox expects:\n  map_bbox &lt;- setNames(\n    unlist(attr(map, \"bb\")),\n    c(\"ymin\", \"xmin\", \"ymax\", \"xmax\")\n  )\n\n  # Coonvert the bbox to an sf polygon, transform it to 3857,\n  # and convert back to a bbox (convoluted, but it works)\n  bbox_3857 &lt;- st_bbox(\n    st_transform(\n      st_as_sfc(\n        st_bbox(map_bbox, crs = 4326)\n        ), \n      3857\n    )\n  )\n\n  # Overwrite the bbox of the ggmap object with the transformed coordinates\n  attr(map, \"bb\")$ll.lat &lt;- bbox_3857[\"ymin\"]\n  attr(map, \"bb\")$ll.lon &lt;- bbox_3857[\"xmin\"]\n  attr(map, \"bb\")$ur.lat &lt;- bbox_3857[\"ymax\"]\n  attr(map, \"bb\")$ur.lon &lt;- bbox_3857[\"xmax\"]\n  map\n}\n\n# Use the function to convert our downloaded Raster Files into \n# the new CRS and new bounding box CRS\nlondon_base2 &lt;- ggmap_bbox(london_base1)\n\n# Plotting the actual map\n\n# Starting with base map tiles\ng &lt;- ggmap(london_base2) +\n  \n  # Plotting the actual sf object data on london boroughs\n  geom_sf(\n    data = df,\n    aes(fill = NAME),\n    inherit.aes = FALSE,\n    alpha = 0.5,\n    colour = alpha(\"white\", 0.5)\n  ) +\n  \n  # Plotting names of London Boroughs on top of the geom_sf\n  geom_sf_text(\n    data = df,\n    aes(label = NAME),\n    inherit.aes = FALSE,\n    family = \"caption_font\",\n    fontface = \"bold\",\n    check_overlap = TRUE\n  ) +\n  \n  # Forcing the ggplot2 map to be in CRS: 3857\n  coord_sf(\n    crs = st_crs(3857)\n  ) +\n  \n  # Some theme elements\n  ggthemes::theme_map() +\n  theme(\n    legend.position = \"none\"\n  )\n\nggsave(\n  filename = here::here(\"geocomputation\", \n                        \"ggmap_rasters\", \n                        \"fig_2.png\"),\n  plot = g\n)\n\n\n\n\n\n\n\n\nFigure 2: Overlapping a geom_sf() object over and above ggmap raster tiles obtained from Stadia Maps\n\n\n\n\n\n\nqmplot(): Similar to qplot(), but automatically adds a background map. It simplifies mapping by automatically computing the bounding box.\n\n\nWork-in-Progress: Other ggmap() functions\n\nmake_bbox(): Computes a bounding box for a dataset based on latitude and longitude columns.\ngeom_hdr() and geom_labeldensity2d(): Useful for plotting density and contour maps on top of ggmap layers, commonly used for visualizing spatial data like crime maps.\nget_googlemap(): Retrieves maps from Google Maps by specifying a location and zoom level. Different map types are supported (e.g., satellite, terrain, hybrid).\ngeocode() and revgeocode(): Provides geocoding and reverse geocoding services using Google Maps API to convert addresses to coordinates and vice versa.\nmutate_geocode(): Works like mutate() in dplyr, adding latitude and longitude columns to a data frame based on an address.\ntrek() and route(): Calculates routes between locations using Google’s routing API, which can be plotted as paths on a map using geom_path().\nmapdist(): Computes distances and travel times between multiple locations. It’s vectorized for multiple origin-destination pairs.\nregister_google(): Registers a Google Maps API key for use with the ggmap package, allowing access to various Google Maps services. The key can be saved for future sessions."
  },
  {
    "objectID": "geocomputation/computing_sea_routes.html",
    "href": "geocomputation/computing_sea_routes.html",
    "title": "Computing shortest routes in the sea that avoid land",
    "section": "",
    "text": "Dataset used: This #TidyTuesday dataset comes from the Center for Whale Research (CWR), which monitors Southern Resident killer whales in the Salish Sea, part of the Pacific Northwest. The dataset, scraped by Jadey Ryan and documented here, contains information on encounters from 2017 to 2024. Each encounter involves photographing and identifying individual whales. The data can be accessed via the {orcas} R package and includes variables like encounter duration, location, and pod. While the dataset is mostly tidy, some inconsistencies such as missing values and negative durations remain. | Source | Data.\nHere’s my #TidyTuesday Visualization for this project in Figure 1, and the code used and the visualization webpage.\n\n\n\n\n\n\nFigure 1: This map visualizes the movements of Southern Resident killer whales, with arrows marking the starting and ending points of each recorded encounter. The concentration of arrows within a small area highlights the key regions in the Salish Sea where these encounters occur most frequently. Background map images provided by StadiaMaps.\n\n\n\n\n\nMethod 1: Using {geosphere} and {sf}\n\nStep 1: Loading libraries, getting the data and cleaning it\n\n\nCode\n# Loading the Libraries\nlibrary(tidyverse)       # Data wrangling\nlibrary(sf)              # SF objects\nlibrary(showtext)        # Using google fonts in R\nlibrary(geosphere)       # Spherical trigonometry for geography\n\n# Set fonts for including in all graphics\nfont_add_google(\"Saira Semi Condensed\", \"body_font\")\nfont_add_google(\"Saira Extra Condensed\",\"caption_font\")\nshowtext_auto()\n\n# Load orcas data\norcas &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2024/2024-10-15/orcas.csv')\n\nsessioninfo::session_info()$packages |&gt; \n  as_tibble() |&gt; \n  dplyr::select(package, \n         version = loadedversion, \n         date, source) |&gt;\n  filter(package %in% .packages()) |&gt; \n  arrange(package) |&gt; \n  janitor::clean_names(\n    case = \"title\"\n  ) |&gt; \n  gt::gt() |&gt; \n  gt::opt_interactive(\n    use_search = TRUE\n  ) |&gt; \n  gtExtras::gt_theme_espn()\n\n\n\n\nTable 1: List of packages used during this analysis and their versions\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStep 2: Clean the data, make it in {sf} format\n\n\nCode\n# A cleaner tibble to use for our visualization\ndf_sf &lt;- orcas |&gt; \n  as_tibble() |&gt;\n  dplyr::select(year, duration, \n         begin_latitude, begin_longitude,\n         end_latitude, end_longitude) |&gt; \n\n  # Convert the duration of encounter into seconds\n  mutate(\n    # remove parenthesis content from duration\n    duration = str_remove(duration, \"\\\\s*\\\\(.*\\\\)\"),\n    \n    # remove the \"s\" for seconds\n    duration = str_extract(duration, \"-?\\\\d+\"),\n    \n    # convert the duration into number\n    duration = as.numeric(duration)\n  ) |&gt; \n  \n  # Remove aberrant observation with durations less than zero\n  filter(duration &gt;= 0) |&gt; \n  \n  # Remove observations with missingness\n  drop_na() |&gt; \n  \n  # Allot an ID number to each finally selected observation\n  mutate(id = row_number()) |&gt; \n  dplyr::relocate(id, .before = everything())\n\n########################################################\n# Get a bounding box on the coordinates of encounters\nbbox_orcas &lt;- bind_rows(\n  \n  # Geometry column of starting coordiantes\n    sf::st_as_sf(\n      df_sf |&gt; dplyr::select(begin_latitude, begin_longitude),\n      coords = c(\"begin_longitude\",\"begin_latitude\"),\n      crs = 'EPSG:4326'\n    ) |&gt;\n    mutate(type = \"start_coords\"),\n    \n\n  # Geometry column of starting coordiantes\n    sf::st_as_sf(\n      df_sf |&gt; dplyr::select(end_latitude, end_longitude),\n      coords = c(\"end_longitude\",\"end_latitude\"),\n      crs = 'EPSG:4326'\n    ) |&gt;\n    mutate(type = \"end_coords\")\n) |&gt; \n  st_bbox()\n\n######################################################\n# Display cleaned data\n\ndf_sf |&gt; \n  gt::gt() |&gt; \n  gt::opt_interactive() |&gt; \n  gtExtras::gt_theme_espn() |&gt; \n  gt::fmt_number(\n    columns = -c(year, id),\n    decimals = 2\n  ) |&gt; \n  gt::tab_header(\n    title = \"Cleaned Data on starting and ending coordinates\",\n    subtitle = \"Recorded Encounters of Orcas (Southern Killer Whales) in the Salish Sea (2017-2024)\"\n  )\n\n\n\n\nTable 2: A table of clean data that shows id, year, duration and starting and ending coordinates of each Killer Whale encounter as an {sf} class column\n\n\n\n\n\n\nCleaned Data on starting and ending coordinates\nRecorded Encounters of Orcas (Southern Killer Whales) in the Salish Sea (2017-2024)\n\n\n\n\n\n\n\n\n\n\n\nStep 3: Computing routes using geosphere::gcIntermediate()\n\n\nCode\n# Technique Credits: https://github.com/xmc811/flightplot/blob/master/R/main.R\n# Credits: Mingchu Xu\n# https://www.linkedin.com/in/mingchu-xu-467a0946/\n# On Twitter: @xmc811\n\nroutes &lt;- geosphere::gcIntermediate(\n  p1 = df_sf |&gt; dplyr::select(begin_longitude, begin_latitude),\n  p2 = df_sf |&gt; dplyr::select(end_longitude, end_latitude),\n  n = 100,\n  addStartEnd = TRUE,\n  sp = TRUE) |&gt; \n  sf::st_as_sf()\n\n# Check whether it works\nggplot() +\n  geom_sf(data = routes)\n\n\n\n\n\n\n\n\nFigure 2: The routes computed by the {geosphere} package’s gcIntermediate() function\n\n\n\n\n\n\n\nStep 4: Getting background maps for the Salish Sea area: USA and Canada\nFor this, we first convert our sf object on Map of USA and Canada, shown in Figure 3 (a) into a SpatVector. In the {terra} package in R, a SpatVector is the main class used to represent and work with vector data in geographic information system (GIS) contexts. A SpatVector can store points, lines, polygons, or any combination of these geometries, along with associated attributes (data linked to these geometries). We can create a SpatVector from:\n\nShapefiles (widely used for vector data in GIS)\nOther vector file formats like GeoJSON, KML, or GPKG.\nR objects such as data frames or matrices that contain coordinate information.\n\nThe reason to create a SpatVector is for performing spatial operations like buffering, intersecting, or spatial joins.The terra::vect() is the method to create these objects from various file formats or other R objects.\nThen, we use the terra::crop() to crop USA and Canada map to a specified geographic extent Figure 3 (b) defined by bounding box of the sf objects of orcas created in previous step. When applied to a SpatVector object (vector data), terra::crop() trims the geometries (points, lines, or polygons) so that only the portions within a specified spatial extent remain. Lastly, we re-convert the cropped SpatVector back into an sf object, shown in ?@fig-basemap1-3\n\n\nCode\n# Extract country borders data\nbase_map &lt;- rgeoboundaries::gb_adm0(country = c(\"USA\", \"Canada\")) %&gt;% \n  rmapshaper::ms_simplify(0.5)\n\n# checking the size\n# object.size(base_map) |&gt; print(units = \"Mb\")\n# 4.3 Mb\n\nggplot(base_map) +\n  geom_sf() +\n  coord_sf(\n    crs = usmap::usmap_crs()\n  )\n\nsea &lt;- terra::crop(terra::vect(base_map), bbox_orcas)\n\n# Finally, reconvert the Cropped area back into an sf object\nsea_sf &lt;- sea |&gt; \n  st_as_sf()\n\nggplot(sea_sf) +\n  geom_sf()\n\n\n\n\n\n\n\n\n\n\n\n(a) Map of entire USA and Canada from {rgeoboundaries}\n\n\n\n\n\n\n\n\n\n\n\n(b) Using the terra::crop() from {terra} to focus on Salish Sea area. The Salish Sea area plotted as an sf object\n\n\n\n\n\n\nFigure 3: Background Map of the Salish Sea Area in 2 steps: (4.1) Getting map of USA and Canada from {rgeoboundaries}, and (4.2) Cropping out the map of Salish Sea area\n\n\n\n\n\n\nStep 5: Computing and Removing routes intersecting with land (i.e., erroneous data)\n\n\nCode\n# Test if path is only sea. Each logical test if for each ID in the \n# df1 tibble\ntest_intersect &lt;- lengths(\n  st_intersects(\n    st_transform(routes, st_crs(base_map)), base_map\n  )\n) &gt; 0\n\n# Compute distance for each \ndist_encounter &lt;- st_length(routes)\n\n# Create a second tibble of distance & paths for each encounter\ndf_routes &lt;- routes |&gt; \n  st_transform(st_crs(base_map)) |&gt; \n  bind_cols(id = df_sf$id) |&gt; \n  bind_cols(whether_intersect_land = test_intersect) |&gt; \n  bind_cols(dist_encounter = as.numeric(dist_encounter)) |&gt; \n  left_join(df_sf |&gt; dplyr::select(year, id, duration)) |&gt; \n  mutate(speed = dist_encounter / duration)\n  \n# A vector of IDs whose paths dont intersect land\nids_to_plot &lt;- df_routes |&gt; \n  filter(whether_intersect_land == FALSE) |&gt; \n  pull(id)\n\ndf_routes |&gt; \n  dplyr::relocate(geometry, .after = everything()) |&gt; \n  gt::gt() |&gt; \n  # gt::cols_hide(geometry) |&gt; \n  gt::fmt_number(\n    columns = c(dist_encounter, speed),\n    decimals = 1\n  ) |&gt; \n  gt::fmt(\n    columns = geometry,\n    fns = function(x) {str_sub(x, 1, 20)}\n  ) |&gt; \n  gt::opt_interactive() |&gt; \n  gtExtras::gt_theme_espn()\n\n\n\n\nTable 3: A table of intersecting and non-intersecting routes\n\n\n\n\n\n\n\n\n\n\n\n\n\nStep 6: Plotting the non-intersecting routes in Figure 4\n\n\nCode\n# ggmap::register_stadiamaps(\"YOUR-KEY-HERE\")\n\nbbox_stadiamap &lt;- c(left = bbox_orcas[\"xmin\"],\n  right = bbox_orcas[\"xmax\"],\n  top = bbox_orcas[\"ymax\"],\n  bottom = bbox_orcas[\"ymin\"])\nnames(bbox_stadiamap) &lt;- c(\"left\", \"right\", \"top\", \"bottom\")\n\n# Getting the Stamen Maps for the background tiles as raster\nstamen_tiles_lowres &lt;- ggmap::get_stadiamap(\n   bbox_stadiamap,\n   zoom = 8,\n   maptype = \"stamen_terrain\"\n)\n\n# Step: 1: \n# Credits: https://stackoverflow.com/questions/47749078/how-to-put-a-geom-sf-produced-map-on-top-of-a-ggmap-produced-raster by andyteucher on StackOverFlow (https://stackoverflow.com/users/1736291/andyteucher)\n\n# Define a function to fix the bbox to be in CRS EPSG:3857\nggmap_bbox &lt;- function(map) {\n  # Extract the bounding box (in lat/lon) from the ggmap\n  # to a numeric vector, and set the names to what\n  # sf::st_bbox expects:\n  map_bbox &lt;- setNames(\n    unlist(attr(map, \"bb\")),\n    c(\"ymin\", \"xmin\", \"ymax\", \"xmax\")\n  )\n\n  # Coonvert the bbox to an sf polygon, transform it to 3857,\n  # and convert back to a bbox (convoluted, but it works)\n  bbox_3857 &lt;- st_bbox(\n    st_transform(\n      st_as_sfc(\n        st_bbox(map_bbox, crs = 4326)\n        ), \n      3857\n    )\n  )\n\n  # Overwrite the bbox of the ggmap object with the transformed coordinates\n  attr(map, \"bb\")$ll.lat &lt;- bbox_3857[\"ymin\"]\n  attr(map, \"bb\")$ll.lon &lt;- bbox_3857[\"xmin\"]\n  attr(map, \"bb\")$ur.lat &lt;- bbox_3857[\"ymax\"]\n  attr(map, \"bb\")$ur.lon &lt;- bbox_3857[\"xmax\"]\n  map\n}\n\n# Use the function to convert our downloaded Raster Files into \n# the new CRS and new bounding box CRS\nstamen_tiles_lowres2 &lt;- ggmap_bbox(stamen_tiles_lowres)\n\ng &lt;- ggmap::ggmap(stamen_tiles_lowres2) +\n  geom_sf(\n    data = df_routes |&gt; \n            filter(!whether_intersect_land) |&gt; \n            st_transform(crs = 3857),\n    mapping = aes(\n      geometry = geometry\n    ),\n    color = \"grey10\",\n    alpha = 0.5,\n    inherit.aes = FALSE,\n    arrow = arrow(\n      angle = 20,\n      length = unit(0.5, \"mm\")\n    ),\n    linewidth = 0.2\n  ) +\n  coord_sf(\n    expand = F\n  ) +\n  labs(\n    x = \"Longitude\", y = \"Latitude\"\n  ) +\n  theme_minimal()\n\nggsave(\n  plot = g,\n  filename = here::here(\"geocomputation\", \"images\", \"computing_sea_routes_1.png\"),\n  width = 900,\n  height = 700,\n  units = \"px\",\n  bg = \"white\"\n)\n\n\n\n\n\n\n\n\nFigure 4: This map visualizes the movements of Southern Resident killer whales, with arrows marking the starting and ending points of each recorded encounter. The concentration of arrows within a small area highlights the key regions in the Salish Sea where these encounters occur most frequently. Background map images provided by StadiaMaps.\n\n\n\n\n\n\n\nMethod 2: Using raster and gdistance package\nThe following code for computing sea routes is inspired from Code by Benjamin Nowak hosted on GitHub as a part of #TidyTuesday visualizations.\n\nStep 1: Getting the data and cleaning it\nThe packages used in this analysis are shown in the Table 4\n\n\nCode\n# Loading the Libraries\nlibrary(tidyverse)       # Data wrangling\nlibrary(rgeoboundaries)  # Getting country & admin boundaries.\nlibrary(rmapshaper)      # For multi-polygon simplification\nlibrary(sf)              # SF objects\nlibrary(terra)           # Spatial data analysis\nlibrary(tidyterra)       # Tidyverse methods for terra objects\nlibrary(gdistance)       # Distances and Routes on Geographical Grids\nlibrary(showtext)        # Using google fonts in R\n\n# Set fonts for including in all graphics\nfont_add_google(\"Saira Semi Condensed\", \"body_font\")\nfont_add_google(\"Saira Extra Condensed\",\"caption_font\")\nshowtext_auto()\n\n# Load orcas data\norcas &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2024/2024-10-15/orcas.csv')\n\nsessioninfo::session_info()$packages |&gt; \n  as_tibble() |&gt; \n  dplyr::select(package, \n         version = loadedversion, \n         date, source) |&gt; \n  filter(package %in% .packages()) |&gt; \n  arrange(package) |&gt; \n  janitor::clean_names(\n    case = \"title\"\n  ) |&gt; \n  gt::gt() |&gt; \n  gt::opt_interactive(\n    use_search = TRUE\n  ) |&gt; \n  gtExtras::gt_theme_espn()\n\n\n\n\nTable 4: List of packages used during this analysis and their versions\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStep 2: Clean the data\n\n\nCode\n# A cleaner tibble to use for our visualization\ndf1 &lt;- orcas |&gt; \n  as_tibble() |&gt;\n  dplyr::select(year, duration, \n         begin_latitude, begin_longitude,\n         end_latitude, end_longitude) |&gt; \n\n  # Convert the duration of encounter into seconds\n  mutate(\n    # remove parenthesis content from duration\n    duration = str_remove(duration, \"\\\\s*\\\\(.*\\\\)\"),\n    \n    # remove the \"s\" for seconds\n    duration = str_extract(duration, \"-?\\\\d+\"),\n    \n    # convert the duration into number\n    duration = as.numeric(duration)\n  ) |&gt; \n  \n  # Remove aberrant observation with durations less than zero\n  filter(duration &gt;= 0) |&gt; \n  \n  # Remove observations with missingness\n  drop_na() |&gt; \n  \n  # Allot an ID number to each finally selected observation\n  mutate(id = row_number()) |&gt; \n  dplyr::relocate(id, .before = everything())\n\ndf1 |&gt; \n  gt::gt() |&gt; \n  gt::opt_interactive() |&gt; \n  gtExtras::gt_theme_espn() |&gt; \n  gt::fmt_number(\n    columns = -c(year, id),\n    decimals = 2\n  )\n\n\n\n\nTable 5: A table of clean data that shows id, year, duration and starting and ending coordinates of each Killer Whale encounter\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStep 3: Creating data is specific formats needed by {sf} {terra}\n\n\nCode\n# The starting Coordinates as an sf object\nstart_coordinates &lt;- df1 |&gt; \n  dplyr::select(id, begin_latitude, begin_longitude) |&gt; \n  sf::st_as_sf(\n    coords = c(\"begin_longitude\",\"begin_latitude\"),\n    crs = 'EPSG:4326'\n  ) |&gt; \n  mutate(type = \"start\")\n\n# The ending Coordinates as an sf object  \nend_coordinates &lt;- df1 |&gt; \n  dplyr::select(id, end_latitude, end_longitude) |&gt; \n  sf::st_as_sf(\n    coords = c(\"end_longitude\",\"end_latitude\"),\n    crs = 'EPSG:4326'\n  ) |&gt; \n  mutate(type = \"end\")\n\n# Compiling starting and ending coordinates into a tibble\norcas_sf &lt;- start_coordinates |&gt; \n  bind_rows(end_coordinates)\n\n# Extracting the bounding box of that tibble to get our map\nbb_orcas &lt;- st_bbox(orcas_sf)\n\norcas_sf |&gt; \n  print(n = 10)\n\n\nSimple feature collection with 1168 features and 2 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -125.6233 ymin: 47.85333 xmax: -122.0445 ymax: 49.55733\nGeodetic CRS:  WGS 84\n# A tibble: 1,168 × 3\n      id             geometry type \n * &lt;int&gt;          &lt;POINT [°]&gt; &lt;chr&gt;\n 1     1  (-124.6925 48.5105) start\n 2     2  (-123.1578 48.4765) start\n 3     3    (-123.2 48.57167) start\n 4     4 (-123.3367 49.09267) start\n 5     5 (-123.0368 48.79683) start\n 6     6 (-122.9295 48.43633) start\n 7     7 (-123.8992 48.84733) start\n 8     8  (-123.592 48.02783) start\n 9     9    (-123.4358 48.87) start\n10    10 (-123.3302 48.80333) start\n# ℹ 1,158 more rows\n\n\n\n\nStep 4: Getting background maps for the Salish Sea area: USA and Canada\nFor description of the actions performed, please see Step 4 of the Method 1 above.\n\n\nCode\n# Extract country borders data\nbase_map &lt;- rgeoboundaries::gb_adm0(country = c(\"USA\", \"Canada\")) %&gt;% \n  rmapshaper::ms_simplify(0.5)\n\n# checking the size\n# object.size(base_map) |&gt; print(units = \"Mb\")\n# 4.3 Mb\n\nggplot(base_map) +\n  geom_sf() +\n  coord_sf(\n    crs = usmap::usmap_crs()\n  )\n\nsea &lt;- terra::crop(terra::vect(base_map), bb_orcas)\n\nggplot(sea) +\n  geom_sf()\n\n# Finally, reconvert the Cropped area back into an sf object\nsea_sf &lt;- sea |&gt; \n  st_as_sf()\n\nggplot(sea_sf) +\n  geom_sf()\n\n\n\n\n\n\n\n\n\n\n\n(a) Map of entire USA and Canada from {rgeoboundaries}\n\n\n\n\n\n\n\n\n\n\n\n(b) Using the terra::crop() from {terra} to focus on Salish Sea area\n\n\n\n\n\n\n\n\n\n\n\n(c) The same Salish Sea area plotted as an sf object\n\n\n\n\n\n\nFigure 5: Background Map of the Salish Sea Area in 2 steps: (4.1) Getting map of USA and Canada from {rgeoboundaries}, and (4.2) Cropping out the map of Salish Sea area\n\n\n\n\n\n\nStep 5: Converting into rasters to plot compute distances and intersections\nterra::rast() function is used to create a raster object or load an existing raster dataset (e.g., GeoTIFF, ASCII, or other raster formats). A raster is a grid of cells (pixels) where each cell has a value representing information such as elevation, temperature, land cover, etc. We use it here to Create an empty raster, defining the number of rows, columns, extent, and coordinate reference system (CRS) to create a raster template.\nterra::rasterize() function is then used to convert vector data (points, lines, polygons) into raster format. This process assigns values from vector geometries to raster cells, typically based on whether the geometries overlap with the cells or using attributes from the vector data. For example, here we are Rasterizing polygons: i.e., for each land types: USA, Canada or other, we can rasterize it so that each raster cell represents one of these three.\n\n\nCode\n# Convert vector to raster and set highly diffferent pixel values based on whether an area is sea or land (i.e. not sea)\n\n# Step 5.1: Generate an empty raster defining the resolution by\n#           number of rows and columns, and a CRS from sea_sf\nr &lt;- terra::rast(sea_sf, ncols = 500, nrows = 500)\n\nggplot() +\n  geom_spatraster(data = r)\n\nrr &lt;- terra::rasterize(sea_sf, r, \"shapeISO\") %&gt;%\n  mutate(shapeISO = case_when(\n    shapeISO %in% c('CAN', 'USA') ~ 1,  # assign value 1 to land\n    TRUE ~ 1000                         # assign value 1000 to sea\n  ))\n\nggplot() +\n  geom_spatraster(data = rr)\n\n\n\n\n\n\n\n\nFigure 6: The empty raster of 500 X 500 created using terra::rast()\n\n\n\n\n\n\n\n\n\n\n\nFigure 7: The raster is enhanced by adding the polygons data from the salish sea area map we cropped in the last step.\n\n\n\n\n\n\n\nStep 6: Computing the distance between starting and ending coordinates\n\nThe gdistance::transition() function is used to create a transition matrix from raster data. The Transition Matrix is a sparse matrix where each element represents the movement “cost” or “resistance” from one cell to its neighboring cells. The transition matrix enables the calculation of the most efficient path (e.g., the least-cost path) from one location to another. Thus, it is used for calculating least-cost paths, commute distances, and other kinds of spatial movement analyses.\nThe transition matrix helps in Movement Modeling: It is used to model movement across a landscape, such as wildlife migration, water flow, or human navigation, where each raster cell’s value might represent an obstacle or ease of travel. Note that we had assigned different value to land and sea raster points.\nAfter creating a transition layer using gdistance::transition(), the gdistance::geoCorrection() function is used to apply geographic corrections to account for the varying distances between raster cells due to the curvature of the Earth or grid layout. This step is crucial when working with spatial data in a geographic coordinate system (e.g., latitude and longitude) where distances between cells are not uniform.\nThe gdistance::shortestPath() is then used to compute the shortest (or least-cost) path between two points on a raster grid, based on a transition matrix that describes the “cost” or “resistance” of moving from one cell to another. The function calculates this path by minimizing the total cost or resistance, taking into account the values in the transition matrix, which typically represent the difficulty or ease of moving through each cell.\n\n\n\nCode\n# For quick rendering of this .qmd file, I have not evaluated \n# this chunk of code, and rather saved the results of \"distance\"\n# as an .rds file and reloaded it.\n\n# Compute transition matrix from raster pixels\nr_trans &lt;- gdistance::transition(\n  x = raster(rr), \n  transitionFunction = mean, \n  directions = 16\n)\n# object.size(r_trans) |&gt; print(units = \"Mb\")\n# 24.7 Mb\n\nr_trans &lt;- geoCorrection(r_trans)\n# object.size(r_trans) |&gt; print(units = \"Mb\")\n# 24.7 Mb\n\n# Compute the shortest path between start and end for the \n# first line of the transition matrix, and convert into sf object:\n\ndistance &lt;- gdistance::shortestPath(\n  r_trans, \n  c(df1 |&gt; filter(id == 1) |&gt; pull(begin_longitude),\n    df1 |&gt; filter(id == 1) |&gt; pull(begin_latitude)), \n  c(df1 |&gt; filter(id == 1) |&gt; pull(end_longitude),\n    df1 |&gt; filter(id == 1) |&gt; pull(end_latitude)), \n  output = \"SpatialLines\"\n) |&gt; \n  st_as_sf()\n\n# Repeat the process for the other points / IDs\nfor (i in 2:nrow(df1)) {\n  \n  temp &lt;- gdistance::shortestPath(\n  r_trans, \n  c(df1 |&gt; filter(id == i) |&gt; pull(begin_longitude),\n    df1 |&gt; filter(id == i) |&gt; pull(begin_latitude)), \n  c(df1 |&gt; filter(id == i) |&gt; pull(end_longitude),\n    df1 |&gt; filter(id == i) |&gt; pull(end_latitude)), \n  output = \"SpatialLines\"\n) |&gt; \n  st_as_sf()\n  \n  distance &lt;- distance |&gt; \n    bind_rows(temp)\n\n}\n\n# Add a CRS to the newly created sf object \ndistance &lt;- distance |&gt; \n  st_set_crs(st_crs(base_map))\n\nsaveRDS(distance, file = here::here(\"data\", \"orcas_distance.rds\"))\n\n\n\n\nCode\ndistance &lt;- readRDS(here::here(\"data\", \"orcas_distance.rds\"))\n\n# Displaying the shortest paths\nggplot() +\n  \n  geom_sf(\n    data = sea_sf, \n    alpha = 0.75, \n    fill = \"#725428\") +\n\n  geom_sf(\n    data = distance\n  ) +\n  coord_sf(expand = FALSE) +\n  \n  theme(\n    panel.background = element_rect(fill = \"#b6e3db\")\n  )\n\n\n\n\n\n\n\n\nFigure 8: The shortest paths computed using {gdistance} show us that many of them are passing over land - these seem to be errors in the data\n\n\n\n\n\n\n\nStep 7: Check whether paths intersect land, and retain only non-intersecting routes\nThe sf::st_intersects() function is used to determine whether two spatial geometries intersect. It checks if any part of one geometry touches or overlaps with another.\nThe sf::st_length() function is then used to calculate the length of geometries represented in sf (simple features) objects. It returns the length of each geometry in the specified unit of measurement.\n\n\nCode\n# Test if path is only sea. Each logical test if for each ID in the \n# df1 tibble\ntest_intersect &lt;- lengths(st_intersects(distance, base_map)) &gt; 0\n\n# Compute distance for each \ndist_encounter &lt;- st_length(distance)\n\n# Create a second tibble of distance & paths for each encounter\ndf2 &lt;- distance |&gt; \n  bind_cols(id = start_coordinates$id) |&gt; \n  bind_cols(whether_intersect_land = test_intersect) |&gt; \n  bind_cols(dist_encounter = as.numeric(dist_encounter)) |&gt; \n  left_join(df1 |&gt; dplyr::select(year, id, duration)) |&gt; \n  mutate(speed = dist_encounter / duration)\n  \n# A vector of IDs whose paths dont intersect land\nids_to_plot &lt;- df2 |&gt; \n  filter(whether_intersect_land == FALSE) |&gt; \n  pull(id)\n\ndf2 |&gt; \n  dplyr::relocate(geometry, .after = everything()) |&gt; \n  slice_head(n = 10) |&gt; \n  mutate(geometry = as.character(geometry)) |&gt; \n  gt::gt() |&gt; \n  # gt::cols_hide(geometry) |&gt; \n  gt::fmt_number(\n    columns = c(dist_encounter, speed),\n    decimals = 2\n  ) |&gt; \n  gt::fmt(\n    columns = geometry,\n    fns = function(x) {str_sub(x, 1, 50)}\n  )\n\n\n\n\n\n\n\n\nid\nwhether_intersect_land\ndist_encounter\nyear\nduration\nspeed\ngeometry\n\n\n\n\n1\nFALSE\n12,981.52\n2024\n5580\n2.33\nc(-124.689260978699, -124.703576316833, -124.71789\n\n\n2\nFALSE\n757.91\n2024\n2460\n0.31\nc(-123.157519798279, -123.157519798279, -123.15751\n\n\n3\nFALSE\n1,845.91\n2024\n9900\n0.19\nc(-123.200465812683, -123.193308143616, -123.18615\n\n\n4\nFALSE\n11,256.39\n2024\n5460\n2.06\nc(-123.336461524963, -123.336461524963, -123.33646\n\n\n5\nFALSE\n6,932.37\n2024\n2460\n2.82\nc(-123.035839424133, -123.035839424133, -123.03583\n\n\n6\nFALSE\n11,305.02\n2024\n6300\n1.79\nc(-122.928474388123, -122.921316719055, -122.91415\n\n\n7\nTRUE\n7,742.05\n2024\n6360\n1.22\nc(-123.901917381287, -123.901917381287, -123.90191\n\n\n8\nTRUE\n130,922.24\n2024\n2340\n55.95\nc(-123.594137611389, -123.594137611389, -123.59413\n\n\n9\nFALSE\n7,738.62\n2024\n3900\n1.98\nc(-123.436668891907, -123.443826560974, -123.45098\n\n\n10\nFALSE\n2,816.18\n2024\n840\n3.35\nc(-123.329303855896, -123.329303855896, -123.32930\n\n\n\n\n\n\n\n\n\nStep 8: Plotting the final routes with ggplot2\n\n\nCode\nland &lt;- \"#725428\"\nsea &lt;- \"#b6e3db\"\norc &lt;- \"grey10\"\n\nggplot() +\n  geom_sf(\n    data = sea_sf,\n    mapping = aes(geometry = geometry),\n    fill = land, color = NA,\n    alpha = 0.9\n  ) +\n  geom_sf(\n    df2 |&gt; filter(!whether_intersect_land),\n    mapping = aes(\n      alpha = speed,\n      geometry = geometry\n    ),\n    color = orc\n  ) + \n  coord_sf(\n    expand = F\n  ) +\n  scale_alpha(range = c(0.5, 0.9)) +\n  guides(alpha = \"none\") +\n  theme_minimal() +\n  theme(\n    panel.background = element_rect(fill = sea, color = NA)\n  )\n\n\n\n\n\n\n\n\nFigure 9: The final map with routes shown that don’t intersect land. The alpha (transparency) of each route is mapped to speed."
  },
  {
    "objectID": "geocomputation/osm_driving_directions.html",
    "href": "geocomputation/osm_driving_directions.html",
    "title": "Driving Directions using Open Street Maps Routing Service",
    "section": "",
    "text": "This code provides a detailed methodology for creating a visually informative route map for a driving trip along the northern Mediterranean, integrating data visualization, spatial data handling, and Open Street Maps (OSM) routing services in R. Utilizing several packages, including {sf} (Pebesma and Bivand 2023) for spatial data and {tidygeocoder} (Cambon et al. 2021) for geocoding, the code transforms a dataset of locations into spatial coordinates. By accessing OSRM (Open Source Routing Machine) through the {osrm} (Giraud 2022)package, the code calculates and visualizes optimized driving routes between selected cities. Distances and travel durations are formatted using custom functions, enhancing the map’s usability and clarity.\nThe geospatial data is presented using {ggplot2} (Wickham 2016) with additional styling from {ggrepel} (Slowikowski 2024) for labels and {patchwork} (Pedersen 2024) to arrange plots. Base map layers are sourced from {rnaturalearth} (Massicotte and South 2023) and a refined background layer is added using {ggmap} with Stadia map tiles, adjusted to EPSG:3857 using custom bounding box functions. This layering enables effective visualization of routes on custom raster maps. The code’s structure allows for modifications, such as changing cities or map styling, demonstrating the adaptability of R’s spatial data packages in route mapping and driving directions creation.\nInspired from this tutorial (Heiss 2023) titled “How to make fancy road trip maps with R and OpenStreetMap”."
  },
  {
    "objectID": "geocomputation/cartogram_types.html",
    "href": "geocomputation/cartogram_types.html",
    "title": "3 types of Cartograms in R with {sf} and {cartogram}",
    "section": "",
    "text": "Introduction\nOn this webpage, we’ll explore how to create cartograms in R, using population data from the CIA World Factbook. Cartograms are a unique type of thematic map that reshape geographic regions to represent data variables rather than their actual geographic area. By resizing areas to reflect variables like population, cartograms reveal spatial patterns and disparities in a more visually striking way, making them a powerful tool for storytelling with data.\nUnlike traditional maps, where region size is based solely on geographical area, cartograms alter these sizes to communicate insights about underlying data trends. This approach offers several advantages: it enhances visualization by making patterns more apparent, communicates complex data to a broad audience effectively, and highlights disparities between regions, drawing attention to areas of interest. Additionally, cartograms facilitate comparative analysis by allowing viewers to easily compare regions resized according to a single variable.\nTo create cartograms in R, we’ll use a combination of packages, including {cartogram} (Jeworutzki 2023)for cartogram-specific functions, {sf} (Pebesma and Bivand 2023) for handling spatial data, {ggplot2} (Wickham 2016) for flexible mapping and plotting, and {tidyverse} (Wickham et al. 2019) for streamlined data manipulation. The {cartogram} package provides various cartogram types, including\n\nDorling cartograms (Figure 5) that represent regions as resized circles,\nContiguous area cartograms (Figure 3) that maintain topological relationships between regions, and\nNon-contiguous area cartograms (Figure 4) that allow flexibility in resizing by ignoring boundaries.\n\n\nAbout the Data\nThe dataset used in this tutorial is sourced from the CIA World Factbook, specifically the Country Comparisons from 2014. This resource provides essential statistics on population, area, and other key indicators for 265 global entities. Through the {openintro} and {usdatasets} R packages, we access population metrics that allow us to create cartograms—maps where countries’ sizes are distorted according to population values rather than geographic area. This dataset, which required no additional cleaning, enables the visualization of demographic distributions, highlighting countries’ population density and size in an intuitive way for mapping exercises in R.\n\n\n\n\n\n\nKey Learnings\n\n\n\n\nCreating Cartograms with {cartogram}, such as contiguous, non-contiguous, and Dorling cartograms to visually communicate data through shape transformations.\nCustom Callouts in Quarto with the Custom Callout Extension, which enhances document structure and readability, such as the present call-out.\nRepelling Overlapping Text Labels with {ggrepel} with geom_sf() and geom_sf_text() for improved clarity on maps.\n\n\n\n\n\nStep 1: Getting libraries and raw data\nIn this step, we are setting up our workspace to create a population-based cartogram using data from the CIA World Factbook. We begin by loading essential libraries, including {tidyverse} for data manipulation and visualization, {sf} for handling spatial data, and {cartogram} for creating cartograms. We load the cia_factbook dataset and use the {countrycode} package to add ISO3 country codes for mapping. The world_map object is created using the {rnaturalearth} package, which provides geographic data in sf format. Additionally, we set up custom fonts using {showtext} and define color palettes for filling and labeling countries, enhancing the map’s readability and aesthetic.\n\n\nCode\n# Load essential libraries\nlibrary(tidyverse)         # For data wrangling and visualization\nlibrary(sf)                # For handling spatial objects in R\nlibrary(ggrepel)           # For repelling overlapping labels in plots\nlibrary(cartogram)         # For creating different types of cartograms\nlibrary(showtext)          # For using custom Google Fonts in plots\n\n# Load and prepare the CIA Factbook data\ncia_data &lt;- openintro::cia_factbook |&gt; \n  mutate(\n    # Convert country names to ISO3 codes for easy matching with \n    # Geographical Maps data\n    iso_a3 = countrycode::countrycode(country, \"country.name\", \"iso3c\") \n  )\n\n# Retrieve the world map data\nworld_map &lt;- rnaturalearth::ne_countries(\n  scale = \"small\",      # Use small scale for manageable detail\n  returnclass = \"sf\"    # Return as an 'sf' object for spatial handling\n  )\n\n# Add a custom Google font for captions\nfont_add_google(\"Saira Extra Condensed\", \"caption_font\")\nshowtext_auto()           # Automatically apply custom fonts\n\n# Display the size of the world_map object in KB\n# object.size(world_map) |&gt; print(units = \"Kb\")\n\n# Define colors for country fill and text\n# Fill color palette for countries\nfill_palette &lt;- paletteer::paletteer_d(\"khroma::stratigraphy\")\n\n# Define a darker color palette for text labels\ncolour_palette &lt;- fill_palette |&gt; \n  str_sub(start = 1, end = 7) |&gt;  # Truncate hex codes to 6 characters\n  colorspace::darken(0.5)         # Darken colors by 50% for better contrast\n\n\n\n\nStep 2: Converting the data into a “tidy” tibble.\nIn this code snippet, we refine the world_map data and visualize it in the Mercator projection using the ggplot2 package. We start by selecting relevant columns, grouping by country name, and keeping the entry with the highest population estimate for countries with multiple entries. After joining this map data with the cia_data dataset, we filter out any countries without population data and apply the Pseudo-Mercator projection (CRS 3857) using {sf}’s st_transform() function. Finally, we use ggplot2 to plot the world map with geom_sf() and set a minimal theme and informative title and caption.\n\n\n\nTable 1\n\n\n\nCode\n# Filter, join, and transform world map data for plotting\n\nworld_map &lt;- world_map |&gt; \n  select(name, geometry, pop_est, iso_a3) |&gt;      # Select relevant columns\n  group_by(name) |&gt;                               # Group by country name\n  slice_max(order_by = pop_est, n = 1) |&gt;         # Retain country entry with max population estimate\n  left_join(cia_data) |&gt;                          # Join with CIA Factbook data\n  filter(!is.na(population)) |&gt;                   # Filter out entries without population data\n  st_transform(crs = 3857) |&gt;                     # Transform to Psuedo-Mercator projection (CRS = 3857)\n  ungroup()\n\n\n\n\n\n\n\n\nTable 2: The sf object morld map to be used in the susequent analysis\n\n\n\n\n\n\n\n\n\nName\nPop Est\nIso a 3\nCountry\nArea\nBirth Rate\nDeath Rate\nInfant Mortality Rate\nInternet Users\nLife Exp at Birth\nMaternal Mortality Rate\nNet Migration Rate\nPopulation\nPopulation Growth Rate\n\n\n\n\nAfghanistan\n38,041,754\nAFG\nAfghanistan\n652,230\n38.8\n14.1\n117.2\n1,000,000.0\n50.5\n460.0\n−1.8\n31,822,848\n2.3\n\n\nAlbania\n2,854,191\nALB\nAlbania\n28,748\n12.7\n6.5\n13.2\n1,300,000.0\n78.0\n27.0\n−3.3\n3,020,209\n0.3\n\n\nAlgeria\n43,053,054\nDZA\nAlgeria\n2,381,741\n24.0\n4.3\n21.8\nNA\n76.4\n97.0\n−0.9\n38,813,722\n1.9\n\n\nAngola\n31,825,295\nAGO\nAngola\n1,246,700\n39.0\n11.7\n80.0\nNA\n55.3\n450.0\n0.5\n19,088,106\n2.8\n\n\nArgentina\n44,938,712\nARG\nArgentina\n2,780,400\n16.9\n7.3\n10.0\n13,694,000.0\n77.5\n77.0\n0.0\n43,024,374\n0.9\n\n\nArmenia\n2,957,731\nARM\nArmenia\n29,743\n13.9\n9.3\n14.0\n208,200.0\n74.1\n30.0\n−5.9\n3,060,631\n−0.1\n\n\nAustralia\n25,364,307\nAUS\nAustralia\n7,741,220\n12.2\n7.1\n4.4\n15,810,000.0\n82.1\n7.0\n5.7\n22,507,617\n1.1\n\n\nAustria\n8,877,067\nAUT\nAustria\n83,871\n8.8\n10.4\n4.2\n6,143,000.0\n80.2\n4.0\n1.8\n8,223,062\n0.0\n\n\nAzerbaijan\n10,023,318\nAZE\nAzerbaijan\n86,600\n17.0\n7.1\n26.7\n2,420,000.0\n71.9\n43.0\n0.0\n9,686,210\n1.0\n\n\nBahamas\n389,482\nBHS\nBahamas, The\n13,880\n15.6\n7.0\n12.5\n115,800.0\n71.9\n47.0\n0.0\n321,834\n0.9\n\n\nBangladesh\n163,046,161\nBGD\nBangladesh\n143,998\n21.6\n5.6\n45.7\n617,300.0\n70.7\n240.0\n0.0\n166,280,712\n1.6\n\n\nBelarus\n9,466,856\nBLR\nBelarus\n207,600\n10.9\n13.5\n3.6\n2,643,000.0\n72.2\n4.0\n0.8\n9,608,058\n−0.2\n\n\nBelgium\n11,484,055\nBEL\nBelgium\n30,528\n10.0\n10.8\n4.2\n8,113,000.0\n79.9\n8.0\n1.2\n10,449,361\n0.0\n\n\nBelize\n390,353\nBLZ\nBelize\n22,966\n25.1\n6.0\n20.3\n36,000.0\n68.5\n53.0\n0.0\n340,844\n1.9\n\n\nBenin\n11,801,151\nBEN\nBenin\n112,622\n36.5\n8.4\n57.1\nNA\n61.1\n350.0\n0.0\n10,160,556\n2.8\n\n\nBhutan\n763,092\nBTN\nBhutan\n38,394\n18.1\n6.8\n37.9\n50,000.0\n69.0\n180.0\n0.0\n733,643\n1.1\n\n\nBolivia\n11,513,100\nBOL\nBolivia\n1,098,581\n23.3\n6.6\n38.6\n1,103,000.0\n68.5\n190.0\n−0.7\n10,631,486\n1.6\n\n\nBosnia and Herz.\n3,301,000\nBIH\nBosnia and Herzegovina\n51,197\n8.9\n9.6\n5.8\n1,422,000.0\n76.3\n8.0\n−0.4\n3,871,643\n−0.1\n\n\nBotswana\n2,303,697\nBWA\nBotswana\n581,730\n21.3\n13.3\n9.4\n120,000.0\n54.1\n160.0\n4.6\n2,155,784\n1.3\n\n\nBrazil\n211,049,527\nBRA\nBrazil\n8,514,877\n14.7\n6.5\n19.2\n75,982,000.0\n73.3\n56.0\n−0.1\n202,656,788\n0.8\n\n\n\n\n\n\n\n\n\n\n\n\nKey Learning: Using geom_text_repel() in place of geom_text_sf() with stat = \"sf_coordinates\"\nIn this code, we generate two versions of a world map using the Mercator projection (CRS = 3857). The first plot demonstrates how using geom_sf_text() without any adjustment can lead to overlapping labels, particularly in densely populated areas. The second plot corrects this with geom_text_repel() from the {ggrepel} package (Slowikowski 2024), which dynamically adjusts label positions to prevent overlap and improve readability. Each map includes labels based on country name, and the label sizes vary by population, offering a clear contrast between the two approaches for displaying map text labels.\n\n\nCode\n# Plot the transformed world map data with overlapping labels\ng &lt;- ggplot(world_map) +\n  \n  # Draws the base map with country shapes\n  geom_sf(\n    linewidth = 0.1\n  ) +    \n  \n  # Adds country names as labels, without overlap prevention\n  geom_sf_text(\n    mapping = aes(\n      label = country\n    )\n  ) +\n  \n  # Applies a minimal theme for a clean visual layout\n  theme_minimal() +           \n  \n  # Sets title, subtitle, and caption for the plot\n  labs(\n    title = \"World Map: Labels Overlapping when using geom_sf_text()\",\n    subtitle = \"Map in the Mercator Projection (CRS = 3857)\",\n    caption = \"Source: {rnaturalearth} package data retrieved with ne_countries() function\"\n  ) +\n  \n  theme(\n    panel.grid = element_line(\n      linewidth = 0.1\n    )\n  )\n\nggsave(\n  filename = here::here(\"geocomputation\",\n                        \"images\",\n                        \"cartogram_types_1.png\"),\n  plot = g,\n  height = 600,\n  width = 800,\n  units = \"px\"\n)\n\n# Plot the transformed world map data with repelled labels\ng &lt;- ggplot(world_map) +\n  \n  # Draws the base map with country shapes\n  geom_sf(\n    linewidth = 0.1,       # Sets line width for label positioning\n    colour = \"grey10\"\n  ) +    \n  \n  # Adds country names as labels with repel effect to prevent overlap\n  geom_text_repel(\n    mapping = aes(\n      label = country,\n      geometry = geometry,\n      size = population\n    ),\n    stat = \"sf_coordinates\",   # Sets the stat for spatial coordinates\n    family = \"caption_font\",   # Sets the font family for labels\n    force_pull = 100,\n    force = 0.01,\n    linewidth = 0.01\n  ) +\n  \n  # Scales the size of labels based on population\n  scale_size_continuous(\n    range = c(5, 25)\n  ) +\n  \n  # Applies a minimal theme for a clean visual layout\n  theme_minimal(\n    base_size = 80\n  ) +    \n    \n  # Sets title, subtitle, and caption for the plot\n  labs(\n    title = \"World Map: Labels with geom_text_repel() with stat = \\\"sf_coordinates\\\"\",\n    caption = \"Source: {rnaturalearth} package data retrieved with ne_countries() function\",\n    x = NULL, y = NULL\n  ) +\n  \n  # Removes the legend for size\n  theme(\n    legend.position = \"none\",\n    panel.grid = element_line(\n      linewidth = 0.01\n    )\n  )\n\nggsave(\n  filename = here::here(\"geocomputation\",\n                        \"images\",\n                        \"cartogram_types_2.png\"),\n  plot = g,\n  height = 3700,\n  width = 4900,\n  units = \"px\",\n  bg = \"white\"\n)\n\n\n\n\n\n\n\n\nFigure 1: Basic World Map: With no effort to prevent overlapping of labels\n\n\n\n\n\n\n\n\n\nFigure 2: Labels Repelled from each other to prevent overlapping, using geom_text_repel() from package {ggrepel}\n\n\n\n\n\nStep 3: Converting geometry into Cartograms geometry using {cartogram}\nIn this step, we generate three types of cartograms based on population data, each offering a unique way to represent global population distribution using the {cartogram} package. First, we transform the world map data to the Mercator projection (EPSG 3857), which is the standard projection for web maps. We then create three cartograms:\n\na contiguous cartogram that distorts countries proportionally to population while maintaining geographic adjacency,\na Dorling cartogram that represents each country as a circle sized by population, and\na non-contiguous cartogram that allows countries to resize independently, resulting in more accurate shapes but less geographic continuity.\n\n\n# Transforming the data to different cartogram types based on population\n\n# Create a contiguous cartogram where countries maintain adjacency\nworld_map_cont &lt;- cartogram::cartogram_cont(world_map, \"population\")\n\n# Create a Dorling cartogram where each country is represented by a circle\nworld_map_dorling &lt;- cartogram::cartogram_dorling(world_map, \"population\")\n\n# Create a non-contiguous cartogram where countries resize independently\nworld_map_ncont &lt;- cartogram::cartogram_ncont(world_map, \"population\")\n\n\n\n\nResults\n\nType 1: A Continuous Cartogram\nIn this code, we generate a contiguous cartogram plot, shown in Figure 3, using {ggplot2} and {sf} libraries, with countries sized according to population. The code begins by arranging world_map_cont in descending order of population (so that the countries with larger population are displayed first, while we use the argument check_overlap = TRUE with geom_sf_text(). The cartogram plot is created using geom_sf() for shapes and geom_sf_text() for country labels, with label sizes reflecting population. Manual scales are applied to align fill and text colors with predefined palettes. The plot includes a centered title and minimal theme.\n\n\nCode\n# Arrange the cartogram data by population in descending order\ng &lt;- world_map_cont |&gt; \n  arrange(desc(population)) |&gt; \n\n# Initialize ggplot, mapping fill and color aesthetics to country\n  ggplot(\n    mapping = aes(\n      fill = country,\n      colour = country\n    )\n  ) +\n\n# Add the country shapes without borders\n  geom_sf(\n    colour = \"transparent\"\n  ) +\n\n# Add text labels for each country with size proportional to population\n  geom_sf_text(\n    mapping = aes(\n      label = country,\n      size = population,\n      geometry = geometry\n    ),\n    family = \"caption_font\",\n    fontface = \"bold\",\n    check_overlap = TRUE\n  ) +\n\n# Set continuous scale for text size within a specified range\n  scale_size_continuous(\n    range = c(1, 10)\n  ) +\n\n# Apply manual color scale for fill and outline of countries\n  scale_fill_manual(\n    values = fill_palette\n  ) +\n  scale_colour_manual(\n    values = colour_palette\n  ) +\n\n# Add plot title and remove x and y axis labels\n  labs(\n    x = NULL, y = NULL,\n    title = \"A contiguous Cartogram of countries' population\"\n  ) +\n\n# Apply a minimal theme with custom font and size\n  theme_minimal(\n    base_family = \"caption_font\",\n    base_size = 16\n  ) +\n\n# Customize plot appearance with centered title and invisible legend\n  theme(\n    legend.position = \"none\",\n    panel.grid = element_line(\n      colour = \"grey90\",\n      linetype = 3,\n      linewidth = 0.1\n    ),\n    plot.title = element_text(\n      hjust = 0.5,\n      margin = margin(0,0,0,0, \"mm\"),\n      size = 32\n    ),\n    plot.margin = margin(0,0,0,0, \"mm\")\n  )\n\n# Save the plot as a PNG with defined size and white background\nggsave(\n  plot = g,\n  filename = here::here(\"geocomputation\", \"images\",\n                        \"cartogram_types_3.png\"),\n  height = 900,\n  width = 1200,\n  units = \"px\",\n  bg = \"white\"\n)\n\n\n\n\n\n\n\n\nFigure 3: A World Map Cartogram, with countries sized by population, using data from CIA World Factbook. The contiguous cartogram ensures that neighbousing countries keep touching each other, although shapes are distorted.\n\n\n\n\n\nType 2: A Non-continuous Cartogram\nThe next code chunk generates a non-contiguous cartogram, shown in Figure 4, where countries are resized according to population but maintain their original shapes, making it easier to recognize familiar geographic forms.. It uses two layers of geom_sf() to add the original world map with a grey outline for context and the resized cartogram countries with a semi-transparent overlay. Text labels are added for each country, sized by population, without overlapping.\n\n\nCode\n# Arrange the non-contiguous cartogram data by population in descending order\ng &lt;- world_map_ncont |&gt; \n  arrange(desc(population)) |&gt; \n\n# Initialize ggplot, mapping fill and color aesthetics to country\n  ggplot(\n    mapping = aes(\n      fill = country,\n      colour = country\n    )\n  ) +\n\n# Add the original world map with grey borders and white fill\n  geom_sf(\n    data = world_map,\n    fill = \"white\",\n    colour = \"grey60\",\n    linewidth = 0.1\n  ) +\n\n# Add the non-contiguous cartogram countries with transparency\n  geom_sf(\n    colour = \"transparent\",\n    alpha = 0.75\n  ) +\n\n# Add text labels for each country with size proportional to population\n  geom_sf_text(\n    mapping = aes(\n      label = country,\n      size = population,\n      geometry = geometry\n    ),\n    family = \"caption_font\",\n    fontface = \"bold\",\n    check_overlap = FALSE\n  ) +\n\n# Set continuous scale for text size within a specified range\n  scale_size_continuous(\n    range = c(1, 10)\n  ) +\n\n# Apply manual color scale for fill and outline of countries\n  scale_fill_manual(\n    values = fill_palette\n  ) +\n  scale_colour_manual(\n    values = colour_palette\n  ) +\n\n# Add plot title and remove x and y axis labels\n  labs(\n    x = NULL, y = NULL,\n    title = \"A non-contiguous Cartogram of countries' population - preserves the country shapes\"\n  ) +\n\n# Apply a minimal theme with custom font and size\n  theme_minimal(\n    base_family = \"caption_font\",\n    base_size = 16\n  ) +\n\n# Customize plot appearance with centered title and invisible legend\n  theme(\n    legend.position = \"none\",\n    panel.grid = element_line(\n      colour = \"grey90\",\n      linetype = 3,\n      linewidth = 0.1\n    ),\n    plot.title = element_text(\n      hjust = 0.5,\n      margin = margin(0,0,0,0, \"mm\"),\n      size = 28\n    ),\n    plot.margin = margin(0,0,0,0, \"mm\")\n  )\n\n# Save the plot as a PNG with defined size and white background\nggsave(\n  plot = g,\n  filename = here::here(\"geocomputation\", \"images\",\n                        \"cartogram_types_4.png\"),\n  height = 900,\n  width = 1200,\n  units = \"px\",\n  bg = \"white\"\n)\n\n\n\n\n\n\n\n\nFigure 4: A non-contiguous cartogram of countries population, using data from CIA Factbook, shows that while shapes of countries are preserved, their neighbouring countries don’t touch each others’ borders anymore.\n\n\n\n\n\nType 3: A non-overlapping circles Cartogram\nThis code snippet creates a Dorling cartogram, shown in Figure 5, where countries are represented as non-overlapping circles sized according to their populations. The ggplot function is used to set up the aesthetic mappings for fill and color based on the country. The geom_sf() function is employed to add the circular representations of countries without outlines, while geom_sf_text() adds text labels for each country, sized according to their populations.\n\n\nCode\n# Arrange the Dorling cartogram data by population in descending order\ng &lt;- world_map_dorling |&gt; \n  arrange(desc(population)) |&gt; \n\n# Initialize ggplot, mapping fill and color aesthetics to country\n  ggplot(\n    mapping = aes(\n      fill = country,\n      colour = country\n    )\n  ) +\n\n# Add the non-overlapping circles representing countries\n  geom_sf(\n    colour = \"transparent\"\n  ) +\n\n# Add text labels for each country, sized by population\n  geom_sf_text(\n    mapping = aes(\n      label = country,\n      size = population,\n      geometry = geometry\n    ),\n    family = \"caption_font\",\n    fontface = \"bold\"\n  ) +\n\n# Set continuous scale for text size within a specified range\n  scale_size_continuous(\n    range = c(1, 10)\n  ) +\n\n# Apply manual color scale for fill and Text of countries\n  scale_fill_manual(\n    values = fill_palette\n  ) +\n  scale_colour_manual(\n    values = colour_palette\n  ) +\n\n# Add plot title and remove x and y axis labels\n  labs(\n    x = NULL, y = NULL,\n    title = \"A non-overlapping circles Cartogram of countries' population.\"\n  ) +\n\n# Apply a map theme with custom font and size\n  ggthemes::theme_map(\n    base_family = \"caption_font\",\n    base_size = 16\n  ) +\n\n# Customize plot appearance with centered title and invisible legend\n  theme(\n    legend.position = \"none\",\n    plot.title = element_text(\n      hjust = 0.5,\n      margin = margin(0,0,0,0, \"mm\"),\n      size = 28\n    ),\n    plot.margin = margin(0,0,0,0, \"mm\")\n  )\n\n# Save the plot as a PNG with defined size and white background\nggsave(\n  plot = g,\n  filename = here::here(\"geocomputation\", \"images\",\n                        \"cartogram_types_5.png\"),\n  height = 900,\n  width = 1200,\n  units = \"px\",\n  bg = \"white\"\n)\n\n\n\n\n\n\n\n\nFigure 5\n\n\n\n\n\n\n\n\n\nReferences\n\nJeworutzki, Sebastian. 2023. “Cartogram: Create Cartograms with r.” https://CRAN.R-project.org/package=cartogram.\n\n\nPebesma, Edzer, and Roger Bivand. 2023. “Spatial Data Science: With Applications in r.” https://doi.org/10.1201/9780429459016.\n\n\nSlowikowski, Kamil. 2024. “Ggrepel: Automatically Position Non-Overlapping Text Labels with ’Ggplot2’.” https://CRAN.R-project.org/package=ggrepel.\n\n\nWickham, Hadley. 2016. “Ggplot2: Elegant Graphics for Data Analysis.” https://ggplot2.tidyverse.org.\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019. “Welcome to the Tidyverse” 4: 1686. https://doi.org/10.21105/joss.01686."
  },
  {
    "objectID": "geocomputation/osm_driving_directions.html#step-1-setting-up-basics",
    "href": "geocomputation/osm_driving_directions.html#step-1-setting-up-basics",
    "title": "Driving Directions using Open Street Maps Routing Service",
    "section": "Step 1: Setting up basics",
    "text": "Step 1: Setting up basics\nThis code initializes an R project for geospatial data analysis and visualization, utilizing multiple packages for enhanced map presentation, styling, and data wrangling:\n\nData Handling & Visualization: Packages like tidyverse provide core data manipulation tools and ggplot2 for visualizations.\nSpatial Data Management: sf simplifies handling spatial objects in a tidy framework, and osrm connects R to the Open Source Routing Machine for geospatial route calculations.\nGeocoding: tidygeocoder automates address-based geocoding.\nMap Enhancements: ggspatial adds visual elements like scale bars; ggrepel prevents overlapping labels for clear visuals.\nCustom Fonts: sysfonts and showtext allow use of Google Fonts, applied through a custom theme.\nPlot Layouts & Tables: patchwork enables combining ggplot plots, and gt produces elegant HTML tables.\n\nThe code defines custom fonts for plot titles and body text using Google Fonts (e.g., “Barlow”) and sets up a theme function, theme_drive, for applying a modern, minimal aesthetic in ggplot2. It also specifies text color and font-family defaults for labels in plots.\n\n\nCode\nlibrary(tidyverse)     # Data Wrangling and ggplot2\nlibrary(sf)            # Handle spatial data in R in a tidy way\nlibrary(tidygeocoder)  # Automated geocoding of addresses\nlibrary(osrm)          # Access OSRM through R\nlibrary(ggrepel)       # Nicer non-overlapping labels\nlibrary(glue)          # Easier string interpolation\nlibrary(scales)        # Nicer labeling functions\nlibrary(patchwork)     # Combine plots made in ggplot2\nlibrary(ggspatial)     # Nicer map features like scale bars\nlibrary(showtext)      # Displaying google fonts\nlibrary(sysfonts)      # Getting google fonts into R\nlibrary(gt)            # Displaying beautiful HTML tables \n\n# A font for the titles and major points\nsysfonts::font_add_google(\"Barlow\", \"title_font\")\n\n# A font for the body and text\nsysfonts::font_add_google(\"Barlow Condensed\", \"body_font\")\n\n# Allow R graphics devices to display these fonts\nshowtext::showtext_auto()\n\n# Text colour\ntext_col &lt;- \"grey20\"\n\n# Custom ggplot theme to make pretty plots\n# Get the font at https://fonts.google.com/specimen/Overpass\n\ntheme_drive &lt;- function(...) {\n  theme_void(\n    base_family = \"body_font\",\n    base_size = 14\n  ) +\n  theme(\n    text = element_text(\n      colour = text_col,\n      family = \"body_font\",\n      hjust = 0.5\n    ),\n    ...\n  )\n}\n\n# Make labels use the fonts specified by default\nupdate_geom_defaults(\"label_repel\", list(family = \"body_font\",\n                                         colour = text_col))\nupdate_geom_defaults(\"label\", list(family = \"body_font\",\n                                         colour = text_col))\nupdate_geom_defaults(\"text_repel\", list(family = \"body_font\",\n                                         colour = text_col))\nupdate_geom_defaults(\"text\", list(family = \"body_font\",\n                                         colour = text_col))"
  },
  {
    "objectID": "geocomputation/osm_driving_directions.html#step-2-a-road-trip-plan",
    "href": "geocomputation/osm_driving_directions.html#step-2-a-road-trip-plan",
    "title": "Driving Directions using Open Street Maps Routing Service",
    "section": "Step 2: A Road Trip Plan",
    "text": "Step 2: A Road Trip Plan\nLet us plan a road trip along the northern shores of the Mediterranean Sea, hopping along the famous sites in the capitals and important cities of some countries. This code snippet uses R to create a table of famous attractions across several European countries, geocodes each location to obtain its latitude and longitude, and displays the data in a formatted table with map coordinates:\n\nData Setup: A sample dataset is created with columns for country, capital, attraction, and address using dplyr.\nGeocoding: The tidygeocoder package is used to automatically retrieve latitude and longitude coordinates based on the address, using OpenStreetMap’s geocoding service.\nSpatial Transformation: Once coordinates are obtained, sf converts them into a simple feature (SF) object, setting the coordinate system to EPSG:4326 for geographic data.\nTabular Display: The data is formatted as a stylish HTML table using gt and gtExtras for theme styling.\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(gt)\n\nrawdata &lt;- dplyr::tribble(\n  ~id, ~country,               ~capital,    ~attraction,                   ~address,\n  1,   \"Greece\",               \"Athens\",    \"Acropolis Museum\",            \"15 Dionysiou Areopagitou St, Athens 11742\",\n  2,   \"Albania\",              \"Tirana\",    \"Skanderbeg Square\",           \"Sheshi Skënderbej, Tirana 1001\",\n  3,   \"Montenegro\",           \"Podgorica\", \"Millennium Bridge\",           \"Cetinjski Put, Podgorica 81000\",\n  4,   \"Bosnia and Herzegovina\",\"Sarajevo\", \"Baščaršija (Old Bazaar)\",     \"Baščaršija, Sarajevo 71000\",\n  5,   \"Croatia\",              \"Zagreb\",    \"Ban Jelačić Square\",          \"Trg bana Josipa Jelačića, Zagreb 10000\",\n  6,   \"Slovenia\",             \"Ljubljana\", \"Ljubljana Castle\",            \"Grajska planota 1, Ljubljana 1000\",\n  7,   \"Italy\",                \"Venice\",    \"St. Mark's Basilica\",         \"Piazza San Marco, Venice 30124\",\n  8,   \"Italy\",                \"Florence\",  \"Piazza del Duomo\",            \"Piazza del Duomo, Florence 50122\",\n  9,   \"Italy\",                \"Rome\",      \"Trevi Fountain\",              \"Piazza di Trevi, Rome 00187\"\n)\n\n\n# Convert latitude and longitudes into SF Coordinates\n\n\ndf &lt;- rawdata |&gt; \n  \n  # Compile a full address to be used for finding the coordinates\n  # mutate(\n  #   address = paste(\n  #     destination,\n  #     capital, \n  #     country,\n  #     sep = \", \"\n  #   )\n  # ) |&gt; \n  tidygeocoder::geocode(\n    address = address,\n    # country = country,\n    # city = capital,\n    method = \"osm\"\n  ) |&gt; \n  st_as_sf(\n    coords = c(\"long\", \"lat\"),\n    crs = st_crs(\"EPSG:4326\")\n  )\n\n\n\n\n\n\nTable 1: The data to be used for further analysis\n\n\n\n\n\n\n\n\n\nid\ncountry\ncapital\nattraction\naddress\ngeometry\n\n\n\n\n1\nGreece\nAthens\nAcropolis Museum\n15 Dionysiou Areopagitou St, Athens 11742\nc(23.7302954, 37.9303789)\n\n\n2\nAlbania\nTirana\nSkanderbeg Square\nSheshi Skënderbej, Tirana 1001\nc(19.8182412, 41.3271148)\n\n\n3\nMontenegro\nPodgorica\nMillennium Bridge\nCetinjski Put, Podgorica 81000\nc(19.2436765, 42.4413965)\n\n\n4\nBosnia and Herzegovina\nSarajevo\nBaščaršija (Old Bazaar)\nBaščaršija, Sarajevo 71000\nc(18.430885, 43.8590435)\n\n\n5\nCroatia\nZagreb\nBan Jelačić Square\nTrg bana Josipa Jelačića, Zagreb 10000\nc(15.9765701, 45.8130054)\n\n\n6\nSlovenia\nLjubljana\nLjubljana Castle\nGrajska planota 1, Ljubljana 1000\nc(14.5085094926128, 46.0488354)\n\n\n7\nItaly\nVenice\nSt. Mark's Basilica\nPiazza San Marco, Venice 30124\nc(12.3385088944988, 45.4342591)\n\n\n8\nItaly\nFlorence\nPiazza del Duomo\nPiazza del Duomo, Florence 50122\nc(11.2554773666595, 43.7731014)\n\n\n9\nItaly\nRome\nTrevi Fountain\nPiazza di Trevi, Rome 00187\nc(12.4836123990993, 41.90089955)"
  },
  {
    "objectID": "geocomputation/osm_driving_directions.html#step-3-some-custom-functions",
    "href": "geocomputation/osm_driving_directions.html#step-3-some-custom-functions",
    "title": "Driving Directions using Open Street Maps Routing Service",
    "section": "Step 3: Some Custom Functions",
    "text": "Step 3: Some Custom Functions\nThis code defines a set of custom functions in R to format durations, distances, and handle conversions between different units, useful for working with geographic and travel data:\n\nFormatting Durations: fmt_duration() takes an input in minutes and converts it into a readable string format. Durations are rounded to the nearest 15 minutes and formatted to display in hours and minutes. When durations exceed 24 hours, days are factored into the calculation by converting them to hours for accurate display.\nDistance Formatting:\n\nfmt_miles and fmt_km utilize scales::label_number() to format distances in miles and kilometers, respectively, with suffixes and thousand separators for clarity.\n\nDistance Conversions: Functions for converting between miles, meters, and kilometers:\n\nmiles_to_meters() converts miles to meters.\nmeters_to_miles() and km_to_miles() handle conversions from meters and kilometers to miles.\n\n\n\n\nCode\n# Credits: Andrew Weiss\n# URL: https://www.andrewheiss.com/blog/2023/06/01/\n#      geocoding-routing-openstreetmap-r/#packages-and-functions\n\n# Format duration in minutes and hours\n# This function takes a numeric input of a duration in minutes,\n# rounds it to the nearest 15 minutes, and formats the result as a string\n# indicating the number of hours and minutes in the duration.\n\nfmt_duration &lt;- function(x) {\n  \n  # Round to the nearest 15 minutes\n  n_seconds &lt;- round(seconds(x * 60) / (15 * 60)) * (15 * 60)\n  n_seconds &lt;- seconds_to_period(n_seconds)\n  \n  out &lt;- map_chr(n_seconds, \\(n) {\n    if (seconds(n) &lt;= 59) {\n      # If this is less than an hour, don't format anything with hours\n      glue(\"{MM} minutes\", MM = minute(n))\n    } else {\n      # The formatting is required in terms of hours only. When the \n      # duration exceeds 24 hours, `seconds_to_period()` converts the \n      # duration into days (e.g., `seconds_to_period(60 * 60 * 24)` returns \n      # \"1d 0H 0M 0S\") and displays zero hours. Therefore, the day portion \n      # of the period is extracted, multiplied by 24, and added to the \n      # hour component intended for display. \n      extra_day_hours &lt;- day(n) * 24\n  \n      glue(\"{HH} hour{s} {MM} minutes\",\n        HH = scales::label_comma()(hour(n) + extra_day_hours),\n        MM = minute(n),\n        s = ifelse(hour(n) == 1, \"\", \"s\")\n      )\n    }\n  })\n  \n  return(out)\n}\n\nfmt_miles &lt;- scales::label_number(\n  accuracy = 10, \n  suffix = \" miles\", \n  big.mark = \",\"\n  )\n\nfmt_km &lt;- scales::label_number(\n  accuracy = 10, \n  suffix = \" km\", \n  big.mark = \",\"\n  )\n\n\nmiles_to_meters &lt;- function(x) {\n  x * 1609.344\n}\n\nmeters_to_miles &lt;- function(x) {\n  x / 1609.344\n}\n\nkm_to_miles &lt;- function(x) {\n  meters_to_miles(x * 1000)\n}"
  },
  {
    "objectID": "geocomputation/osm_driving_directions.html#step-4-the-base-map-and-the-driving-locations",
    "href": "geocomputation/osm_driving_directions.html#step-4-the-base-map-and-the-driving-locations",
    "title": "Driving Directions using Open Street Maps Routing Service",
    "section": "Step 4: The base map and the driving locations",
    "text": "Step 4: The base map and the driving locations\nThis code creates a custom map showing key tourist attractions within the calculated bounding box of selected European countries:\n\nBounding Box Calculation:\n\nThe bounding box for mapped points is set with an additional degree of expansion (edi), extending the box slightly around all locations. This is calculated with st_bbox() using geometries in df.\n\nBasemap Creation:\n\nA basemap of European countries is created using rnaturalearth data, filtering out small states like Vatican City and San Marino. The map’s area data is computed for further customization if needed.\n\nMap Plotting:\n\nggplot2 and sf add visual layers:\n\nCountry boundaries as background with geom_sf().\nCountry names with partially transparent, bold labels via geom_sf_text().\nTourist attraction points and city names using red markers and labels.\n\n\n\n\n\nCode\n# Compute the bounding box for the maps\n# Expansion outside bounding box in degrees = edi\nedi = 0.5\ndrive_bbox &lt;- st_bbox(df$geometry) + c(-2 * edi, -2.5 * edi, edi, edi)\n\n\nbasemap &lt;- rnaturalearth::ne_countries(scale = 50) |&gt;\n  select(name, iso_a3, geometry) |&gt; \n  filter(!(name %in% c(\"Vatican\", \"San Marino\"))) |&gt; \n  st_crop(drive_bbox) |&gt; \n  mutate(area = as.numeric(st_area(geometry)))\n\ng &lt;- ggplot(basemap) +\n  geom_sf() +\n  geom_sf_text(\n    mapping = aes(\n      label = name\n    ),\n    alpha = 0.5,\n    fontface = \"bold\",\n    nudge_y = +0.3\n  ) +\n  geom_sf(\n    data = df,\n    colour = \"darkred\",\n    size = 2,\n    alpha = 0.5\n  ) +\n  geom_sf_text(\n    data = df,\n    mapping = aes(label = capital),\n    colour = \"darkred\",\n    nudge_y = -0.2\n  ) +\n  labs(x = NULL, y = NULL)\n\n\nggsave(\n  filename = here::here(\"geocomputation\", \"images\",\n                        \"osm_driving_directions_4.png\"),\n  plot = g,\n  height = 900,\n  width = 900,\n  units = \"px\",\n  bg = \"white\"\n)\n\n\n\n\n\n\n\n\nFigure 1: A basic map showing the selected cities and the map of selected countries using data available in {rnaturalearth} and ne_countries()"
  },
  {
    "objectID": "geocomputation/osm_driving_directions.html#step-5-getting-the-routes-and-a-raw-map-of-the-routes",
    "href": "geocomputation/osm_driving_directions.html#step-5-getting-the-routes-and-a-raw-map-of-the-routes",
    "title": "Driving Directions using Open Street Maps Routing Service",
    "section": "Step 5: Getting the Routes and a raw map of the routes",
    "text": "Step 5: Getting the Routes and a raw map of the routes\nThis code generates a visual map illustrating the shortest driving routes between selected European cities, based on OpenStreetMap data:\n\nRoute Data Preparation:\n\nStarting with df (containing cities and their coordinates), cities are paired sequentially as origins and destinations using lead(). The data is trimmed to exclude the final unpaired row.\nosrmRoute() retrieves the shortest driving route between each origin and destination pair, with the computed route details stored in a nested column named route.\n\nUnnesting and Formatting:\n\nThe route column is expanded to reveal route-specific data (geometry, distance, duration). Route geometry is then set as the primary spatial feature.\nCustom functions fmt_km() and fmt_duration() format the route’s distance and duration for clear labeling.\n\nMap Plotting:\n\nggplot2 visualizes the data in layers:\n\nA basemap of European countries, created earlier, serves as the background.\nCities are marked in red, with labels for capital cities slightly adjusted for readability.\nDriving routes between cities are drawn as connecting lines using the computed route_geometry.\n\n\n\n\n\nCode\ndfroutes &lt;- df|&gt; \n  rename(\n    origin_geometry = geometry,\n    origin_city = capital\n  ) |&gt;  \n  mutate(\n    destination_geometry = lead(origin_geometry),\n    destination_city = lead(origin_city)\n  )  |&gt; \n  slice_head(n = (nrow(df) - 1)) |&gt; \n  \n  # Let functions compute on our data frame a row-at-a-time\n  rowwise() |&gt; \n  \n  # Getting the shortest route between the two cities\n  mutate(route = osrmRoute(\n    src = origin_geometry, \n    dst = destination_geometry)\n  ) |&gt; \n\n# The route details are stored in a nested list column called `route`, # which we’ll unnest. This produces a data frame with three geometry \n# columns—for origin, destination, and route—so we’ll set the route \n# column as the primary geometry (allowing us to use `geom_sf(data = routes_geocoded)` directly).\n  \n  unnest(route, names_sep = \"_\") |&gt; \n  st_set_geometry(\"route_geometry\") |&gt; \n  mutate(\n    distance_text = fmt_km(route_distance),\n    duration_text = fmt_duration(route_duration)\n  )\n\n\n\n\nCode\ng &lt;- ggplot() +\n  geom_sf(\n    data = basemap\n  ) +\n  geom_sf(\n    data = df,\n    colour = \"red\",\n    size = 3\n  ) +\n  geom_sf_text(\n    data = df,\n    aes(label = capital),\n    nudge_y = -0.3,\n    size = 5\n  ) +\n  geom_sf(\n    data = dfroutes,\n    mapping = aes(\n      geometry = route_geometry\n    )\n  ) +\n  labs(\n    x = NULL, y = NULL\n  )\n\nggsave(\n  filename = here::here(\"geocomputation\", \"images\",\n                        \"osm_driving_directions_2.png\"),\n  plot = g,\n  height = 900,\n  width = 900,\n  units = \"px\",\n  bg = \"white\"\n)\n\n\n\n\n\n\n\n\nFigure 2: A simple map of the country boundaries [from {rnaturalearth} and function ne_countries()] with the route computed by osrmRoute() from {osrm} and selected destination cities as red dots."
  },
  {
    "objectID": "geocomputation/osm_driving_directions.html#step-6-a-nice-stadia-map-background-map",
    "href": "geocomputation/osm_driving_directions.html#step-6-a-nice-stadia-map-background-map",
    "title": "Driving Directions using Open Street Maps Routing Service",
    "section": "Step 6: A nice Stadia Map background map",
    "text": "Step 6: A nice Stadia Map background map\nThis code retrieves and customizes a basemap using Stadia Maps, overlaying it with geospatial data in EPSG:3857, a coordinate reference system commonly used for web mapping.\n\nAPI Setup:\n\nThe Stadia Maps API is registered with the register_stadiamap() function, allowing access to map tiles.\n\nBounding Box Definition:\n\nA bounding box (dv_bbox) is defined using the limits of the area of interest. The bounding box is adjusted to Stadia Maps’ format, setting boundaries based on longitude and latitude.\n\nFetching Map Tiles:\n\nget_stadiamap() retrieves map tiles with terrain background style (maptype = \"stamen_terrain_background\"), appropriate for visualizing geographic contexts.\n\nCoordinate System Transformation:\n\nA custom function, ggmap_bbox(), redefines the map’s bounding box to EPSG:3857, necessary for layering sf objects over the raster map. This transformation is critical for accurate overlay alignment.\n\nMap Overlay and Export:\n\nUsing ggmap(), the transformed Stadia basemap is displayed. The map, including overlaid geospatial features, is saved as a high-resolution image (osm_driving_directions_3.png) with ggsave().\n\n\n\n\nCode\n# ggmap::register_stadiamap(\"YOUR API KEY HERE\")\n\n# A bounding box in the format c(lowerleftlon, lowerleftlat, upperrightlon, upperrightlat)\ndv_bbox &lt;- drive_bbox\nnames(dv_bbox) &lt;- c(\"left\", \"bottom\", \"right\", \"top\")\n\n\n# Getting the map tiles\nbasemap2 &lt;- ggmap::get_stadiamap(\n  bbox = dv_bbox,\n  zoom = 7,\n  maptype = \"stamen_terrain_background\"\n)\nobject.size(basemap2) |&gt; print(units = \"Mb\")\n\nggmap::ggmap(basemap2)\n\n# Starting the process of Overlaying the geom_sf() data on this\n# Most important is to add the inherit.aes = FALSE argument.\n\n# Step: 1: \n# Credits: https://stackoverflow.com/questions/47749078/how-to-put-a-geom-sf-produced-map-on-top-of-a-ggmap-produced-raster by andyteucher on StackOverFlow (https://stackoverflow.com/users/1736291/andyteucher)\n\n# Define a function to fix the bbox to be in CRS EPSG:3857\nggmap_bbox &lt;- function(map) {\n  # Extract the bounding box (in lat/lon) from the ggmap\n  # to a numeric vector, and set the names to what\n  # sf::st_bbox expects:\n  map_bbox &lt;- setNames(\n    unlist(attr(map, \"bb\")),\n    c(\"ymin\", \"xmin\", \"ymax\", \"xmax\")\n  )\n\n  # Coonvert the bbox to an sf polygon, transform it to 3857,\n  # and convert back to a bbox (convoluted, but it works)\n  bbox_3857 &lt;- st_bbox(\n    st_transform(\n      st_as_sfc(\n        st_bbox(map_bbox, crs = 4326)\n        ), \n      3857\n    )\n  )\n\n  # Overwrite the bbox of the ggmap object with the transformed coordinates\n  attr(map, \"bb\")$ll.lat &lt;- bbox_3857[\"ymin\"]\n  attr(map, \"bb\")$ll.lon &lt;- bbox_3857[\"xmin\"]\n  attr(map, \"bb\")$ur.lat &lt;- bbox_3857[\"ymax\"]\n  attr(map, \"bb\")$ur.lon &lt;- bbox_3857[\"xmax\"]\n  map\n}\n\n# Use the function to convert our downloaded Raster Files into \n# the new CRS and new bounding box CRS\nbasemap_sf &lt;- ggmap_bbox(basemap2)\n\ng &lt;- ggmap::ggmap(basemap2) +\n  labs(x = NULL, y = NULL)\n\n\nggsave(\n  filename = here::here(\"geocomputation\", \"images\",\n                        \"osm_driving_directions_3.png\"),\n  plot = g,\n  height = 900,\n  width = 900,\n  units = \"px\",\n  bg = \"white\"\n)\n\n\n\n\n\n\n\n\nFigure 3: The base map retrieved in the form of raster tiles, from {ggmap} using get_stadia_maps() with the map style “Stamen Terrain Background”"
  },
  {
    "objectID": "geocomputation/osm_driving_directions.html#step-7-the-overall-visualization",
    "href": "geocomputation/osm_driving_directions.html#step-7-the-overall-visualization",
    "title": "Driving Directions using Open Street Maps Routing Service",
    "section": "Step 7: The overall visualization",
    "text": "Step 7: The overall visualization\nThis code snippet enhances the base map by overlaying spatial data, labels, and route details, creating a rich, layered map visualization with ggplot2 and ggmap. Here’s a breakdown of each step:\n\nBasemap Layer:\n\nUses ggmap::ggmap(basemap_sf) to display the raster map tiles retrieved and adjusted to EPSG:3857, enabling overlays of geospatial objects.\n\nCountry Boundaries and Names:\n\ngeom_sf() with transparency and thin lines adds country outlines, while geom_sf_text() displays country names proportionally sized by area.\n\nDriving Route:\n\nThe dfroutes dataset, containing route geometries between destinations, is layered with geom_sf(), color-coded for visibility.\n\nCity Locations and Labels:\n\ngeom_sf() highlights cities in red, while geom_text_repel() labels each city’s name, ensuring labels do not overlap with other map features.\n\nRoute Details:\n\ngeom_sf_label() displays distance labels along the route with partially transparent backgrounds, enhancing readability without cluttering.\n\nCoordinate System and Styling:\n\ncoord_sf() is set to EPSG:3857, matching the basemap. The theme_void() removes unnecessary plot elements for a clean map-focused look, with additional styling adjustments.\n\n\n\n\nCode\n# The base map raster tiles\ng &lt;- ggmap::ggmap(basemap_sf) +\n  \n  # Country boundaries\n  geom_sf(\n    data = basemap,\n    fill = \"transparent\",\n    colour = alpha(text_col, 0.3),\n    inherit.aes = F,\n    linewidth = 0.3\n  ) +\n  \n  # Country names\n  geom_sf_text(\n    data = basemap,\n    mapping = aes(label = name, size = area),\n    alpha = 0.5,\n    fontface = \"bold\",\n    inherit.aes = F\n  ) +\n  scale_size_continuous(range = c(5, 12)) +\n  \n  # The driving route\n  geom_sf(\n    data = dfroutes,\n    mapping = aes(\n      geometry = route_geometry\n    ),\n    inherit.aes = F,\n    colour = alpha(text_col, 0.8),\n    linewidth = 0.5\n  ) +\n  \n  # The cities to be visited\n  geom_sf(\n    data = df,\n    colour = \"red\",\n    size = 3, \n    inherit.aes = F,\n    alpha = 0.5\n  ) +\n  \n  # Names of cities\n  geom_text_repel(\n    data = df,\n    aes(\n      label = capital,\n      geometry = geometry\n    ),\n    inherit.aes = F,\n    stat = \"sf_coordinates\",\n    fontface = \"bold\",\n    size = 8\n  ) +\n  \n  # Route times and distances\n  geom_sf_label(\n    data = dfroutes,\n    mapping = aes(\n      label = paste0(distance_text)\n    ),\n    fill = alpha(\"white\", 0.5),\n    lineheight = 0.3,\n    inherit.aes = F,\n    label.size = unit(0, \"mm\")\n    \n  ) +\n  \n  # Coordinates and Scales\n  coord_sf(\n    crs = 3857\n  ) +\n  theme_void(\n    base_size = 40,\n    base_family = \"body_font\"\n  ) +\n  theme(\n    legend.position = \"none\",\n    plot.margin = margin(0,0,0,0, \"mm\")\n  )\n\nggsave(\n  filename = here::here(\"geocomputation\", \"images\",\n                        \"osm_driving_directions_1.png\"),\n  plot = g,\n  height = 9.25,\n  width = 10,\n  unit = \"cm\",\n  bg = \"white\"\n)\n\n\n\n\n\n\n\n\nFigure 4: The completed overall visualization - with a base map of raster tiles from {ggmap} get_stadia_map(), overlaid country names and boundaries from {rnaturalearth} ne_countries(), and routes from {osrm} package."
  },
  {
    "objectID": "geocomputation/osm_driving_directions.html#step-8-each-leg-of-the-trip-visualized-separately",
    "href": "geocomputation/osm_driving_directions.html#step-8-each-leg-of-the-trip-visualized-separately",
    "title": "Driving Directions using Open Street Maps Routing Service",
    "section": "Step 8: Each leg of the trip visualized separately",
    "text": "Step 8: Each leg of the trip visualized separately\nThis code snippet generates individual map visualizations for each driving route using ggmap and ggplot2. Here’s an explanation of the process, which effectively creates a series of images showcasing routes between pairs of cities:\n\nLoop through Routes:\n\nThe for loop iterates over each row of the dfroutes dataframe, which contains driving route data between origin and destination cities.\n\nDefine Temporary Bounding Box:\n\nFor each route, a temporary bounding box is created using the st_bbox() function and expanded slightly to ensure that the route is well-framed in the map view.\n\nRetrieve Map Tiles:\n\nThe get_stadiamap() function fetches map tiles based on the temporary bounding box, specifying a zoom level and map type (e.g., “outdoors”).\n\nCrop Basemap:\n\nA cropped version of the original country basemap is created to match the bounding box of the current route, ensuring the country boundaries align with the area of interest.\n\nCreate Map Visualization:\n\nggmap::ggmap(temp_basemap) initializes the base map, onto which various layers are added:\n\nCountry Names: Displayed using geom_sf_text(), showing the names of countries within the bounding box.\nDriving Route: The specific route for the current iteration is drawn using geom_sf().\nCities: Both the origin and destination cities are represented with red points using geom_sf().\nCity Labels: City names are added with geom_text_repel(), ensuring that they do not overlap with each other or other elements.\nRoute Details: Distance and duration information are displayed using geom_sf_label(), formatted neatly for clarity.\n\n\nFinalizing the Map:\n\nCoordinate System: Set to EPSG:3857 for compatibility with the base map.\nTheme Adjustments: theme_void() is used to create a clean look, removing axes and grid lines.\n\n\nThis approach results in a series of visually consistent maps, each illustrating a distinct driving route between two cities, complete with detailed annotations and clear geographic context. The display is done using the Tabset Panels layout available in Quarto.\n\n\nCode\nfor (i in 1: nrow(dfroutes)) {\n \n  # A bounding box in the format (left, right, top, bottom) for {ggmap}\n  temp_bbox &lt;- st_bbox(\n    dfroutes |&gt; \n    slice(i)\n    ) + c(-1, -1, 1, 1)\n  names(temp_bbox) &lt;- c(\"left\", \"bottom\", \"right\", \"top\")\n  \n  # Getting the map tiles\n  temp_basemap &lt;- ggmap::get_stadiamap(\n    bbox = temp_bbox,\n    zoom = 8,\n    maptype = \"outdoors\"\n  )  \n  \n  temp_basemap &lt;- ggmap_bbox(temp_basemap)\n  \n  object.size(temp_basemap) |&gt; print(units = \"Mb\")\n  \n  temp_baselinemap &lt;- st_crop(basemap, temp_bbox)\n  \n  # The base map raster tiles\n  g &lt;- ggmap::ggmap(temp_basemap) +\n    \n    # Country boundaries\n    # geom_sf(\n    #   data = temp_baselinemap,\n    #   fill = \"transparent\",\n    #   colour = alpha(text_col, 0.3),\n    #   inherit.aes = F,\n    #   linewidth = 0.3\n    # ) +\n    \n    # Country names\n    geom_sf_text(\n      data = temp_baselinemap,\n      mapping = aes(label = name, size = area),\n      alpha = 0.5,\n      fontface = \"bold\",\n      inherit.aes = F\n    ) +\n    scale_size_continuous(range = c(5, 12)) +\n    \n    # The driving route\n    geom_sf(\n      data = slice(dfroutes, i),\n      mapping = aes(\n        geometry = route_geometry\n      ),\n      inherit.aes = F,\n      colour = alpha(text_col, 0.8),\n      linewidth = 0.5\n    ) +\n    \n    # The cities to be visited: origin\n    geom_sf(\n      data = slice(dfroutes, i),\n      mapping = aes(geometry = origin_geometry),\n      colour = \"red\",\n      size = 3, \n      inherit.aes = F,\n      alpha = 0.4\n    ) +\n    # The cities to be visited: destination\n    geom_sf(\n      data = slice(dfroutes, i),\n      mapping = aes(geometry = destination_geometry),\n      colour = \"red\",\n      size = 3, \n      inherit.aes = F,\n      alpha = 0.4\n    ) +\n    \n    # Names of cities: Origin\n    geom_text_repel(\n      data = slice(dfroutes, i),\n      aes(\n        label = origin_city,\n        geometry = origin_geometry\n      ),\n      inherit.aes = F,\n      stat = \"sf_coordinates\",\n      fontface = \"bold\",\n      size = 8\n    ) +\n    # Names of cities: Destination\n    geom_text_repel(\n      data = slice(dfroutes, i),\n      aes(\n        label = destination_city,\n        geometry = destination_geometry\n      ),\n      inherit.aes = F,\n      stat = \"sf_coordinates\",\n      fontface = \"bold\",\n      size = 8\n    ) +\n    \n    \n    # Route times and distances\n    geom_sf_label(\n      data = slice(dfroutes, i),\n      mapping = aes(\n        label = paste0(\n          distance_text,\n          \"\\n\",\n          \"(\",\n          duration_text,\n          \")\"\n        )\n      ),\n      fill = alpha(\"white\", 0.5),\n      lineheight = 0.3,\n      inherit.aes = F,\n      label.size = unit(0, \"mm\"),\n      size = 5,\n      fontface = \"bold\"\n    ) +\n    \n    # Coordinates and Scales\n    coord_sf(\n      crs = 3857\n    ) +\n    \n    theme_void(\n      base_size = 40,\n      base_family = \"body_font\"\n    ) +\n    theme(\n      legend.position = \"none\",\n      plot.margin = margin(0,0,0,0, \"mm\")\n    )\n  \n  ggsave(\n    filename = here::here(\"geocomputation\", \"images\",\n                          paste0(\"osm_driving_directions_leg\", i, \".png\")),\n    plot = g,\n    height = 6,\n    width = 6,\n    unit = \"cm\",\n    bg = \"white\"\n  )\n   \n}\n\n\n\nLeg 1Leg 2Leg 3Leg 4Leg 5Leg 6Leg 7Leg 8\n\n\n\n\n\n\n\n\nFigure 5: Day 1: Drive from Athens to Tirana.\n\n\n\n\n\n\n\n\n\n\n\nFigure 6: Day 2: Drive from Tirana to Padogorica.\n\n\n\n\n\n\n\n\n\n\n\nFigure 7: Day 3: Drive from Padogorica to Sarajevo.\n\n\n\n\n\n\n\n\n\n\n\nFigure 8: Day 4: Drive from Sarajevo to Zagreb.\n\n\n\n\n\n\n\n\n\n\n\nFigure 9: Day 5: Drive from Zagreb to Ljubljana.\n\n\n\n\n\n\n\n\n\n\n\nFigure 10: Day 6: Drive from Ljubljana to Venice.\n\n\n\n\n\n\n\n\n\n\n\nFigure 11: Day 7: Drive from Venice to Florence.\n\n\n\n\n\n\n\n\n\n\n\nFigure 12: Day 8: Drive from Florence to Rome."
  },
  {
    "objectID": "ggplot2_ext.html",
    "href": "ggplot2_ext.html",
    "title": "ggplot2 Extensions",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nSubtitle\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "geocomputation/chapter1.html",
    "href": "geocomputation/chapter1.html",
    "title": "Chapter 2: Geocomputation with R",
    "section": "",
    "text": "Geographic Data Models: Vector and raster models are foundational.\n\nVector Model: Represents geographic data as points, lines, and polygons with precise boundaries; commonly used in social sciences for features like human settlements.\nRaster Model: Divides surfaces into cells; useful in environmental sciences, often based on remote sensing and aerial data. Scalable and consistent over large areas.\n\nChoosing a Model:\n\nVector is often used in social sciences.\nRaster is prevalent in environmental studies.\n\nR Implementation:\n\nUse sf for vector data.\nUse terra for raster data.\n\n\n\nlibrary(sf)           # Simple Features in R\nlibrary(terra)        # Raster Data in R\nlibrary(spData)       # Spatial Datasets\nlibrary(spDataLarge)  # Large Spatial Datasets\nlibrary(tidyverse)    # Data Wrangling and Visualization"
  },
  {
    "objectID": "geocomputation/chapter1.html#introduction",
    "href": "geocomputation/chapter1.html#introduction",
    "title": "Chapter 2: Geocomputation with R",
    "section": "",
    "text": "Geographic Data Models: Vector and raster models are foundational.\n\nVector Model: Represents geographic data as points, lines, and polygons with precise boundaries; commonly used in social sciences for features like human settlements.\nRaster Model: Divides surfaces into cells; useful in environmental sciences, often based on remote sensing and aerial data. Scalable and consistent over large areas.\n\nChoosing a Model:\n\nVector is often used in social sciences.\nRaster is prevalent in environmental studies.\n\nR Implementation:\n\nUse sf for vector data.\nUse terra for raster data.\n\n\n\nlibrary(sf)           # Simple Features in R\nlibrary(terra)        # Raster Data in R\nlibrary(spData)       # Spatial Datasets\nlibrary(spDataLarge)  # Large Spatial Datasets\nlibrary(tidyverse)    # Data Wrangling and Visualization"
  },
  {
    "objectID": "geocomputation/chapter1.html#vector-data",
    "href": "geocomputation/chapter1.html#vector-data",
    "title": "Chapter 2: Geocomputation with R",
    "section": "2.2 Vector Data",
    "text": "2.2 Vector Data\n\nVector Data: Represents geographic features using points, lines, and polygons based on coordinate reference systems (CRS).\n\nExample: London’s coordinates c(-0.1, 51.5) in geographic CRS or c(530000, 180000) in projected CRS (British National Grid).\n\nCRS Overview:\n\nGeographic CRS uses lon/lat (0° longitude and latitude origin).\nProjected CRS, like the British National Grid, is based on Easting/Northing coordinates with positive values.\n\nKey dependencies / libraries used by the sf Package:\n\nGDAL: Handles geographic data formats\nPROJ: For CRS transformations\nGEOS: Supports planar geometry for projected data\nS2: Manages spherical geometry for unprojected data (e.g., lon/lat), toggleable with sf::sf_use_s2(FALSE).\n\nGeometry Engines:\n\nPlanar (GEOS): For 2D projected data.\nSpherical (S2): For 3D unprojected data.\n\n\n\n2.2.1 Introduction to Simple Features\n\nSimple Features (SF): Hierarchical model by OGC; supports multiple geometry types.\nCore Types: sf package in R supports 7 core geometry types (points, lines, polygons, and “multi” versions).\nLibrary Integration: sf replaces sp, rgdal, rgeos; unified interface for GEOS (geometry), GDAL (data I/O), PROJ (CRS).\nNon-Planar Support: Integrates s2 for geographic (lon/lat) operations, used by default for accuracy on spherical geometries.\nData Storage: SF objects are data frames with a spatial column (geom).\nVignettes: Documentation accessible with vignette(package = \"sf\") for practical use and examples.\nPlotting: plot(sf_object) maps all variables, unlike single-map GIS tools.\nSummary: summary() gives spatial and attribute data insights.\nSubset: SF objects subsettable like data frames, retaining spatial metadata.\n\n\n\nCode\n# See which vignettes are available\n# vignette(package = \"sf\")\n\nworld\n## Simple feature collection with 177 features and 10 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -180 ymin: -89.9 xmax: 180 ymax: 83.64513\n## Geodetic CRS:  WGS 84\n## # A tibble: 177 × 11\n##    iso_a2 name_long continent region_un subregion type  area_km2     pop lifeExp\n##  * &lt;chr&gt;  &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n##  1 FJ     Fiji      Oceania   Oceania   Melanesia Sove…   1.93e4  8.86e5    70.0\n##  2 TZ     Tanzania  Africa    Africa    Eastern … Sove…   9.33e5  5.22e7    64.2\n##  3 EH     Western … Africa    Africa    Northern… Inde…   9.63e4 NA         NA  \n##  4 CA     Canada    North Am… Americas  Northern… Sove…   1.00e7  3.55e7    82.0\n##  5 US     United S… North Am… Americas  Northern… Coun…   9.51e6  3.19e8    78.8\n##  6 KZ     Kazakhst… Asia      Asia      Central … Sove…   2.73e6  1.73e7    71.6\n##  7 UZ     Uzbekist… Asia      Asia      Central … Sove…   4.61e5  3.08e7    71.0\n##  8 PG     Papua Ne… Oceania   Oceania   Melanesia Sove…   4.65e5  7.76e6    65.2\n##  9 ID     Indonesia Asia      Asia      South-Ea… Sove…   1.82e6  2.55e8    68.9\n## 10 AR     Argentina South Am… Americas  South Am… Sove…   2.78e6  4.30e7    76.3\n## # ℹ 167 more rows\n## # ℹ 2 more variables: gdpPercap &lt;dbl&gt;, geom &lt;MULTIPOLYGON [°]&gt;\n\nnames(world)\n##  [1] \"iso_a2\"    \"name_long\" \"continent\" \"region_un\" \"subregion\" \"type\"     \n##  [7] \"area_km2\"  \"pop\"       \"lifeExp\"   \"gdpPercap\" \"geom\"\nclass(world)\n## [1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\n\n\nCode\nworld |&gt; names()\n\nclass(world)\n\nggplot(world) + geom_sf()\n\nplot(world)\n\nworld[1:2, 1:3]\n\nvignette(\"sf1\")\n\nrbind(c(5, 2), c(1, 3), c(3, 4), c(3, 2))\n\nlist(rbind(c(1, 5), c(4, 4), c(4, 1), c(2, 2), c(3, 2)), \n                            rbind(c(1, 2), c(2, 4)))\n\nsf_use_s2()\n\nraster_filepath = system.file(\n  \"raster/srtm.tif\", \n  package = \"spDataLarge\"\n  )\n\nmy_rast = rast(raster_filepath)\n\n?rast\n\nclass(my_rast)\nprint(my_rast)\nmy_rast\nobject.size(my_rast)\n?srtm.tif\nncell(my_rast)\n457*465\nres(my_rast)\ninMemory(my_rast)\nplot(my_rast)\n\n\nnew_raster = rast(nrows = 36, ncols = 36, \n                  xmin = -15, xmax = 15, ymin = -15, ymax = 15,\n                  vals = round(rnorm(n = 36*36) * 100, 1))\n\nplot(new_raster)\n\nmulti_raster_file = system.file(\"raster/landsat.tif\", package = \"spDataLarge\")\nmulti_rast = rast(multi_raster_file)\n\nmulti_rast |&gt; \n  plot()\n\nnlyr(multi_rast)"
  },
  {
    "objectID": "geocomputation/chapter2.html",
    "href": "geocomputation/chapter2.html",
    "title": "Chapter 2: Geographic data in R",
    "section": "",
    "text": "Geographic Data Models: Vector and raster models are foundational.\n\nVector Model: Represents geographic data as points, lines, and polygons with precise boundaries; commonly used in social sciences for features like human settlements.\nRaster Model: Divides surfaces into cells; useful in environmental sciences, often based on remote sensing and aerial data. Scalable and consistent over large areas.\n\nChoosing a Model:\n\nVector is often used in social sciences.\nRaster is prevalent in environmental studies.\n\nR Implementation:\n\nUse sf for vector data.\nUse terra for raster data.\n\n\n\nlibrary(sf)           # Simple Features in R\nlibrary(terra)        # Raster Data in R\nlibrary(spData)       # Spatial Datasets\nlibrary(spDataLarge)  # Large Spatial Datasets\nlibrary(tidyverse)    # Data Wrangling and Visualization"
  },
  {
    "objectID": "geocomputation/chapter2.html#introduction",
    "href": "geocomputation/chapter2.html#introduction",
    "title": "Chapter 2: Geographic data in R",
    "section": "",
    "text": "Geographic Data Models: Vector and raster models are foundational.\n\nVector Model: Represents geographic data as points, lines, and polygons with precise boundaries; commonly used in social sciences for features like human settlements.\nRaster Model: Divides surfaces into cells; useful in environmental sciences, often based on remote sensing and aerial data. Scalable and consistent over large areas.\n\nChoosing a Model:\n\nVector is often used in social sciences.\nRaster is prevalent in environmental studies.\n\nR Implementation:\n\nUse sf for vector data.\nUse terra for raster data.\n\n\n\nlibrary(sf)           # Simple Features in R\nlibrary(terra)        # Raster Data in R\nlibrary(spData)       # Spatial Datasets\nlibrary(spDataLarge)  # Large Spatial Datasets\nlibrary(tidyverse)    # Data Wrangling and Visualization"
  },
  {
    "objectID": "geocomputation/chapter2.html#vector-data",
    "href": "geocomputation/chapter2.html#vector-data",
    "title": "Chapter 2: Geographic data in R",
    "section": "2.2 Vector Data",
    "text": "2.2 Vector Data\n\nVector Data: Represents geographic features using points, lines, and polygons based on coordinate reference systems (CRS).\n\nExample: London’s coordinates c(-0.1, 51.5) in geographic CRS or c(530000, 180000) in projected CRS (British National Grid).\n\nCRS Overview:\n\nGeographic CRS uses lon/lat (0° longitude and latitude origin).\nProjected CRS, like the British National Grid, is based on Easting/Northing coordinates with positive values.\n\nKey dependencies / libraries used by the sf Package:\n\nGDAL: Handles geographic data formats\nPROJ: For CRS transformations\nGEOS: Supports planar geometry for projected data\nS2: Manages spherical geometry for unprojected data (e.g., lon/lat), toggleable with sf::sf_use_s2(FALSE).\n\nGeometry Engines:\n\nPlanar (GEOS): For 2D projected data.\nSpherical (S2): For 3D unprojected data.\n\n\n\n2.2.1 Introduction to Simple Features\n\nSimple Features (SF): Hierarchical model by OGC (Open Geospatial Consortium); supports multiple geometry types.\nCore Types: sf package in R supports 7 core geometry types (points, lines, polygons, and their “multi” versions).\nLibrary Integration: sf replaces sp, rgdal, rgeos; unified interface for GEOS (geometry), GDAL (data I/O), PROJ (CRS).\nNon-Planar Support: Integrates s2 for geographic (lon/lat) operations, used by default for accuracy on spherical geometries.\nData Storage: SF objects are data frames with a spatial column (geometry or geom).\nVignettes: Documentation accessible with vignette(package = \"sf\") for practical use and examples.\nPlotting: plot(sf_object) maps all variables, unlike single-map GIS tools.\nSummary: summary() gives spatial and attribute data insights.\nSubset: SF objects subsettable like data frames, retaining spatial metadata.\n\n\nworld\n\nSimple feature collection with 177 features and 10 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -180 ymin: -89.9 xmax: 180 ymax: 83.64513\nGeodetic CRS:  WGS 84\n# A tibble: 177 × 11\n   iso_a2 name_long continent region_un subregion type  area_km2     pop lifeExp\n * &lt;chr&gt;  &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1 FJ     Fiji      Oceania   Oceania   Melanesia Sove…   1.93e4  8.86e5    70.0\n 2 TZ     Tanzania  Africa    Africa    Eastern … Sove…   9.33e5  5.22e7    64.2\n 3 EH     Western … Africa    Africa    Northern… Inde…   9.63e4 NA         NA  \n 4 CA     Canada    North Am… Americas  Northern… Sove…   1.00e7  3.55e7    82.0\n 5 US     United S… North Am… Americas  Northern… Coun…   9.51e6  3.19e8    78.8\n 6 KZ     Kazakhst… Asia      Asia      Central … Sove…   2.73e6  1.73e7    71.6\n 7 UZ     Uzbekist… Asia      Asia      Central … Sove…   4.61e5  3.08e7    71.0\n 8 PG     Papua Ne… Oceania   Oceania   Melanesia Sove…   4.65e5  7.76e6    65.2\n 9 ID     Indonesia Asia      Asia      South-Ea… Sove…   1.82e6  2.55e8    68.9\n10 AR     Argentina South Am… Americas  South Am… Sove…   2.78e6  4.30e7    76.3\n# ℹ 167 more rows\n# ℹ 2 more variables: gdpPercap &lt;dbl&gt;, geom &lt;MULTIPOLYGON [°]&gt;\n\nnames(world)\n\n [1] \"iso_a2\"    \"name_long\" \"continent\" \"region_un\" \"subregion\" \"type\"     \n [7] \"area_km2\"  \"pop\"       \"lifeExp\"   \"gdpPercap\" \"geom\"     \n\nclass(world)\n\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n########### THE GEOMETRY COLUMN IS STICKY ################\nsummary(world[\"lifeExp\"])\n\n    lifeExp                 geom    \n Min.   :50.62   MULTIPOLYGON :177  \n 1st Qu.:64.96   epsg:4326    :  0  \n Median :72.87   +proj=long...:  0  \n Mean   :70.85                      \n 3rd Qu.:76.78                      \n Max.   :83.59                      \n NA's   :10                         \n\n\n\n\nCode\nplot(world)\n\n\n\n\n\n\n\n\nFigure 1: The basic plot() function on a sf object produced multiple plots, one for each of the non-geometry variables (columns) in the plotted dataset.\n\n\n\n\n\n\n\n2.2.2 Why Simple Features?\n\nCross-Compatibility: SF model is compatible with many GIS tools (e.g., QGIS, PostGIS), enabling easy data transfer.\nAdvantages of sf in R:\n\nData Handling: Fast reading/writing of spatial data.\nPlotting: Improved plotting speed and performance.\nData Frame-Like: sf objects behave like data frames.\nConsistent Naming: sf functions are intuitive, starting with st_.\nTidyverse-Friendly: Works well with |&gt; and integrates with tidyverse packages.\n\nData Import Options:\n\nread_sf(): Imports data as a tidy tibble (quietly).\nst_read(): Imports data as a base R data frame (verbose).\n\nPopularity: sf is the primary package for spatial vector data in R, preferred over alternatives like spatstat and terra.\n\n\nworld_dfr &lt;- st_read(system.file(\"shapes/world.shp\", package = \"spData\"))\n## Reading layer `world' from data source \n##   `C:\\Users\\dradi\\AppData\\Local\\R\\win-library\\4.3\\spData\\shapes\\world.shp' \n##   using driver `ESRI Shapefile'\n## Simple feature collection with 177 features and 10 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -180 ymin: -89.9 xmax: 180 ymax: 83.64513\n## Geodetic CRS:  WGS 84\nworld_dfr &lt;- read_sf(system.file(\"shapes/world.shp\", package = \"spData\"))\n\nclass(world_dfr)\n## [1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\n\n2.2.3 Basic Maps\n\nPlotting in sf:\n\nplot() creates multi-panel plots for multiple variables or a single-panel plot for one variable.\nSupports fixed color customization using col and border arguments.\n\n\n\n\nCode\nplot(world)\n\n\n\n\n\n\n\n\nFigure 2: The base plot() function creates a faceted output with a map for each variable other than geometry\n\n\n\n\n\n\nLayering Plots: Add layers to existing plots with add = TRUE. Use reset = FALSE for plots with a key.\nOverlaying Data: Circles representing population size can be plotted using cex and st_centroid().\nBounding Box Expansion: expandBB adjusts the plot boundaries (bottom, left, top, right).\nLimitations: Base plot() is simple but limited in functionality; use tmap for advanced maps.\n\n\n\n2.2.4 Geometry Types\n\nGeometry Basics:\n\nCore components of simple features; sf supports 18 types.\nFocus on 7 common types: POINT, LINESTRING, POLYGON, MULTIPOINT, MULTILINESTRING, MULTIPOLYGON, GEOMETRYCOLLECTION.\n\nEncoding Standards:\n\nWKB (Well-known binary): Hexadecimal, computer-friendly format.\nWKT (Well-known text): Human-readable format, often shown for explanation.\n\nCommon Geometries:\n\nPOINT: Single coordinate (e.g., POINT (5 2)).\nLINESTRING: Connected sequence of points (e.g., LINESTRING (1 5, 4 4, 4 1, 2 2, 3 2)).\nPOLYGON: Closed ring of points (e.g., POLYGON ((1 5, 2 2, 4 1, 4 4, 1 5))).\n\nMulti-Geometries:\n\nMULTIPOINT: Multiple points (e.g., MULTIPOINT (5 2, 1 3, 3 4, 3 2)).\nMULTILINESTRING: Multiple linestrings (e.g., MULTILINESTRING ((1 5, 4 4, 4 1, 2 2, 3 2), (1 2, 2 4))).\nMULTIPOLYGON: Multiple polygons (e.g., MULTIPOLYGON (((1 5, 2 2, 4 1, 4 4, 1 5), (0 2, 1 2, 1 3, 0 3, 0 2)))).\n\nGeometry Collection:\n\nMix of geometry types (e.g., GEOMETRYCOLLECTION (MULTIPOINT (5 2, 1 3, 3 4, 3 2), LINESTRING (1 5, 4 4, 4 1, 2 2, 3 2))).\n\n\n\n\n2.2.5 The sf Class\n\nStructure of sf Objects: Composed of geometries (sfc object) and non-geographic attributes (data.frame or tibble).\nCreation of sf Objects: Steps:\n\nCreate geometry (sfg) with functions like st_point()\nConvert to geometry column (sfc) with CRS using function st_sfc(..., crs = \"...\")\nCombine attributes (data.frame) with sfc using function st_sf(..., geometry = ...)\n\n\n\n\nCharacteristics:\n\nsf objects have dual class: sf and data.frame.\nSpatial attributes stored in a geometry column.\nsf behaves like a data.frame but with spatial extension.\n\n\n\n\n2.2.6 Simple Feature Geometries (sfg)\nAn sfg object represents a single simple feature geometry. A simple feature geometry column (sfc) is a collection of sfg objects and can also include information about the coordinate reference system (CRS) being used.\nGeometries can be created using st_ functions or imported from existing spatial files.\n\nsfg Creation Functions:\n\nst_point(): Create a single point.\nst_linestring(): Create a linestring.\nst_polygon(): Create a polygon.\nst_multipoint(): Create a multipoint.\nst_multilinestring(): Create a multilinestring.\nst_multipolygon(): Create a multipolygon.\nst_geometrycollection(): Create a geometry collection.\n\nInput Data Types:\n\nNumeric Vector: Single points.\nMatrix: Sets of points for multipoint or linestring.\nList: Complex structures for multilinestrings, (multi)polygons, or geometry collections.\n\nExamples:\n\n\nCode\n\n# Create a point\npoint &lt;- st_point(c(8, 3))  # POINT (8 3)\nprint(point)\nggplot(point) +\n  geom_sf()\n\n# Create a multipoint\nmultipoint_matrix &lt;- rbind(c(8, 3), c(2, 5), c(5, 7), c(7, 3))\nmultipoint &lt;- st_multipoint(multipoint_matrix)  # MULTIPOINT ((8 3), (2 5), (5 7), (7 3))\nprint(multipoint)\nggplot(multipoint) +\n  geom_sf()\n\n# Create a linestring\nlinestring_matrix &lt;- rbind(c(2, 8), c(6, 6), c(7, 2), c(5, 3), c(8, 4))\nlinestring &lt;- st_linestring(linestring_matrix)  # LINESTRING (2 8, 6 6, 7 2, 5 3, 8 4)\nprint(linestring)\nggplot(linestring) +\n  geom_sf()\n\n# Create a polygon\npolygon_list &lt;- list(rbind(c(2, 8), c(4, 3), c(7, 2), c(6, 7), c(2, 8)))\npolygon &lt;- st_polygon(polygon_list)  # POLYGON ((2 8, 4 3, 7 2, 6 7, 2 8))\nprint(polygon)\nggplot(polygon) +\n  geom_sf()\n\n# Polygon with a hole\npolygon_border &lt;- rbind(c(2, 8), c(4, 3), c(7, 2), c(6, 7), c(2, 8))\npolygon_hole &lt;- rbind(c(4, 6), c(5, 6), c(5, 5), c(4, 5), c(4, 6))\npolygon_with_hole_list &lt;- list(polygon_border, polygon_hole)\npolygon_with_hole &lt;- st_polygon(polygon_with_hole_list)  # POLYGON with a hole\nprint(polygon_with_hole)\nggplot(polygon_with_hole) +\n  geom_sf()\n\n# Create a multilinestring\nmultilinestring_list = list(\n  rbind(c(2, 8), c(6, 6), c(7, 2), c(5, 3), c(8, 4)),\n  rbind(c(3, 2), c(5, 8))\n)\nmultilinestring = st_multilinestring(multilinestring_list)  # MULTILINESTRING\nprint(multilinestring)\nggplot(multilinestring) +\n  geom_sf()\n\n# Create a multipolygon\nmultipolygon_list = list(\n  list(rbind(c(2, 8), c(4, 3), c(7, 2), c(6, 7), c(2, 8))),\n  list(rbind(c(0, 3), c(2, 3), c(2, 4), c(0, 4), c(0, 3)))\n)\nmultipolygon = st_multipolygon(multipolygon_list)  # MULTIPOLYGON\nprint(multipolygon)\nggplot(multipolygon) +\n  geom_sf()\n\n# Create a geometry collection\ngeometrycollection_list = list(st_multipoint(multipoint_matrix), st_linestring(linestring_matrix))\ngeometry_collection = st_geometrycollection(geometrycollection_list)  # GEOMETRYCOLLECTION\nprint(geometry_collection)\nggplot(geometry_collection) +\n  geom_sf()\n\n\n\n\n\n\n\n\n\n\n\n\n(a) A point\n\n\n\n\n\n\n\n\n\n\n\n(b) A multipoint\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) A linestring\n\n\n\n\n\n\n\n\n\n\n\n(d) A polygon\n\n\n\n\n\n\n\n\n\n\n\n\n\n(e) Polygon with a hole\n\n\n\n\n\n\n\n\n\n\n\n(f) Multilinestring\n\n\n\n\n\n\n\n\n\n\n\n\n\n(g) Multipolygon\n\n\n\n\n\n\n\n\n\n\n\n(h) Geometry Collection\n\n\n\n\n\n\n\nFigure 3: Creating different sample geometry objects in R with {sf}\n\n\n\n\n\n2.2.8 The sfheaders Package\n\nOverview:\n\nsfheaders (Cooley 2024) is an R package designed to efficiently create and manipulate sf objects from vectors, matrices, and data frames.\nIt does not rely on the sf library and instead uses underlying C++ code, enabling faster operations and the potential for further development with compiled code.\n\nCompatibility:\n\nAlthough separate from sf, it is fully compatible, producing valid sf objects like sfg, sfc, and sf.\n\nKey Functionality:\n\nConverts:\n\nVector → sfg_POINT\nMatrix → sfg_LINESTRING\nData Frame → sfg_POLYGON\n\nCreates sfc and sf objects using similar syntax.\n\nAdvantages:\n\nsfheaders is optimized for high-speed ‘deconstruction’ and ‘reconstruction’ of sf objects and casting between geometry types, offering faster performance than sf in many cases.\n\n\n\n\n2.2.9 Spherical Geometry Operations with S2\n\nConcept:\n\nSpherical geometry operations acknowledge Earth’s roundness, as opposed to planar operations that assume flat surfaces.\nSince sf version 1.0.0, R integrates with Google’s S2 spherical geometry engine, enabling accurate global spatial operations.\nS2 supports operations like distance, buffer, and area calculations, allowing accurate geocomputation on a spherical Earth model.\nKnown as a Discrete Global Grid System (DGGS), S2 is similar to other systems like H3, which is a global hexagonal index.\n\nS2 Mode:\n\nBy default, S2 is enabled in sf. Verify with:\nsf_use_s2()\nTurning Off S2:\nsf_use_s2(FALSE)\n\nS2 Limitations and Edge Cases:\n\nSome operations may fail due to S2’s stricter definitions, potentially affecting legacy code. Error messages such as Error in s2_geography_from_wkb ... might require turning off S2.\n\nRecommendation:\n\nKeep S2 enabled for accurate global calculations unless specific operations necessitate its deactivation."
  },
  {
    "objectID": "geocomputation/chapter2.html#raster-data",
    "href": "geocomputation/chapter2.html#raster-data",
    "title": "Chapter 2: Geographic data in R",
    "section": "2.3 Raster Data",
    "text": "2.3 Raster Data\n\nThe raster data model represents the world as a continuous grid of cells (pixels). Focuses on regular grids, where each cell is of constant size, though other grid types (e.g., rotated, sheared) exist.\nStructure:\n\nComprises a raster header and a matrix of equally spaced cells.\nThe raster header includes:\n\nCRS (Coordinate Reference System)\nExtent (geographical area covered)\nOrigin (starting point, often the lower left corner; the terra package defaults to the upper left).\n\nExtent is defined by:\n\nNumber of columns (ncol)\nNumber of rows (nrow)\nCell size resolution\n\n\nCell Access and Modification:\n\nCells can be accessed and modified by:\n\nCell ID\nExplicitly specifying row and column indices.\n\nThis matrix representation is efficient as it avoids storing corner coordinates (unlike vector polygons).\n\nData Characteristics:\n\nEach cell can hold a single value, which can be either:\n\nContinuous (e.g., elevation, temperature)\nCategorical (e.g., land cover classes).\n\n\nApplications:\n\nRaster maps are useful for continuous phenomena (e.g., temperature, population density) and can also represent discrete features (e.g., soil classes).\n\n\n\n2.3.1 R Packages for Working with Raster Data\n\nSeveral R packages for reading and processing raster datasets have emerged over the last two decades. The raster package was the first significant advancement in R’s raster capabilities when launched in 2010. It was the premier package until the development of terra and stars, both offering powerful functions for raster data.\nThis book emphasizes terra, which replaces the older, slower raster package.\nComparison of terra and stars:\n\n\n\n\n\n\n\n\n\nFeature\nterra\nstars\n\n\n\n\nPrimary Focus\nRegular grids\nSupports regular, rotated, sheared, rectilinear, and curvilinear grids\n\n\nData Structure\nOne or multi-layered rasters\nRaster data cubes with multiple layers, time steps, and attributes\n\n\nMemory Management\nUses C++ code and pointers for data storage\nUses lists of arrays for smaller rasters; file paths for larger ones\n\n\nVector Data Integration\nUses its own class SpatVector but supports sf objects\nClosely related to vector objects/functions in sf\n\n\nFunctions & Methods\nLarge number of built-in, purpose-specific functions (e.g., re-sampling, cropping)\nMix of built-in functions (st_ prefix), existing dplyr functions, and custom methods for R functions\n\n\nConversion Between Packages\nConversion to stars with st_as_stars()\nConversion to terra with rast()\n\n\nPerformance\nGenerally optimized for speed and memory efficiency\nFlexible, but performance varies based on data type and structure\n\n\nBest Use Cases\nSingle or multi-layer rasters; fast processing\nComplex data cubes with layers over time and multiple attributes\n\n\nProgramming Language Basis\nPrimarily C++\nR with some C++ integration\n\n\n\n\n\n2.3.2 Introduction to terra\n\nThe terra package is designed for handling raster objects in R, supporting a range of functions to create, read, export, manipulate, and process raster datasets.\n\nWhile its functionality is similar to the older raster package, terra offers improved computational efficiency.\nDespite terra’s advantages, the raster class system remains popular due to its widespread use in other R packages.\nterra provides seamless translation between the two object types using functions like raster(), stack(), and brick() for backward compatibility.\n\nKey Features:\n\nLow-Level Functionality: Includes functions that help in building new tools for raster data processing.\nMemory Management: Supports processing of large raster datasets by dividing them into smaller chunks for iterative processing, allowing operations beyond available RAM capacity.\n\n\n\n\nCode\nraster_filepath &lt;- system.file(\"raster/srtm.tif\", \n                              package = \"spDataLarge\")\nmy_rast &lt;- rast(raster_filepath)\n\nclass(my_rast)\n## [1] \"SpatRaster\"\n## attr(,\"package\")\n## [1] \"terra\"\n\next(my_rast)\n## SpatExtent : -113.239583212784, -112.85208321281, 37.1320834298579, 37.5129167631658 (xmin, xmax, ymin, ymax)\n\nprint(my_rast)\n## class       : SpatRaster \n## dimensions  : 457, 465, 1  (nrow, ncol, nlyr)\n## resolution  : 0.0008333333, 0.0008333333  (x, y)\n## extent      : -113.2396, -112.8521, 37.13208, 37.51292  (xmin, xmax, ymin, ymax)\n## coord. ref. : lon/lat WGS 84 (EPSG:4326) \n## source      : srtm.tif \n## name        : srtm \n## min value   : 1024 \n## max value   : 2892\n\n\n\nDedicated Reporting Functions:\n\ndim(): Number of rows, columns, and layers.\nncell(): Total number of cells (pixels).\nres(): Spatial resolution.\next(): Spatial extent.\ncrs(): Coordinate reference system (CRS).\ninMemory(): Checks if data is stored in memory or on disk.\nsources: Shows file location.\n\nAccessing Full Function List:\n\nRun help(\"terra-package\") to see all available terra functions.\n\n\n\n\n2.3.3 Basic Map-Making\n\nPlotting with terra:\n\nThe terra package offers a simple way to create basic visualizations using the plot() function, specifically designed for SpatRaster objects.\n\n\n\n\nCode\nplot(my_rast)\n\n\n\n\n\n\n\n\nFigure 4: An example raster data displayed with {terra} using plot()\n\n\n\n\n\n\nAdvanced Plotting Options:\n\nplotRGB(): A specialized function in terra for creating color composite plots using three layers (e.g., red, green, blue bands) from a SpatRaster object.\ntmap Package (Tennekes 2018): Useful for creating both static and interactive maps for raster and vector data.\nrasterVis Package (2023): Includes functions such as levelplot() to create advanced visualizations, including faceted plots for displaying changes over time.\n\n\n\n\n2.3.4 Raster Classes\n\nThe SpatRaster class in terra represents raster objects. Rasters are commonly created by reading a file using rast()\n\nterra supports reading various formats via GDAL, only loading the header and a file pointer into RAM.\n\nCreating Rasters from Scratch: Use rast() to make new raster objects:\n\nFills values row-wise from the top left corner.\nResolution depends on rows, columns, and extent; defaults to degrees (WGS84 CRS).\n\n\n\n\nCode\n# Create a new SpatRaster object: a checkerboard design\nnew_raster = rast(nrows = 50, ncols = 50, \n                  xmin = 0, xmax = 50, \n                  ymin = 0, ymax = 50,\n                  vals = rep(c(1, 0.25, 0.75, 0.5), \n                             times = 12)) \n\n\n# Plot the new raster\nplot(new_raster, \n     col = c(\"darkblue\", \n             \"white\",\n             \"blue\",\n             \"lightblue\"), # Use blue and white for the design\n     axes = TRUE, \n     box = FALSE)\n\n\n\n\n\n\n\n\nFigure 5: Creating a new raster from scratch\n\n\n\n\n\n\nHandling Multi-Layer Rasters:\n\nSpatRaster supports multi-layer rasters, such as satellite or time-series data:\n\nUse nlyr() to get the number of layers:\nAccess layers with [[ or $.\nUse subset() for layer extraction:\n\n\nCombining Raster Layers:\n\nMerge SpatRaster layers using c():\n\nSaving SpatRaster Objects:\n\nSince they often point to files, direct saving to .rds or .rda isn’t feasible.\nSolutions:\n\nwrap(): Creates a temporary object for saving or cluster use.\nwriteRaster(): Saves as a regular raster file."
  },
  {
    "objectID": "geocomputation/chapter2.html#coordinate-reference-systems",
    "href": "geocomputation/chapter2.html#coordinate-reference-systems",
    "title": "Chapter 2: Geographic data in R",
    "section": "2.4 Coordinate Reference Systems",
    "text": "2.4 Coordinate Reference Systems\n\nCRSs (Coordinate Reference Systems) are essential for spatial data, defining how spatial elements correspond to the Earth’s surface (or other celestial bodies).\nTypes of CRSs:\n\nGeographic CRSs:\n\nRepresent data on a three-dimensional surface (e.g., latitude and longitude).\nCoordinate units are typically degrees.\n\nProjected CRSs:\n\nRepresent data on a two-dimensional, flat plane.\nTransform spherical Earth data into a flat map.\nCoordinate units can be in meters, feet, etc.\n\n\n\n\n2.4.1 Geographic Coordinate Reference Systems\n\nGeographic CRSs use longitude and latitude to identify locations on Earth.\n\nLongitude: Measures East-West position relative to the Prime Meridian.\nLatitude: Measures North-South position relative to the equatorial plane.\nDistances are measured in angular units (degrees), not meters, impacting spatial measurements (explored further in Section 7).\n\nThe Earth can be modeled as spherical or ellipsoidal.\n\nSpherical models: Simplify calculations by assuming Earth is a perfect sphere.\nEllipsoidal models: More accurately represent Earth with distinct equatorial and polar radii. The equatorial radius is about 11.5 km longer than the polar radius due to Earth’s compression.\n\nDatum refers to the model describing the relationship between coordinate values and actual locations on Earth. A datum consists of:\n\nEllipsoid: An idealized mathematical model of the Earth’s shape, which helps to approximate the Earth’s surface.\nOrigin Point: A fixed starting point for the coordinate system, where the ellipsoid is anchored to Earth.\nOffset and Orientation: How the ellipsoid is aligned with respect to the actual shape of the Earth.\n\n\n\n\nThe two types of Datums are: —\n\nGeocentric datum (e.g., WGS84): Centered at Earth’s center of gravity, providing global consistency but less local accuracy.\nLocal datum (e.g., NAD83): Adjusted for specific regions to better align with the Earth’s surface, accounting for local geographic variations (e.g., mountain ranges).\n\n\n\n\n2.4.2 Projected Coordinate Reference Systems\n\nProjected CRSs are based on geographic CRSs and use map projections to represent Earth’s three-dimensional surface in Easting and Northing (x and y) values. These CRSs rely on Cartesian coordinates on a flat surface, with an origin and linear units (e.g., meters).\nDeformations:\n\nThe conversion from 3D to 2D inherently introduces distortions. Projected CRSs can only preserve one or two of the following properties:\n\nArea: Preserved in equal-area projections.\nDirection: Preserved in azimuthal projections.\nDistance: Preserved in equidistant projections.\nShape: Preserved in conformal projections.\n\n\n\n\n\nTypes of Projections and Their Characteristics\n\n\n\n\n\n\n\n\n\nType of Projection\nDescription\nCommon Properties Preserved\nBest Used For\n\n\n\n\nConic\nProjects Earth’s surface onto a cone.\nArea, shape\nMaps of mid-latitude regions\n\n\nCylindrical\nProjects Earth’s surface onto a cylinder.\nDirection, shape\nWorld maps\n\n\nPlanar (Azimuthal)\nProjects onto a flat surface at a point or line.\nDistance, direction\nPolar region maps\n\n\n\n\n\nDeformations by Projection Type\n\n\n\n\n\n\n\n\nProperty\nDefinition\nProjection Type That Preserves It\n\n\n\n\nArea\nThe relative size of regions is maintained.\nEqual-area projections (e.g., Albers)\n\n\nDirection\nBearings from the center are accurate.\nAzimuthal projections (e.g., Lambert)\n\n\nDistance\nCorrect distances are preserved along specific lines or from specific points.\nEquidistant projections (e.g., Equirectangular)\n\n\nShape\nLocal angles and shapes are maintained, though areas are distorted.\nConformal projections (e.g., Mercator)\n\n\n\n\nUse the Map Projection Explorer for details.\nUse st_crs() for querying CRSs in sf objects and crs() for terra objects.\n\n\n\nCode\nsf_proj_info(type = \"proj\") |&gt; \n  as_tibble() |&gt; \n  gt::gt() |&gt; \n  gt::cols_label_with(fn = snakecase::to_title_case) |&gt; \n  gtExtras::gt_theme_espn() |&gt; \n  gt::opt_interactive()\n\n\n\n\nTable 1: A list of the available projections supported by the PROJ library"
  },
  {
    "objectID": "geocomputation/chapter2.html#exercises",
    "href": "geocomputation/chapter2.html#exercises",
    "title": "Chapter 2: Geographic data in R",
    "section": "2.6 Exercises",
    "text": "2.6 Exercises\n\n\nE1\nUsing summary() on the geometry column of the world data object in the spData package provides valuable information about the spatial characteristics of the dataset:\n\nGeometry Type:\n\nThe output will indicate the type of geometries present in the world data object. Here, it is MULTIPOLYGON suggesting that the dataset represents the outlines of countries or regions in MULTIPLOYGON formats.\n\nNumber of Countries:\n\nThe summary will show the number of geometries or features present, which corresponds to the number of countries or regions represented in the world dataset. Here, it is 177 countries.\n\nCoordinate Reference System (CRS):\n\nThe output will include details about the CRS, and in the present case it is EPSG:4326.\n\n\n\nsummary((spData::world$geom))\n\n MULTIPOLYGON     epsg:4326 +proj=long... \n          177             0             0 \n\n\n\n\n\nE2\nTo generate the world map, you can run the following code (as shown in Section 2.2.3):\n\nCode\nlibrary(spData)\nplot(world[3:6])\nplot(world[\"pop\"])\n\n\n\n\n\n\n\n\n\n\nFigure 6: Reproducing Figure 2.4 of the book\n\n\n\n\n\n\n\n\n\n\n\nFigure 7: Reproducing Figure 2.4 of the book\n\n\n\n\n\n\n\nSimilarities:\n\nThe map displays country boundaries and highlights the global population distribution as shown in the book.\nThe color scale representing population data is consistent with that described in the book, with larger populations shown with more intense colors.\n\nDifferences:\n\nThe aspect ratio or positioning of the map might vary depending on your screen resolution and window size.\nThe color theme and legend display may differ if your R setup or graphic device uses default settings different from those in the book.\n\ncex Argument: This parameter controls the size of plotting symbols in R. It is a numeric value that acts as a multiplier for the default size of symbols.\n\nSetting cex to values larger than 1 enlarges symbols, while values less than 1 shrink them.\n\nReason for cex = sqrt(world$pop) / 10000 : The code sets cex to sqrt(world$pop) / 10000 to scale the size of the points on the map in proportion to the population of each country. This square root transformation is used to moderate the variation in symbol sizes because population values can vary significantly between countries. Dividing by 10,000 helps to reduce the symbol size to a reasonable range for plotting.\n\nOther Ideas: —\n\nBubble Plot: Overlay a bubble plot on the map with points sized by population.\n\n\n\nCode\nplot(world[\"pop\"])\npoints(st_coordinates(st_centroid(world$geom)), \n       cex = sqrt(world$pop) / 5000, \n       col = \"red\", pch = 19)\n\n\n\n\n\n\n\n\n\n\nChoropleth Map: Use color gradients to represent population density.\n\n\n\nCode\nlibrary(tmap)\ntm_shape(world) +\n  tm_polygons(\"pop\", style = \"jenks\", \n              palette = \"Blues\", \n              title = \"Population\")\n\n\n\n\n\n\n\n\n\n\nLog Transformation: Visualize population using a log scale for better differentiation.\n\n\n\nCode\nworld$log_pop = log10(world$pop + 1)\nplot(world[\"log_pop\"])\n\n\n\n\n\n\n\n\n\n\n\n\nE3\nTo create a map of Nigeria in context and customize it using the plot() function, you can follow these steps:\nStep 1: Load Necessary Libraries and Data: Make sure you have the spData package loaded and access to the world spatial data.\nStep 2: Plotting Nigeria in Context: You can plot Nigeria by subsetting the world data and adjusting parameters such as lwd (line width), col (color), and expandBB (expanding the bounding box). Here’s an example code snippet:\nStep 3: Annotating the Map: To annotate the map with text labels, you can use the text() function. Here’s an example where we add the name of Nigeria and its capital, Abuja:\nStep 4: Exploring the text() Documentation\n\nlwd: This argument controls the line width for the borders of the countries.\ncol: This argument sets the fill color for the countries. You can customize it based on your preference.\nexpandBB: This argument expands the bounding box of the plot, which can help visualize nearby areas more clearly.\n\n\n\n\nE4\nTo create an empty SpatRaster object with 10 columns and 10 rows, assign random values between 0 and 10, and then plot it, you can use the terra package in R. Here’s how you can do it:\n\n\nCode\nlibrary(terra)\n\n# Create an empty SpatRaster object with 10 columns and 10 rows\nmy_raster &lt;- rast(nrows = 10, ncols = 10)\n\n# Assign random values between 0 and 10\nvalues(my_raster) &lt;- runif(ncell(my_raster), min = 0, max = 10)\n\n# Plot the raster\nplot(my_raster, main = \"Random Values Raster\")\n\n\n\n\n\n\n\n\n\n\n\n\nE5\nTo read in the raster/nlcd.tif file from the spDataLarge package and examine its properties, you can follow these steps in R:\n\nlibrary(spDataLarge)\nlibrary(terra)\n\n# Read the raster file\nnlcd_raster &lt;- rast(system.file(\"raster/nlcd.tif\", package = \"spDataLarge\"))\n\nInformation You Can Obtain: —\n\nBasic Properties: The print(nlcd_raster) command will provide you with information about the raster, including its dimensions, number of layers, and type of data.\n\n# Check the basic properties of the raster\nprint(nlcd_raster)\n\nclass       : SpatRaster \ndimensions  : 1359, 1073, 1  (nrow, ncol, nlyr)\nresolution  : 31.5303, 31.52466  (x, y)\nextent      : 301903.3, 335735.4, 4111244, 4154086  (xmin, xmax, ymin, ymax)\ncoord. ref. : NAD83 / UTM zone 12N (EPSG:26912) \nsource      : nlcd.tif \ncolor table : 1 \ncategories  : levels \nname        :   levels \nmin value   :    Water \nmax value   : Wetlands \n\n\nSummary Statistics: The summary(nlcd_raster) function will give you basic statistics about the raster values, such as minimum, maximum, and mean values. In this case, it tells the number of cells with Forest, Shrubland, Barren, Developed, Cultivated, Wetlands and Other land-use types.\n\n# Get summary statistics\nsummary(nlcd_raster)\n\n        levels     \n Forest    :52620  \n Shrubland :37463  \n Barren    : 7290  \n Developed : 1203  \n Cultivated:  596  \n Wetlands  :  443  \n (Other)   :  421  \n\n\nExtent: The ext(nlcd_raster) command will provide the geographical extent of the raster, showing the minimum and maximum x and y coordinates.\n\n# Check the extent of the raster\next(nlcd_raster)\n\nSpatExtent : 301903.344386758, 335735.354381954, 4111244.46098842, 4154086.47216415 (xmin, xmax, ymin, ymax)\n\n\nRows and Columns: You can find the number of rows and columns in the raster using nrow(nlcd_raster) and ncol(nlcd_raster).\n\n# Get the number of rows and columns\nnrow(nlcd_raster)\n\n[1] 1359\n\nncol(nlcd_raster)\n\n[1] 1073\n\n\nCoordinate Reference System (CRS): The crs(nlcd_raster) command will return the CRS of the raster, which is essential for spatial analyses.\n\n# Get the coordinate reference system (CRS)\nstr_view(crs(nlcd_raster))\n\n[1] │ PROJCRS[\"NAD83 / UTM zone 12N\",\n    │     BASEGEOGCRS[\"NAD83\",\n    │         DATUM[\"North American Datum 1983\",\n    │             ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n    │                 LENGTHUNIT[\"metre\",1]]],\n    │         PRIMEM[\"Greenwich\",0,\n    │             ANGLEUNIT[\"degree\",0.0174532925199433]],\n    │         ID[\"EPSG\",4269]],\n    │     CONVERSION[\"UTM zone 12N\",\n    │         METHOD[\"Transverse Mercator\",\n    │             ID[\"EPSG\",9807]],\n    │         PARAMETER[\"Latitude of natural origin\",0,\n    │             ANGLEUNIT[\"degree\",0.0174532925199433],\n    │             ID[\"EPSG\",8801]],\n    │         PARAMETER[\"Longitude of natural origin\",-111,\n    │             ANGLEUNIT[\"degree\",0.0174532925199433],\n    │             ID[\"EPSG\",8802]],\n    │         PARAMETER[\"Scale factor at natural origin\",0.9996,\n    │             SCALEUNIT[\"unity\",1],\n    │             ID[\"EPSG\",8805]],\n    │         PARAMETER[\"False easting\",500000,\n    │             LENGTHUNIT[\"metre\",1],\n    │             ID[\"EPSG\",8806]],\n    │         PARAMETER[\"False northing\",0,\n    │             LENGTHUNIT[\"metre\",1],\n    │             ID[\"EPSG\",8807]]],\n    │     CS[Cartesian,2],\n    │         AXIS[\"(E)\",east,\n    │             ORDER[1],\n    │             LENGTHUNIT[\"metre\",1]],\n    │         AXIS[\"(N)\",north,\n    │             ORDER[2],\n    │             LENGTHUNIT[\"metre\",1]],\n    │     USAGE[\n    │         SCOPE[\"Engineering survey, topographic mapping.\"],\n    │         AREA[\"North America - between 114°W and 108°W - onshore and offshore. Canada - Alberta; Northwest Territories; Nunavut; Saskatchewan. United States (USA) - Arizona; Colorado; Idaho; Montana; New Mexico; Utah; Wyoming.\"],\n    │         BBOX[31.33,-114,84,-108]],\n    │     ID[\"EPSG\",26912]]\n\n\nResolution: You can check the resolution of the raster with the res(nlcd_raster) function, which will indicate the size of each pixel.\n\n# Check the resolution of the raster\nres(nlcd_raster)\n\n[1] 31.53030 31.52466\n\n\nValues: The values(nlcd_raster) command allows you to access the actual values contained in the raster. Here, I am printing only the first few values.\n\n# Get the values of the raster\nvalues(nlcd_raster) |&gt; head()\n\n     levels\n[1,]      4\n[2,]      4\n[3,]      5\n[4,]      4\n[5,]      4\n[6,]      4\n\n\n\n\n\n\nE6\nTo check the Coordinate Reference System (CRS) of the raster/nlcd.tif file from the spDataLarge package, you can use the following steps in R. The CRS provides essential information about how the spatial data is projected on the Earth’s surface.\n\nlibrary(spDataLarge)\nlibrary(terra)\n\n# Read the raster file\nnlcd_raster &lt;- rast(system.file(\"raster/nlcd.tif\", package = \"spDataLarge\"))\n\n# Check the coordinate reference system (CRS)\nnlcd_crs &lt;- crs(nlcd_raster)\nnlcd_crs |&gt; str_view()\n\n[1] │ PROJCRS[\"NAD83 / UTM zone 12N\",\n    │     BASEGEOGCRS[\"NAD83\",\n    │         DATUM[\"North American Datum 1983\",\n    │             ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n    │                 LENGTHUNIT[\"metre\",1]]],\n    │         PRIMEM[\"Greenwich\",0,\n    │             ANGLEUNIT[\"degree\",0.0174532925199433]],\n    │         ID[\"EPSG\",4269]],\n    │     CONVERSION[\"UTM zone 12N\",\n    │         METHOD[\"Transverse Mercator\",\n    │             ID[\"EPSG\",9807]],\n    │         PARAMETER[\"Latitude of natural origin\",0,\n    │             ANGLEUNIT[\"degree\",0.0174532925199433],\n    │             ID[\"EPSG\",8801]],\n    │         PARAMETER[\"Longitude of natural origin\",-111,\n    │             ANGLEUNIT[\"degree\",0.0174532925199433],\n    │             ID[\"EPSG\",8802]],\n    │         PARAMETER[\"Scale factor at natural origin\",0.9996,\n    │             SCALEUNIT[\"unity\",1],\n    │             ID[\"EPSG\",8805]],\n    │         PARAMETER[\"False easting\",500000,\n    │             LENGTHUNIT[\"metre\",1],\n    │             ID[\"EPSG\",8806]],\n    │         PARAMETER[\"False northing\",0,\n    │             LENGTHUNIT[\"metre\",1],\n    │             ID[\"EPSG\",8807]]],\n    │     CS[Cartesian,2],\n    │         AXIS[\"(E)\",east,\n    │             ORDER[1],\n    │             LENGTHUNIT[\"metre\",1]],\n    │         AXIS[\"(N)\",north,\n    │             ORDER[2],\n    │             LENGTHUNIT[\"metre\",1]],\n    │     USAGE[\n    │         SCOPE[\"Engineering survey, topographic mapping.\"],\n    │         AREA[\"North America - between 114°W and 108°W - onshore and offshore. Canada - Alberta; Northwest Territories; Nunavut; Saskatchewan. United States (USA) - Arizona; Colorado; Idaho; Montana; New Mexico; Utah; Wyoming.\"],\n    │         BBOX[31.33,-114,84,-108]],\n    │     ID[\"EPSG\",26912]]\n\n\nUnderstanding the CRS Information: —\nThe output from the crs(nlcd_raster) command will typically include details such as:\n\nProjection Type: Indicates whether the CRS is geographic (latitude and longitude) or projected (a flat representation). Here, it is North American NAD83 / UTM Zone 12 N\nDatum: Information about the geodetic datum used, which is crucial for accurately locating points on the Earth’s surface. Here, it is North American Datum 1983.\nCoordinate Units: Specifies the units of measurement used for the coordinates, such as degrees (for geographic CRSs) or meters (for projected CRSs). Here, it is in metres, as shown in:\nLENGTHUNIT[\"metre\",1]\nEPSG Code: If applicable, the output might include an EPSG code, which is a standardized reference number for a specific CRS. This code can be used to look up more detailed information about the CRS. Here, it is: —\nID[\"EPSG\",26912]\nTransformation Parameters: If it’s a projected CRS, the output may include parameters related to the projection method, such as central meridian, standard parallels, and false easting/northing. Here, they are: —\n|         PRIMEM[\"Greenwich\",0,     \n│             ANGLEUNIT[\"degree\",0.0174532925199433]],     \n│         ID[\"EPSG\",4269]], \n|\n|\n│     CONVERSION[\"UTM zone 12N\",     \n│         METHOD[\"Transverse Mercator\",     \n│             ID[\"EPSG\",9807]],     \n│         PARAMETER[\"Latitude of natural origin\",0,     \n│             ANGLEUNIT[\"degree\",0.0174532925199433],     \n│             ID[\"EPSG\",8801]],     \n│         PARAMETER[\"Longitude of natural origin\",-111,     \n|             ANGLEUNIT[\"degree\",0.0174532925199433],     \n│             ID[\"EPSG\",8802]],     \n│         PARAMETER[\"Scale factor at natural origin\",0.9996,\n│             SCALEUNIT[\"unity\",1],     \n│             ID[\"EPSG\",8805]],     \n│         PARAMETER[\"False easting\",500000,     \n│             LENGTHUNIT[\"metre\",1],     \n│             ID[\"EPSG\",8806]],     \n│         PARAMETER[\"False northing\",0,     \n│             LENGTHUNIT[\"metre\",1],     \n│             ID[\"EPSG\",8807]]],"
  },
  {
    "objectID": "geocomputation/chapter2.html#units",
    "href": "geocomputation/chapter2.html#units",
    "title": "Chapter 2: Geographic data in R",
    "section": "2.5 Units",
    "text": "2.5 Units\n\nCRSs include spatial units information, which is crucial for accurately interpreting distance and area.\nCartographic best practices suggest adding scale indicators on maps to show the relationship between map and ground distances.\nUnits in sf Objects:\n\nsf objects natively support units for geometric data, ensuring outputs from functions like st_area() come with a units attribute.\nThis feature, supported by the units package, avoids confusion across different CRSs, which may use meters, feet, etc.\nTo convert units, use units::set_units()\n\nUnits in Raster Data:\n\nUnlike sf, raster packages do not natively support units.\nUsers should be cautious when working with raster data to convert units properly.\nAn example to calculate the area of India in square meters and then, square kilometres\n\n\n\n# Load required libraries\nlibrary(sf)\nlibrary(units)\n\n# Calculate the area of India in square meters\nindia_area &lt;- rnaturalearth::ne_countries() |&gt; \n  filter(admin == \"India\") |&gt; \n  st_area()\nindia_area\n\n3.150428e+12 [m^2]\n\n# Convert area to square kilometers\nprint(paste(\"Area of India in square kilometers:\", format(set_units(india_area, km^2))))\n\n[1] \"Area of India in square kilometers: 3150428 [km^2]\"\n\n# Convert area to hectares\nprint(paste(\"Area of India in hectares:\", format(set_units(india_area, ha))))\n\n[1] \"Area of India in hectares: 315042827 [ha]\"\n\n# Convert area to acres\nprint(paste(\"Area of India in acres:\", format(set_units(india_area, acre))))\n\n[1] \"Area of India in acres: 778484666 [acre]\""
  },
  {
    "objectID": "geocomputation/chapter3.html",
    "href": "geocomputation/chapter3.html",
    "title": "Chapter 3: Attribute data operations",
    "section": "",
    "text": "sf for vector data manipulation (link)\nterra for raster data manipulation (link)\ndplyr for data frame operations (link)\nspData for example datasets (link)"
  },
  {
    "objectID": "geocomputation/chapter3.html#introduction",
    "href": "geocomputation/chapter3.html#introduction",
    "title": "Chapter 3: Attribute data operations",
    "section": "3.1 Introduction",
    "text": "3.1 Introduction\n\nAttribute Data: Non-spatial info tied to geographic data (e.g., bus stop name or elevation).\n\nVector Example: A bus stop’s location as POINT (-0.098 51.495) with attributes like its name.\nRaster Example: Pixel values represent attributes (e.g., elevation); location defined by matrix indices and resolution.\n\nChapter Focus:\n\nManipulating geographic objects using attributes (e.g., names, elevations).\nTechniques: subsetting, aggregation, joining data, creating new variables.\nVector and raster data operations are similar and interchangeable (e.g., subsetting, spatial joins).\n\n\n\n\nCode\nlibrary(sf)        # Handling Simple Features in R\nlibrary(terra)     # Handling Rasters in R\nlibrary(tidyverse) # Data Wrangling\n\nlibrary(spData)    # Spatial Data-sets"
  },
  {
    "objectID": "geocomputation/chapter3.html#vector-attribute-manipulation",
    "href": "geocomputation/chapter3.html#vector-attribute-manipulation",
    "title": "Chapter 3: Attribute data operations",
    "section": "3.2 Vector Attribute Manipulation",
    "text": "3.2 Vector Attribute Manipulation\n\nsf Package:\n\nExtends base R’s data.frame with a geometry column (sfc class) for spatial features (points, lines, polygons).\nGeometry column often named geometry or geom, but customizable.\n\nManipulation Methods:\n\n\nCode\nmethods(class = \"sf\") |&gt; \n  as_tibble() |&gt;\n  rename(methods = x) |&gt; \n  mutate(methods = str_replace_all(methods, \",sf\", \"  \")) |&gt; \n  mutate(methods = str_replace_all(methods, \".sf\", \"  \")) |&gt; \n  gt::gt() |&gt; \n  gt::tab_header(\n    title = \"Methods available\"\n  ) |&gt; \n  gt::opt_interactive()\n\n\n\n\nTable 1: Methods available for the class ‘sf’ in R using {sf} package\n\n\n\n\n\n\nMethods available\n\n\n\n\n\n\n\n\n\n\n\nMethods like aggregate(), cbind(), merge(), and rbind() work seamlessly with sf objects.\nCompatible with tidyverse functions (dplyr, tidyr) and can be used with data.table (partial compatibility noted in issue #2273).\nDropping geometry (st_drop_geometry()) can speed up attribute data operations when spatial data is not required.\n\n\n# Original 'world' dataset\ndim(world)\n## [1] 177  11\nclass(world)\n## [1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n# Dropping the geometry column: Effects\nst_drop_geometry(world) |&gt; \n  dim()\n## [1] 177  10\nst_drop_geometry(world) |&gt; \n  class()\n## [1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\nAdvantages:\n\nsf’s integration with the tidyverse allows robust, efficient data manipulation.\nCompatible with tidyverse functions (e.g., dplyr), making it versatile for data analysis.\n\n\n\n\n\n\n\n\nRelevant Topic\n\n\n\nMajor Pitfalls of Using Spatial Data with the Tidyverse\n\nName Clashes\n\nFunctions like select() from dplyr can mask similar functions from the raster package.\nUse fully qualified names (e.g., dplyr::select()) to avoid conflicts.\n\nCompatibility Issues with sp Package\n\nThe older sp package does not integrate well with tidyverse functions.\nRequires conversion between sp to sf object types using functions like st_as_sf().\n\nHandling Multipolygon Objects\n\nMultiple geometries in objects can cause unexpected plotting results.\nResolve issues by casting to simpler geometry types using st_cast(to = \"POLYGON\").\n\nSpatial Subsetting Challenges\n\nVerbose syntax when using tidyverse functions like filter() with spatial predicates like st_intersects().\nMay result in altered row names, complicating joins and comparisons.\nOther option is spatial subsetting using base R\n\nlnd_buff = lnd[1, ] %&gt;% \n  st_transform(crs = 27700) %&gt;%  # uk CRS\n  st_buffer(500000) %&gt;%\n  st_transform(crs = 4326)\nnear_lnd = world[lnd_buff, ]\nworld_poly = world %&gt;% \n  st_cast(to = \"POLYGON\")\nnear_lnd_new = world_poly[lnd_buff, ]\nnear_lnd_tidy = world %&gt;% \n  filter(st_intersects(., lnd_buff, sparse = FALSE))\n\n\nRow Name Alterations\n\nTidyverse operations may drop or alter row names, affecting joins and comparisons. See related discussion in tidyverse/dplyr#366.\n\nAttribute Alteration Pitfall\n\nResults from tidyverse functions may differ from base R operations due to row name discrepancies.\nExample functions: filter() vs base R subsetting ([]).\n\nIssues with bind_rows()\n\nbind_rows() fails on spatial objects; use alternatives like setting geometries to NULL with st_set_geometry() before combining.\n\nLimited Raster Data Support\n\nTidyverse integration with raster data is minimal.\nInitial efforts like tabularaster, sfraster, and stars aim to enhance support.\n\n\n\n\n\n3.2.1 Vector Attribute Sub-setting\n\nBase R Sub-setting:\n\nUses [ operator and subset() function for rows and columns selection.\nSyntax: object[i, j] returns rows indexed by i and columns by j.\n\ndplyr Sub-setting Functions:\n\nfilter() and slice() for rows, select() for columns.\nselect(): Subsets columns by name or position.\nHelper functions in select() like contains(), starts_with(), num_range().\n\nExtracting a Single Column:\n\nUse pull() (dplyr), $, or [[ (base R).\n\nRow Selection:\n\nslice(): Selects rows by index.\nfilter(): Filters rows based on conditions.\n\nComparison Operators:\n\nStandard operators can be used in filter(): &lt;, &gt;, &lt;=, &gt;=, ==, !=.\n\n\nThe dplyr functions (filter(), select(), pull()) are intuitive and integrate well with the tidyverse workflows.\n\n\n3.2.2 Chaining Commands with Pipes\n\nPipe Operator:\n\n%&gt;% (from the magrittr package) and native |&gt; (from R 4.1.0 onwards) enable chaining commands, improving readability and flow of code.\nThe output of one function becomes the input of the next.\nAlternative: Nested Function Calls: The same operation without pipes uses nested functions, which is harder to read.\n\nSplitting into Multiple Lines:\n\nUseful for debugging and inspecting intermediate results but can clutter the environment.\n\nKey Packages:\n\ndplyr: Provides verbs like filter(), select(), slice(), and supports pipe workflows.\nmagrittr: Provides %&gt;% operator for chaining functions.\n\n\n\n\n3.2.3 Vector Attribute Aggregation\n\nAggregation is summarizing data using one or more grouping variables, often leading to a smaller dataset. It is useful for data reduction, especially when working with large datasets.\nBase R Approach\n\nUsing aggregate():\n\naggregate() groups data and applies a function (e.g., sum). Result: A non-spatial data frame with two columns (continent, pop).\n\nUsing aggregate.sf():\n\nFor spatial objects (sf), use aggregate() with by argument. This results in an sf object with eight features representing continents.\n\n\ndplyr Approach\n\nUsing group_by() and summarize():\n\nEquivalent to aggregate(), but offers flexibility and control:\n\ngroup_by() defines grouping variables.\nsummarize() applies aggregation functions.\n\n\n\n\n\n\nCode\nlibrary(dplyr)\nworld |&gt;\n  group_by(continent) |&gt;\n  summarize(pop = sum(pop, na.rm = TRUE))\n\n\nSimple feature collection with 8 features and 2 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: -180 ymin: -89.9 xmax: 180 ymax: 83.64513\nGeodetic CRS:  WGS 84\n# A tibble: 8 × 3\n  continent                      pop                                        geom\n  &lt;chr&gt;                        &lt;dbl&gt;                              &lt;GEOMETRY [°]&gt;\n1 Africa                  1154946633 MULTIPOLYGON (((36.86623 22, 36.69069 22.2…\n2 Antarctica                       0 MULTIPOLYGON (((-180 -89.9, 180 -89.9, 180…\n3 Asia                    4311408059 MULTIPOLYGON (((36.14976 35.82153, 35.9050…\n4 Europe                   669036256 MULTIPOLYGON (((26.29 35.29999, 25.74502 3…\n5 North America            565028684 MULTIPOLYGON (((-82.26815 23.18861, -82.51…\n6 Oceania                   37757833 MULTIPOLYGON (((166.7932 -15.66881, 167.00…\n7 Seven seas (open ocean)          0 POLYGON ((68.935 -48.625, 68.8675 -48.83, …\n8 South America            412060811 MULTIPOLYGON (((-66.95992 -54.89681, -66.4…\n\n\n\nMore details on grouped data and summarize() from the dplyr package vignettes.\n\n\n\n\n\n\n\nRelevant Topic\n\n\n\ndplyr functions are highly effective when applied to grouped data frames (grouped_df objects). Here are the main points covered:\n\nGrouping Data: Use group_by() to create groups within a data frame based on one or more variables.\n\nTo count rows in each group, use tally().\n\nAccessing Group Metadata:\n\ngroup_keys(): Shows underlying group data. Details here.\ngroup_vars(): Retrieves names of the grouping variables. Details here.\n\nModifying Groups:\n\nTo overwrite or add grouping variables, use .add = TRUE with group_by(). Read more.\nTo remove groups, use ungroup().\n\nVerbs and Grouping:\n\nsummarise(): Computes summary statistics per group. The .groups argument controls grouping structure. More on summarise().\n\nColumn Manipulation:\n\nselect() retains grouping variables by default. More on select().\nrename() and relocate() function the same way for grouped and ungrouped data. Details here.\n\nSorting Groups:\n\narrange(): Sorts data, with .by_group = TRUE option to sort within groups. More on arrange().\n\n\n\n\n\nCheck out Chapter 5 of R for Data Science.\n\n\n\n3.2.4 Vector Attribute Joining\n\nJoining involves combining tables based on a shared key variable. In R, dplyr functions like left_join() and inner_join() are commonly used for this purpose.\n\nThe join functions in dplyr (left_join, inner_join, etc.) follow conventions from SQL, allowing easy and consistent data merging.\nThese functions work similarly for both non-spatial (data.frame) and spatial (sf) objects. The geometry list column in sf objects is the key difference.\n\nWhen merging an sf object with a data.frame\n\nThe resulting object remains an sf object, keeping its spatial features intact while adding new columns for coffee production.\n\nHandling Key Variables:\n\nIf datasets have key variables with matching names (e.g., name_long), joining works automatically.\nIf the key variables differ, either:\n\nRename the variable to match, or\nUse the by argument to specify the joining variables explicitly.\n\n\nInner Joins:\n\nAn inner join keeps only the rows with matching key variables in both datasets. This reduces the number of rows, depending on the overlap in key variables.\n\nTroubleshooting Joins:\n\nIf some rows are missing in the result (e.g., due to differing key names like “Congo, Dem. Rep. of”), identify mismatches using setdiff().\nUse regex matching from the stringr package to identify correct key names for adjustments.\n\nReversing Joins:\n\nYou can also join starting with a non-spatial dataset and adding spatial variables from an sf object.\nThe result will be a non-spatial data.frame (tibble), unless explicitly converted to an sf object using st_as_sf().\n\nFurther Resources:\n\nChapter 13 on Relational Data in R for Data Science by Grolemund and Wickham (2016)\nThe documentation describing joins with data.table package.\nThe join vignette in the geocompkg package, which is summarized below: —\n\n\n\n\n\n\n\n\nRelevant Topic\n\n\n\nSpatial Joins Extended\n\nSpatial Joins: Combines attributes from different datasets based on a common key, useful for integrating non-spatial (attribute) data with spatial data.\n\n\nLeft Join\n\nAdds attributes to all observations from the left dataset with matched values from the right.\n\n\n\nJoining by Different Column Names\n\nCase: If key columns have different names, use a named vector to specify the keys\nIssue: Duplicate columns (e.g., tbl_1_var.x and tbl_2_var.y). Resolved by specifying all keys.\n\n\n\nJoining with a Non-Spatial First Argument\n\nDropping Geometry: st_drop_geometry() removes spatial attributes, allowing joins with standard data frames.\n\n\n\nInner Join\n\nKeeps only rows with matching keys in both datasets.\n\n\n\n\n\n\n3.2.5 Creating attributes and removing spatial information\n\nCreating new attributes:\n\nCalculate a new attribute using mutate() from dplyr. Example: population / area.\nUse mutate() to add the new column without overwriting the geometry column.\n\nCombining columns:\n\nUse unite() from tidyr to merge two or more columns into one (e.g., continent and region_un).\nunite() allows setting a separator (e.g., :) and can optionally remove the original columns.\n\nSplitting columns:\n\nUse separate_wider_position() and separate_wider_delim()from tidyr to split a combined column back into its original components.\n\nRenaming columns:\n\nUse rename() from dplyr for renaming specific columns.\nFor renaming all columns, use setNames() with a character vector for new names.\n\nRemoving geometry:\n\nUse st_drop_geometry() to drop the spatial information while retaining the attributes in a non-spatial data.frame. This method is preferred over manually selecting non-geometry columns as it avoids unintended issues."
  },
  {
    "objectID": "geocomputation/chapter3.html#manipulating-raster-objects",
    "href": "geocomputation/chapter3.html#manipulating-raster-objects",
    "title": "Chapter 3: Attribute data operations",
    "section": "3.3 Manipulating Raster Objects",
    "text": "3.3 Manipulating Raster Objects\n\nRaster Data Model:\n\nRepresents continuous surfaces, unlike vector data which use discrete entities (points, lines, polygons).\nUseful for representing spatial phenomena like elevation, temperature, and land cover.\n\nCreating a Raster Object:\n\nUse rast() function to create raster objects.\nThe vals argument assigns numeric values to each cell.\n\nCategorical Raster Values:\n\nCan hold logical or factor (categorical) values.\nExample: Creating a raster for soil types (clay, silt, sand).\n\nRaster Attribute Table (RAT):\n\nStores additional information about raster values, accessible with cats().\nEach layer’s attribute data can be modified with levels().\n\nColor Table:\n\nCategorical rasters can store color information using a color table with RGB (Red, Green, Blue) or RGBA (Red, Green, Blue, Alpha) columns.\nUse coltab() to view or set color tables.\nSaving the raster (e.g., as GeoTIFF) includes the color table information.\n\n\n\n3.3.1 Raster subsetting\n\nRaster Subsetting:\n\nInvolves selecting specific parts of a raster dataset using the base R subsetting operator [ , ].\nSubsetting Methods:\n\nRow-Column Indexing: Accesses cells using specific row and column coordinates.\nCell IDs: Accesses cells using unique numeric identifiers for each raster cell.\nCoordinates and Spatial Objects: These methods are used for spatial subsetting, using another spatial object to subset a raster.\n\n\nExamples:\n\nAccessing the top-left pixel value using row-column indexing:\n\n\n\n\nCode\n# A simple raster\n  elev &lt;- rast(\n    nrows = 10, ncols = 10,\n    xmin = -1.5, xmax = 1.5, ymin = -1.5, ymax = 1.5,\n    vals = 1:100\n    ) \n\n# A raster with categorical levels\ngrain &lt;- rast(\n  nrows = 10, ncols = 10,\n  xmin = -1.5, xmax = 1.5, ymin = -1.5, ymax = 1.5,\n  vals = sample(\n    x = c(\"Wheat\", \"Rice\", \"Maize\", \"Others\"),\n    size = 100,\n    replace = TRUE\n  )\n)\n\n    # Print the \"elev\" object to visualize the design\n    print(elev)\n## class       : SpatRaster \n## dimensions  : 10, 10, 1  (nrow, ncol, nlyr)\n## resolution  : 0.3, 0.3  (x, y)\n## extent      : -1.5, 1.5, -1.5, 1.5  (xmin, xmax, ymin, ymax)\n## coord. ref. : lon/lat WGS 84 (CRS84) (OGC:CRS84) \n## source(s)   : memory\n## name        : lyr.1 \n## min value   :     1 \n## max value   :   100\n\n    # Plot the raster object to visualize the matrix as an image\n    plot(\n      elev, \n      main = \"Raster Object with a Sequential Pattern\"\n    )\n\n\n\n\n\n\n\n\n\nCode\n\n    # Accessing using row number and column number\n    elev[1, 1]\n##   lyr.1\n## 1     1\n\n    elev[10,5]\n##   lyr.1\n## 1    95\n\n    plot(\n      grain,\n      main = \"Raster Object with 4 categorical levels\"\n    )\n\n\n\n\n\n\n\n\n\nCode\n\n    # Accessing using row number and column number\n\n    grain[1,1]\n##   lyr.1\n## 1 Wheat\n\n    grain[10, 10]\n##   lyr.1\n## 1  Rice\n\n    # A multilayered raster - combining both\n    two_layers &lt;- c(elev, grain)\n\n    print(two_layers)\n## class       : SpatRaster \n## dimensions  : 10, 10, 2  (nrow, ncol, nlyr)\n## resolution  : 0.3, 0.3  (x, y)\n## extent      : -1.5, 1.5, -1.5, 1.5  (xmin, xmax, ymin, ymax)\n## coord. ref. : lon/lat WGS 84 (CRS84) (OGC:CRS84) \n## source(s)   : memory\n## names       : lyr.1, lyr.1 \n## min values  :     1, Maize \n## max values  :   100, Wheat\n    names(two_layers) &lt;- c(\"Continuous variable\", \n                           \"Categorical variable\")\n    plot(\n      two_layers\n    )\n\n\n\n\n\n\n\n\n\n\nAccessing the first cell using its Cell ID:\n\n\n\nCode\n# Accessing raster values using cell ID\nelev[1]\n##   lyr.1\n## 1     1\nelev[95]\n##   lyr.1\n## 1    95\n\n\n\nSubsetting Multi-layered Rasters:\n\nFor multi-layer raster objects (e.g., two_layers = c(grain, elev)), subsetting returns values from each layer:\n\n\n\ntwo_layers[1]\n\n  Continuous variable Categorical variable\n1                   1                Wheat\n\n\n\nTo extract all cell values from a raster:\n\n\n# Extracting all values - single layer raster\nelev[][1:10]  \n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n# It is Equivalent to using the values() function\nvalues(elev)[1:10]\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n# Extracting all values - multi-layer raster\n# It returns a data.frame\nvalues(two_layers) |&gt; \n  as_tibble()\n\n# A tibble: 100 × 2\n   `Continuous variable` `Categorical variable`\n                   &lt;int&gt;                  &lt;int&gt;\n 1                     1                      4\n 2                     2                      1\n 3                     3                      3\n 4                     4                      2\n 5                     5                      2\n 6                     6                      2\n 7                     7                      4\n 8                     8                      3\n 9                     9                      2\n10                    10                      3\n# ℹ 90 more rows\n\n\n\nModifying Raster Values:\n\nChange specific cell values by combining subsetting with assignment:\n\n\n\nelev[5, 5] = 0  # Sets the value of the 1 central cells to 0\n\nplot(elev)\n\n\n\n\n\n\n\n\n\nModify multiple cells simultaneously:\n\n\nelev[5, c(5,6)] = 0  # Sets the value of the central 2 cells to 0\n\nplot(elev)\n\n\n\n\n\n\n\n\n\nReplacing Values in Multi-layered Rasters:\n\nModify cell values in a multi-layer raster using a matrix with corresponding layers and cell indices:\n\n\n\n# Assigns new values for Cell ID 1 in both layers\ntwo_layers[45] = cbind(c(1), c(4))  \n\nplot(two_layers)\n\n\n\n\n\n\n\n\nThis subsetting approach allows efficient extraction and manipulation of raster cell values, enabling the customization of raster datasets for specific analytical needs.\n\n\n3.3.2 Summarizing Raster Objects\n\nDescriptive Statistics:\n\nThe terra package provides functions for summarizing raster objects.\nPrinting a raster object directly shows the minimum and maximum values.\nThe summary() function provides detailed statistics:\n\nFor continuous rasters: Minimum, maximum, quartiles, and count of NAs.\nFor categorical rasters: Counts of each unique class.\n\n\n\n\nsummary(two_layers)\n##  Continuous.variable Categorical.variable\n##  Min.   :  1.00      Maize :18           \n##  1st Qu.: 24.75      Others:32           \n##  Median : 50.50      Rice  :22           \n##  Mean   : 50.06      Wheat :28           \n##  3rd Qu.: 75.25                          \n##  Max.   :100.00\n\n\nCustom Summary Statistics:\n\nThe global() function calculates additional statistics like standard deviation and can be used to apply custom summary statistics.\n\n\n\nglobal(two_layers, sum)\n\n                      sum\nContinuous variable  5006\nCategorical variable  260\n\nglobal(two_layers, mean)\n\n                      mean\nContinuous variable  50.06\nCategorical variable  2.60\n\n\n\nFrequency Table:\n\nThe freq() function generates a frequency table for categorical raster values, showing counts of each category.\n\n\n\n\nCode\nfreq(two_layers$`Categorical variable`) |&gt; \n  gt::gt() |&gt; \n  gtExtras::gt_theme_538()\n\n\n\n\nTable 2: Frequency table using freq() on raster objects\n\n\n\n\n\n\n\n\n\nlayer\nvalue\ncount\n\n\n\n\n1\nMaize\n18\n\n\n1\nOthers\n32\n\n\n1\nRice\n22\n\n\n1\nWheat\n28\n\n\n\n\n\n\n\n\n\n\n\nVisualization of Raster Statistics:\n\nSeveral functions like hist(), boxplot(), and density() work directly with raster objects to visualize statistics.\nIf visualization functions do not support raster objects, values can be extracted using values() for further plotting.\n\nHandling Function Name Clashes:\n\nSome functions (e.g., extract()) exist in multiple packages like terra and tidyr, leading to conflicts.\nTo avoid issues, call functions with full namespaces (e.g., tidyr::extract()).\n\nUse detach() to unload conflicting packages, but be cautious as it may impact dependent packages."
  },
  {
    "objectID": "geocomputation/chapter3.html#exercises",
    "href": "geocomputation/chapter3.html#exercises",
    "title": "Chapter 3: Attribute data operations",
    "section": "3.4 Exercises",
    "text": "3.4 Exercises\n\nlibrary(sf)\nlibrary(dplyr)\nlibrary(terra)\nlibrary(spData)\ndata(us_states)\ndata(us_states_df)\n\n\nE1\nCreate a new object called us_states_name that contains only the NAME column from the us_states object using either base R ([) or tidyverse (select()) syntax. What is the class of the new object and what makes it geographic?\n\nus_states_name &lt;- us_states |&gt; \n  select(NAME)\n\nclass(us_states_name)\n\n[1] \"sf\"         \"data.frame\"\n\n\nThe new object of the class sf, and the stickiness of the geometry column makes it a geographical dataset.\n\n\n\nE2\nSelect columns from the us_states object which contain population data. Obtain the same result using a different command (bonus: try to find three ways of obtaining the same result). Hint: try to use helper functions, such as contains or matches from dplyr (see ?contains).\n\nus_states |&gt; \n  select(contains(\"pop\"))\n\nus_states |&gt; \n  select(where(is.double)) |&gt; \n  select(-AREA)\n\nus_states |&gt; \n  select(5:6)\n\nThe above three methods all select the columns total_pop_10 and total_pop_15 . Notice that the column geometry is sticky, and can be removed using st_drop_geometry().\n\n\n\nE3\nFind all states with the following characteristics (bonus: find and plot them):\n\nBelong to the Midwest region.\nThe code shown below gives out the names of all such states.\n\n\nus_states |&gt; \n  filter(REGION == \"Midwest\") |&gt; \n  pull(NAME) |&gt; \n  paste(collapse = \", \")\n\n[1] \"Indiana, Kansas, Minnesota, Missouri, North Dakota, South Dakota, Illinois, Iowa, Michigan, Nebraska, Ohio, Wisconsin\"\n\n\n\nBelong to the West region, have an area below 250,000 km2and in 2015 a population greater than 5,000,000 residents (hint: you may need to use the function units::set_units() or as.numeric()).\nOnly Washington State qualifies all three conditions. Code is shown below.\n\n\nus_states |&gt; \n  filter(REGION == \"West\") |&gt; \n  filter(total_pop_15 &gt; 5e6) |&gt; \n  filter(as.numeric(AREA) &lt; 250000)\n\nSimple feature collection with 1 feature and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -124.7042 ymin: 45.54774 xmax: -116.916 ymax: 49.00236\nGeodetic CRS:  NAD83\n  GEOID       NAME REGION          AREA total_pop_10 total_pop_15\n1    53 Washington   West 175436 [km^2]      6561297      6985464\n                        geometry\n1 MULTIPOLYGON (((-122.7699 4...\n\nus_states |&gt; \n  filter(REGION == \"West\") |&gt; \n  filter(total_pop_15 &gt; 5e6) |&gt; \n  filter(AREA &lt; units::set_units(250000, \"km2\"))\n\nSimple feature collection with 1 feature and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -124.7042 ymin: 45.54774 xmax: -116.916 ymax: 49.00236\nGeodetic CRS:  NAD83\n  GEOID       NAME REGION          AREA total_pop_10 total_pop_15\n1    53 Washington   West 175436 [km^2]      6561297      6985464\n                        geometry\n1 MULTIPOLYGON (((-122.7699 4...\n\n\n\nBelong to the South region, had an area larger than 150,000 km2 and a total population in 2015 larger than 7,000,000 residents.\nThe states that fulfil these conditions are Florida, Georgia and Texas.\n\n\n\nCode\nus_states |&gt; \n  filter(REGION == \"South\") |&gt; \n  filter(AREA &gt; units::set_units(150000, \"km2\")) |&gt; \n  filter(total_pop_15 &gt; 7e6) |&gt; \n  pull(NAME)\n\n\n[1] \"Florida\" \"Georgia\" \"Texas\"  \n\n\n\n\n\nE4\nWhat was the total population in 2015 in the us_states dataset? What was the minimum and maximum total population in 2015?\nThe total population in the us_states dataset in the year 2015 was 314,375,347. The minimum total population in 2015 was 579,679 (Wyoming), and the maximum total population was 38,421,464 (California).\n\nus_states |&gt; \n  st_drop_geometry() |&gt; \n  as_tibble() |&gt; \n  summarise(\n    total_pop_15 = sum(total_pop_15)\n  )\n## # A tibble: 1 × 1\n##   total_pop_15\n##          &lt;dbl&gt;\n## 1    314375347\n\nus_states |&gt; \n  st_drop_geometry() |&gt; \n  slice_min(order_by = total_pop_15, n = 1)\n##   GEOID    NAME REGION            AREA total_pop_10 total_pop_15\n## 1    56 Wyoming   West 253309.6 [km^2]       545579       579679\n\nus_states |&gt; \n  st_drop_geometry() |&gt; \n  slice_max(order_by = total_pop_15, n = 1)\n##   GEOID       NAME REGION            AREA total_pop_10 total_pop_15\n## 1    06 California   West 409747.1 [km^2]     36637290     38421464\n\n\n\n\nE5\nHow many states are there in each region?\nThe number of states in each region are shown in Table 3 below.\n\n\nCode\nus_states |&gt; \n  st_drop_geometry() |&gt; \n  count(REGION, name = \"Number of States\") |&gt; \n  gt::gt() |&gt; \n  gtExtras::gt_theme_538()\n\n\n\n\nTable 3: Table showing number of states in each region.\n\n\n\n\n\n\n\n\n\nREGION\nNumber of States\n\n\n\n\nNorteast\n9\n\n\nMidwest\n12\n\n\nSouth\n17\n\n\nWest\n11\n\n\n\n\n\n\n\n\n\n\n\n\n\nE6\nWhat was the minimum and maximum total population in 2015 in each region? What was the total population in 2015 in each region?\nThe minimum and maximum total population in 2015 in each region is shown in Table 4 (a). The total population in each region in 2015 is shown in Table 4 (b).\n\n\nCode\nus_states |&gt; \n  as_tibble() |&gt; \n  group_by(REGION) |&gt; \n  slice_min(order_by = total_pop_15, n = 1) |&gt; \n  select(REGION, NAME, total_pop_15) |&gt; \n  ungroup() |&gt; \n  gt::gt() |&gt; \n  gt::fmt_number(\n    columns = total_pop_15,\n    decimals = 0\n  ) |&gt; \n  gt::cols_label_with(fn = snakecase::to_title_case) |&gt; \n  gtExtras::gt_theme_538()\nus_states |&gt; \n  as_tibble() |&gt; \n  group_by(REGION) |&gt; \n  summarise(\n    total_population_2015 = sum(total_pop_15)\n  ) |&gt; \n  select(REGION, total_population_2015) |&gt; \n  ungroup() |&gt; \n  gt::gt() |&gt; \n  gt::fmt_number(\n    columns = total_population_2015,\n    decimals = 0\n  ) |&gt; \n  gt::cols_label_with(fn = snakecase::to_title_case) |&gt; \n  gtExtras::gt_theme_538()\n\n\n\n\nTable 4: Region-wise total and minimum-maximum populations\n\n\n\n\n\n\n\n\n\n(a) Minimum and maximum populations, region-wise, in 2015\n\n\n\n\n\nRegion\nName\nTotal Pop 15\n\n\n\n\nNorteast\nVermont\n626,604\n\n\nMidwest\nNorth Dakota\n721,640\n\n\nSouth\nDistrict of Columbia\n647,484\n\n\nWest\nWyoming\n579,679\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Total population, region-wise, in 2015\n\n\n\n\n\nRegion\nTotal Population 2015\n\n\n\n\nNorteast\n55,989,520\n\n\nMidwest\n67,546,398\n\n\nSouth\n118,575,377\n\n\nWest\n72,264,052\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nE7\nAdd variables from us_states_df to us_states, and create a new object called us_states_stats. What function did you use and why? Which variable is the key in both datasets? What is the class of the new object?\nThe function we use to accomplish this task is left_join() and the key in both datasets are the state names, called NAME in us_states dataset, and state in us_states_df dataset.\nThe class of the new object depends on which object is used first on the left_join() function, if us_states (an sf object) is used first, the class of new object is sf . However, if the us_states_df (a data frame) is used first, the resulting object is a data.frame or tibble.\n\nus_states |&gt; \n  left_join(us_states_df, by = join_by(NAME == state)) |&gt; \n  class()\n## [1] \"sf\"         \"data.frame\"\n\nus_states_df |&gt; \n  left_join(us_states, by = join_by(state == NAME)) |&gt; \n  class()\n## [1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\n\n\nE8\nus_states_df has two more rows than us_states. How can you find them? (Hint: try to use the dplyr::anti_join() function.)\nThe two rows that more more in us_states_df are shown below: —\n\nus_states_df |&gt; \n  anti_join(us_states, by = join_by(state == NAME)) |&gt; \n  gt::gt() |&gt; \n  gtExtras::gt_theme_538() |&gt; \n  gt::cols_label_with(fn = snakecase::to_title_case)\n\n\n\nTable 5: The two extra rows in us_states_df\n\n\n\n\n\n\n\n\n\nState\nMedian Income 10\nMedian Income 15\nPoverty Level 10\nPoverty Level 15\n\n\n\n\nAlaska\n29509\n31455\n64245\n72957\n\n\nHawaii\n29945\n31051\n124627\n153944\n\n\n\n\n\n\n\n\n\n\n\n\n\nE9\nWhat was the population density in 2015 in each state? What was the population density in 2010 in each state?\nThe Table 6 shows the population density.\n\n\nCode\nus_states |&gt; \n  st_drop_geometry() |&gt; \n  as_tibble() |&gt; \n  mutate(\n    population_density_2010 = total_pop_10 / as.numeric(AREA),\n    population_density_2015 = total_pop_15 / as.numeric(AREA),\n    .keep = \"unused\"\n  ) |&gt; \n  select(-GEOID) |&gt; \n  gt::gt() |&gt; \n  gt::opt_interactive() |&gt; \n  gtExtras::gt_theme_espn() |&gt; \n  gt::fmt_number(\n    decimals = 1\n  ) |&gt; \n  gt::cols_label_with(fn = snakecase::to_title_case)\n\n\n\n\nTable 6: A table showing population density in 2010 and 2015 in each state\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nE10\nHow much has population density changed between 2010 and 2015 in each state? Calculate the change in percentages and map them.\nThe Table 7 shows how much the population density has changed between 2010 and 2015 in each state. The Figure 1 shows the percentage change in a map of the US.\n\n\nCode\nus_states |&gt; \n  st_drop_geometry() |&gt; \n  as_tibble() |&gt; \n  mutate(\n    population_density_2010 = total_pop_10 / as.numeric(AREA),\n    population_density_2015 = total_pop_15 / as.numeric(AREA),\n    change_in_density = (population_density_2015 - population_density_2010)/population_density_2010,\n    .keep = \"unused\"\n  ) |&gt; \n  select(-GEOID) |&gt; \n  gt::gt() |&gt; \n  gt::opt_interactive() |&gt; \n  gtExtras::gt_theme_espn() |&gt; \n  gt::fmt_number(\n    decimals = 1\n  ) |&gt; \n  gt::fmt_percent(\n    columns = change_in_density\n  ) |&gt; \n  gt::cols_label_with(fn = snakecase::to_title_case)\n\n\n\n\nTable 7: Table showing change in population density between 2010 and 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nus_states |&gt; \n  mutate(\n    population_density_2010 = total_pop_10 / as.numeric(AREA),\n    population_density_2015 = total_pop_15 / as.numeric(AREA),\n    change_in_density = (population_density_2015 - population_density_2010)/population_density_2010,\n    .keep = \"unused\"\n  ) |&gt; \n  ggplot() +\n  geom_sf(\n    mapping = aes(\n      fill = change_in_density\n    )\n  ) +\n  geom_sf_text(\n    mapping = aes(\n      label = paste0(\n        round(\n          change_in_density * 100,\n          1\n        ),\n        \"%\"\n      )\n    ),\n    size = 3\n  ) +\n  paletteer::scale_fill_paletteer_c(\n    \"ggthemes::Red-Green Diverging\",\n    labels = scales::label_percent(),\n    name = \"Change in population density between 2010 and 2015\",\n    limits = c(-0.05, 0.1)\n  ) +\n  ggthemes::theme_map() +\n  theme(\n    legend.position = \"bottom\",\n    legend.title.position = \"top\"\n  )\n\n\n\n\n\n\n\n\nFigure 1: Map of the change in population density\n\n\n\n\n\n\n\n\nE11\nChange the columns’ names in us_states to lowercase. (Hint: helper functions - tolower() and colnames() may help.)\nA very easy method is using the janitor package and the function clean_names()\n\n\nCode\nus_states |&gt; \n  janitor::clean_names() |&gt; \n  as_tibble() |&gt; \n  print(n = 5)\n\n\n# A tibble: 49 × 7\n  geoid name   region   area total_pop_10 total_pop_15                  geometry\n  &lt;chr&gt; &lt;chr&gt;  &lt;fct&gt;  [km^2]        &lt;dbl&gt;        &lt;dbl&gt;        &lt;MULTIPOLYGON [°]&gt;\n1 01    Alaba… South  1.34e5      4712651      4830620 (((-88.20006 34.99563, -…\n2 04    Arizo… West   2.95e5      6246816      6641928 (((-114.7196 32.71876, -…\n3 08    Color… West   2.70e5      4887061      5278906 (((-109.0501 41.00066, -…\n4 09    Conne… Norte… 1.30e4      3545837      3593222 (((-73.48731 42.04964, -…\n5 12    Flori… South  1.51e5     18511620     19645772 (((-81.81169 24.56874, -…\n# ℹ 44 more rows\n\n\n\n\n\nE12\nUsing us_states and us_states_df create a new object called us_states_sel. The new object should have only two variables: median_income_15 and geometry. Change the name of the median_income_15 column to Income.\nThe new object us_states_sel is created as shown below.\n\n\nCode\nus_states_sel &lt;- us_states |&gt; \n  left_join(us_states_df, by = join_by(NAME == state)) |&gt; \n  select(Income = median_income_15, geometry)\n\nus_states_sel\n\n\nSimple feature collection with 49 features and 1 field\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -124.7042 ymin: 24.55868 xmax: -66.9824 ymax: 49.38436\nGeodetic CRS:  NAD83\nFirst 10 features:\n   Income                       geometry\n1   22890 MULTIPOLYGON (((-88.20006 3...\n2   26156 MULTIPOLYGON (((-114.7196 3...\n3   30752 MULTIPOLYGON (((-109.0501 4...\n4   33226 MULTIPOLYGON (((-73.48731 4...\n5   24654 MULTIPOLYGON (((-81.81169 2...\n6   25588 MULTIPOLYGON (((-85.60516 3...\n7   23558 MULTIPOLYGON (((-116.916 45...\n8   25834 MULTIPOLYGON (((-87.52404 4...\n9   27315 MULTIPOLYGON (((-102.0517 4...\n10  24014 MULTIPOLYGON (((-92.01783 2...\n\n\n\n\n\nE13\nCalculate the change in the number of residents living below the poverty level between 2010 and 2015 for each state. (Hint: See ?us_states_df for documentation on the poverty level columns.) Bonus: Calculate the change in the percentage of residents living below the poverty level in each state.\nThe Table 8 shows the change in the number of residents living below the poverty level between 2010 and 2015 for each state.\n\n\nCode\nus_states_df |&gt; \n  mutate(\n    change_in_poverty = poverty_level_15 - poverty_level_10\n  ) |&gt; \n  select(state, change_in_poverty) |&gt; \n  gt::gt() |&gt; \n  gt::fmt_number(decimals = 0) |&gt; \n  gt::cols_label_with(fn = snakecase::to_title_case) |&gt; \n  gt::opt_interactive() \n\n\n\n\nTable 8: The change in the number of residents living below the poverty level between 2010 and 2015 for each state\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Table 9 shows the change in the percentage of residents living below the poverty level in each state.\n\n\nCode\nus_states |&gt; \n  st_drop_geometry() |&gt; \n  left_join(us_states_df, by = join_by(NAME == state)) |&gt; \n  as_tibble() |&gt; \n  mutate(\n    state = NAME,\n    poverty_2010 = poverty_level_10 / total_pop_10,\n    poverty_2015 = poverty_level_15 / total_pop_15,\n    change_in_poverty = poverty_2015 - poverty_2010,\n    .keep = \"none\"\n  ) |&gt; \n  gt::gt() |&gt; \n  gt::fmt_percent() |&gt; \n  gt::cols_label_with(fn = snakecase::to_title_case) |&gt; \n  gt::opt_interactive()\n\n\n\n\nTable 9: Table showing the change in the percentage of residents living below the poverty level in each state.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nE14\nWhat was the minimum, average and maximum state’s number of people living below the poverty line in 2015 for each region? Bonus: What is the region with the largest increase in people living below the poverty line?\nThe the minimum, average and maximum state’s number of people living below the poverty line in 2015 for each region are shown in Table 10 below.\n\n\nCode\nus_states |&gt; \n  st_drop_geometry() |&gt; \n  select(state = NAME, region = REGION) |&gt; \n  left_join(us_states_df) |&gt; \n  as_tibble() |&gt; \n  group_by(region) |&gt; \n  summarise(\n    minimum_poverty_2015 = min(poverty_level_15),\n    maximum_poverty_2015 = max(poverty_level_15),\n    average_poverty_2015 = mean(poverty_level_15)\n  ) |&gt; \n  gt::gt() |&gt; \n  gt::cols_label_with(fn = snakecase::to_title_case) |&gt; \n  gt::fmt_number(decimals = 0)\n\n\n\n\nTable 10: A table showing the minimum, average and maximum state’s number of people living below the poverty line in 2015 for each region\n\n\n\n\n\n\n\n\n\nRegion\nMinimum Poverty 2015\nMaximum Poverty 2015\nAverage Poverty 2015\n\n\n\n\nNorteast\n69,233\n3,005,943\n804,465\n\n\nMidwest\n79,758\n1,801,118\n799,155\n\n\nSouth\n108,315\n4,472,451\n1,147,575\n\n\nWest\n64,995\n6,135,142\n1,016,665\n\n\n\n\n\n\n\n\n\n\nAs evident in Table 11, the region with the largest increase in people living below the poverty line is the South Region.\n\n\nCode\nus_states |&gt; \n  st_drop_geometry() |&gt; \n  select(state = NAME, region = REGION) |&gt; \n  as_tibble() |&gt; \n  left_join(us_states_df) |&gt; \n  group_by(region) |&gt; \n  summarise(\n    change_total_poverty = sum(poverty_level_15) - sum(poverty_level_10)\n  ) |&gt; \n  arrange(desc(change_total_poverty)) |&gt; \n  gt::gt() |&gt; \n  gt::cols_label_with(fn = snakecase::to_title_case) |&gt; \n  gt::fmt_number(decimals = 0)\n\n\n\n\nTable 11: Table showing the region with the largest increase in people living below the poverty line\n\n\n\n\n\n\n\n\n\nRegion\nChange Total Poverty\n\n\n\n\nSouth\n2,718,396\n\n\nWest\n2,102,479\n\n\nMidwest\n1,095,133\n\n\nNorteast\n877,493\n\n\n\n\n\n\n\n\n\n\n\n\n\nE15\nCreate a raster from scratch, with nine rows and columns and a resolution of 0.5 decimal degrees (WGS84). Fill it with random numbers. Extract the values of the four corner cells.\n\n# Load the terra package\nlibrary(terra)\n\n# Create a raster with 9 rows and 9 columns, resolution of 0.5 degrees\nr &lt;- rast(nrows = 9, ncols = 9, \n          resolution = 0.5, \n          crs = \"EPSG:4326\")\n\n# Fill the raster with random numbers\nvalues(r) &lt;- runif(ncell(r))\n\n# Print the raster\nprint(r)\n## class       : SpatRaster \n## dimensions  : 360, 720, 1  (nrow, ncol, nlyr)\n## resolution  : 0.5, 0.5  (x, y)\n## extent      : -180, 180, -90, 90  (xmin, xmax, ymin, ymax)\n## coord. ref. : lon/lat WGS 84 (EPSG:4326) \n## source(s)   : memory\n## name        :        lyr.1 \n## min value   : 2.654269e-07 \n## max value   : 9.999946e-01\n\nplot(r)\n\n\n\n\n\n\n\n# Extract the values of the four corner cells\n# Top-left (1, 1), Top-right (1, 9), Bottom-left (9, 1), \n# # Bottom-right (9, 9)\n\nr[1,1]\n##       lyr.1\n## 1 0.3745735\nr[1,9]\n##       lyr.1\n## 1 0.7673042\nr[9,1]\n##       lyr.1\n## 1 0.1745812\nr[9,9]\n##       lyr.1\n## 1 0.8618642\n\n\n\n\nE16\nWhat is the most common class of our example raster grain?\n\n\nCode\ngrain_order &lt;-  c(\"clay\", \"silt\", \"sand\")\ngrain_char &lt;- sample(grain_order, 36, replace = TRUE)\ngrain_fact &lt;-  factor(grain_char, levels = grain_order)\ngrain &lt;-rast(nrows = 6, ncols = 6, \n             xmin = -1.5, xmax = 1.5, \n             ymin = -1.5, ymax = 1.5,\n             vals = grain_fact)\n\nanswer &lt;- freq(grain) |&gt; \n  arrange(desc(count))\n\ngt::gt(answer) |&gt; \n  gt::cols_label_with(fn = snakecase::to_title_case)\n\n\n\n\nTable 12: The count of different classes in the example raster grain.\n\n\n\n\n\n\n\n\n\nLayer\nValue\nCount\n\n\n\n\n1\nclay\n12\n\n\n1\nsilt\n12\n\n\n1\nsand\n12\n\n\n\n\n\n\n\n\n\n\nThe most common class is the clay .\n\n\n\nE17\nPlot the histogram and the boxplot of the dem.tif file from the spDataLarge package (system.file(\"raster/dem.tif\", package = \"spDataLarge\")).\nThe plots are shown in Figure 2\n\ntemp_rast &lt;- rast(system.file(\"raster/dem.tif\", package = \"spDataLarge\"))\n\nhist(temp_rast)\n\nboxplot(temp_rast)\n\n# Using ggplot2 methods\n\ntemp_rast |&gt; \n  values() |&gt; \n  as_tibble() |&gt; \n  ggplot(aes(dem)) +\n  geom_histogram(\n    fill = \"white\",\n    colour = \"grey20\"\n  )\n\ntemp_rast |&gt; \n  values() |&gt; \n  as_tibble() |&gt; \n  ggplot(aes(dem)) +\n  geom_boxplot(\n    fill = \"white\",\n    colour = \"grey20\",\n    staplewidth = 0.5\n  )\n\n\n\n\n\n\n\n\n\n\n(a) Histogram of the raster dem.tif using base R hist()\n\n\n\n\n\n\n\n\n\n\n\n(b) Boxplot of the raster dem.tif using base R boxplot()\n\n\n\n\n\n\n\n\n\n\n\n(c) Histogram of the values in raster dem.tif using ggplot2\n\n\n\n\n\n\n\n\n\n\n\n(d) Boxplot of the values in raster dem.tif using ggplot2\n\n\n\n\n\n\nFigure 2: Plots produced for question E17"
  },
  {
    "objectID": "geocomputation/chapter4.html",
    "href": "geocomputation/chapter4.html",
    "title": "Chapter 4: Spatial data operations",
    "section": "",
    "text": "library(sf)        # Simple Features in R\nlibrary(terra)     # Handling rasters in R\nlibrary(tidyterra) # For plotting rasters in ggplot2\nlibrary(tidyverse) # All things tidy; Data Wrangling\nlibrary(spData)    # Spatial Datasets\n\n\nsysfonts::font_add_google(\"Saira Extra Condensed\", \"caption_font\")\nsysfonts::font_add_google(\"Saira\", \"body_font\")\ntheme_set(theme_minimal(base_family = \"body_font\"))\nshowtext::showtext_auto()"
  },
  {
    "objectID": "geocomputation/chapter4.html#introduction-to-spatial-operations",
    "href": "geocomputation/chapter4.html#introduction-to-spatial-operations",
    "title": "Chapter 4: Spatial data operations",
    "section": "4.1 Introduction to Spatial Operations",
    "text": "4.1 Introduction to Spatial Operations\n\nSpatial Operations: Include spatial joins for vectors and local/focal operations for rasters, allowing modification based on location and shape.\n\nRelation to Non-Spatial Operations: Many spatial operations (e.g., subsetting, joining) have non-spatial counterparts.\n\nSpatial Joins: Can be done in multiple ways (e.g., intersect, within distance), unlike non-spatial joins (refer to fuzzyjoin package (Robinson 2020) for alternatives).\n\nTypes of Spatial Relationships: Includes operations like intersects and disjoint. Distance calculations explore spatial relationships.\n\nRaster Operations:\n\nSubsetting (Section 4.3.1)\nMap Algebra: Modifies raster cell values through local, focal, zonal, and global operations (Sections 4.3.3 to 4.3.6).\nMerging Rasters: Demonstrated with reproducible examples (Section 4.3.8).\n\nCoordinate Reference System (CRS): Consistency in CRS is essential for spatial operations.."
  },
  {
    "objectID": "geocomputation/chapter4.html#spatial-operations-on-vector-data",
    "href": "geocomputation/chapter4.html#spatial-operations-on-vector-data",
    "title": "Chapter 4: Spatial data operations",
    "section": "4.2 Spatial operations on vector data",
    "text": "4.2 Spatial operations on vector data\n\n4.2.1 Spatial Subsetting: use st_filter()\n\nSpatial subsetting extracts features from a spatial object (x) that relate spatially to another object (y).\nSyntax: Use the [ ] operator: x[y, , op = st_intersects].\n\nx: Target sf object.\ny: Subsetting sf object.\nop: Topological relation (default is st_intersects).\nsf package documentation\n\nDefault Operator: st_intersects() selects features intersecting with the subsetting object. Alternative operators like st_disjoint() can be used for different relations.\n\nExample: nz_height[canterbury, ] returns high points within Canterbury from the nz_height dataset in the spData package (spData documentation).\n\nTopological Relations: Include touches, crosses, and within. These determine spatial relationships between features in x and y.\nSparse Geometry Binary Predicate (sgbp):\n\nUsing st_intersects(), an sgbp list object is created.\nConvert sgbp to logical vector for subsetting using lengths({sgbp_object_name} &gt; 0)\nUsing sparse = FALSE argument in st_intersects() returns a dense matrix.\n\nTidyverse Alternative: st_filter() from the sf package simplifies spatial subsetting, increasing compatibility with dplyr.\nOutput Consistency: Subsets created using [ ], logical vectors, or st_filter() are equivalent in spatial operations.\n\n\n\nCode\ndata(\"nz\")\ndata(\"nz_height\")\n\nclass(nz)\n## [1] \"sf\"         \"data.frame\"\n\n# A plot for all regions and all peaks\nnz |&gt; \n  ggplot() +\n  geom_sf(fill = \"white\") +\n  ggrepel::geom_text_repel(\n    mapping = aes(\n      label = Name,\n      geometry = geom\n    ),\n    size = 4,\n    family = \"caption_font\",\n    stat = \"sf_coordinates\"\n  ) +\n  geom_sf(\n    data = nz_height,\n    pch = 2,\n    colour = \"red\",\n    size = 3\n  ) +\n  scale_fill_manual(\n    values = c(\"white\", \"pink\")\n  ) +\n  labs(\n    title = \"All peaks in New Zealand, and all regions.\"\n  ) +\n  theme_void() +\n  theme(\n    plot.background = element_rect(\n      fill = \"lightblue\",\n      colour = NA\n    ),\n    legend.position = \"none\"\n  )\n\n# Total peaks in New Zealand\nnz_height |&gt; dim()\n## [1] 101   3\n\n# Peaks within Canterbury in New Zealand\n\n# Base R Version\ncanterbury &lt;- nz |&gt; filter(Name == \"Canterbury\")\nnz_height[canterbury,] |&gt; dim()\n## [1] 70  3\n\n# Tidyverse Version\nnz_height |&gt;\n  st_filter(\n    nz |&gt; filter(Name == \"Canterbury\"),\n    .predicate = st_intersects\n  ) |&gt; \n  dim()\n## [1] 70  3\n\n# Getting the peaks which are inside Canterbury\ncanterbury_ids &lt;- nz_height |&gt;\n  st_filter(\n    nz |&gt; filter(Name == \"Canterbury\"),\n    .predicate = st_intersects\n  ) |&gt; \n  pull(t50_fid)\n\nnz_height |&gt; \n  mutate(in_canterbury = t50_fid %in% canterbury_ids) |&gt; \n  ggplot() +\n  \n  # Base NZ Map and Label for Canterbury\n  geom_sf(\n    data = nz,\n    mapping = aes(\n      fill = Name == \"Canterbury\"\n    )\n  ) +\n  geom_sf_text(\n    data = filter(nz, Name == \"Canterbury\"),\n    mapping = aes(\n      label = Name,\n      geometry = geom\n    ),\n    size = 4,\n    family = \"caption_font\"\n  ) +\n  \n  # Plotting the peaks, and colouring by presence in Canterbury\n  geom_sf(\n    mapping = aes(\n      colour = in_canterbury,\n      size = in_canterbury\n    ),\n    pch = 2\n  ) +\n  \n  scale_fill_manual(\n    values = c(\"white\", \"lightpink\")\n  ) +\n  scale_colour_manual(\n    values = c(\"black\", \"red\")\n  ) +\n  guides(\n    fill = \"none\"\n  ) +\n  labs(\n    colour = \"Peaks within Canterbury Region?\",\n    size = \"Peaks within Canterbury Region?\",\n    title = \"Highlighting Peaks within Canterbury region\"\n  ) +\n  theme_void() +\n  theme(\n    plot.background = element_rect(\n      fill = \"lightblue\"\n    ),\n    legend.position = \"bottom\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n(a) New Zealand Map with all the peaks\n\n\n\n\n\n\n\n\n\n\n\n(b) New Zealand Map focussing on peaks that intersect with Canterbury\n\n\n\n\n\n\nFigure 1: Spatial Subsetting and plotting with tidyverse and ggplot2 methods\n\n\n\n\nExample code for st_intersects() and st_disjoint() : these functions produce a sparse predicate list only. Hence, correct way to use them would be st_filter() with .predicate = &lt;function&gt; argument.\n\nnz_height |&gt; \n  st_intersects(\n    filter(nz, Name == \"Canterbury\")\n  )\n\nSparse geometry binary predicate list of length 101, where the\npredicate was `intersects'\nfirst 10 elements:\n 1: (empty)\n 2: (empty)\n 3: (empty)\n 4: (empty)\n 5: 1\n 6: 1\n 7: 1\n 8: 1\n 9: 1\n 10: 1\n\n# The 70 peaks within Canterbury region\nnz_height |&gt; \n  st_filter(\n    filter(nz, Name == \"Canterbury\"),\n    .predicate = st_intersects\n  )\n\nSimple feature collection with 70 features and 2 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 1365809 ymin: 5158491 xmax: 1654899 ymax: 5350463\nProjected CRS: NZGD2000 / New Zealand Transverse Mercator 2000\nFirst 10 features:\n   t50_fid elevation                geometry\n1  2362630      2749 POINT (1378170 5158491)\n2  2362814      2822 POINT (1389460 5168749)\n3  2362817      2778 POINT (1390166 5169466)\n4  2363991      3004 POINT (1372357 5172729)\n5  2363993      3114 POINT (1372062 5173236)\n6  2363994      2882 POINT (1372810 5173419)\n7  2363995      2796 POINT (1372579 5173989)\n8  2363997      3070 POINT (1373796 5174144)\n9  2363998      3061 POINT (1373955 5174231)\n10 2363999      3077 POINT (1373984 5175228)\n\n# The 31 peaks outside Canterbury Region\nnz_height |&gt; \n  st_filter(\n    filter(nz, Name == \"Canterbury\"),\n    .predicate = st_disjoint\n  )\n\nSimple feature collection with 31 features and 2 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 1204143 ymin: 5048309 xmax: 1822492 ymax: 5650492\nProjected CRS: NZGD2000 / New Zealand Transverse Mercator 2000\nFirst 10 features:\n   t50_fid elevation                geometry\n1  2353944      2723 POINT (1204143 5049971)\n2  2354404      2820 POINT (1234725 5048309)\n3  2354405      2830 POINT (1235915 5048745)\n4  2369113      3033 POINT (1259702 5076570)\n5  2363996      2759 POINT (1373264 5175442)\n6  2364028      2756 POINT (1374183 5177165)\n7  2364029      2800 POINT (1374469 5176966)\n8  2364031      2788 POINT (1375422 5177253)\n9  2364166      2782 POINT (1383006 5181085)\n10 2364167      2905 POINT (1383486 5181270)\n\n\n\n\n4.2.2 Topological Relations\n\nTopological relations describe spatial relationships between objects using logical TRUE or FALSE statements (Egenhofer and Herring, 1990).\nSymmetrical vs. non-symmetrical relations:\n\nSymmetrical relations (e.g., equals, intersects, crosses) yield the same result when order of input is swapped.\nNon-symmetrical relations (e.g., contains, within) depend on the order of input geometries.\n\nBinary predicates in sf package test spatial relationships between vector geometries. See vignette(“sf3”). The following binary predicates exist in sf : —\n\n\n\n\n\n\n\n\n\nFunction\nDescription\nSymmetrical?\n\n\n\n\nst_intersects\nChecks if geometries intersect.\nYes\n\n\nst_disjoint\nChecks if geometries do not intersect (are disjoint).\nYes\n\n\nst_touches\nChecks if geometries have at least one boundary point in common.\nYes\n\n\nst_crosses\nChecks if a geometry crosses another (e.g., a line crosses a polygon).\nYes\n\n\nst_overlaps\nChecks if geometries have some but not all interior points in common.\nYes\n\n\nst_equals\nChecks if geometries are topologically equal.\nYes\n\n\nst_within\nChecks if a geometry is completely contained within another.\nNo\n\n\nst_contains\nChecks if a geometry contains another completely.\nNo\n\n\nst_contains_properly\nChecks if a geometry contains another but not vice versa.\nNo\n\n\nst_covers\nChecks if a geometry covers another (includes boundary).\nNo\n\n\nst_covered_by\nChecks if a geometry is covered by another (includes boundary).\nNo\n\n\nst_equals_exact\nChecks if geometries are exactly equal within a given tolerance.\nYes\n\n\nst_is_within_distance\nChecks if geometries are within a specified distance from each other.\nYes\n\n\n\n\nSparse matrix output: Functions like st_intersects() use sparse matrices to save memory by only registering positive results; setting sparse = FALSE returns a dense matrix.\n\n\n\nCode\n# Create two polygons\n polygon1 &lt;- st_polygon(\n   list(matrix(c(0, 0, 1, 0, 1, 1, 0, 1, 0, 0),\n     ncol = 2,\n     byrow = TRUE\n   ))\n )\n\n polygon2 &lt;- st_polygon(\n   list(matrix(c(0.5, 0.5, 1.5, 0.5, 1.5, 1.5, 0.5, 1.5, 0.5, 0.5),\n     ncol = 2,\n     byrow = TRUE\n   ))\n )\n\n polygon3 &lt;- st_polygon(\n   list(matrix(c(0.2, 1.2,\n                 0.5, 1.2, \n                 0.5, 1.5, \n                 0.2, 1.5, \n                 0.2, 1.2),\n     ncol = 2,\n     byrow = TRUE\n   ))\n )\n\n polygon4 &lt;- st_polygon(\n   list(matrix(c(1.2, 0.2, \n                 1.5, 0.2, \n                 1.5, 0.4, \n                 1.2, 0.4, \n                 1.2, 0.2),\n     ncol = 2,\n     byrow = TRUE\n   ))\n )\n \n # Convert to sf objects\n sf_poly1 &lt;- st_sfc(polygon1, crs = 4326)\n sf_poly2 &lt;- st_sfc(polygon2, crs = 4326)\n sf_poly3 &lt;- st_sfc(polygon3, crs = 4326)\n sf_poly4 &lt;- st_sfc(polygon4, crs = 4326)\n \n # Create a collection of points\n points &lt;- st_sfc(\n   st_point(c(0.25, 0.25)),\n   st_point(c(0.75, 0.75)),\n   st_point(c(1.25, 1.25)),\n   crs = 4326\n )\n\n sf_points &lt;- tibble(\n   point = c(\"p1\", \"p2\", \"p3\"),\n   geometry = points\n ) |&gt;\n   st_as_sf() |&gt;\n   st_set_crs(4326)\n\n# Keeping environment clean\nrm(polygon1, polygon2, \n   polygon3, polygon4,\n   points)\n\n# Visualize the objects\nggplot() +\n  geom_sf(data = sf_poly1, \n          aes(fill = \"sf_poly1\"),\n          alpha = 0.5) +\n  geom_sf(data = sf_poly2, \n          aes(fill = \"sf_poly2\"),\n          alpha = 0.5) +\n  geom_sf(data = sf_poly3, \n          aes(fill = \"sf_poly3\"),\n          alpha = 0.5) +\n  geom_sf(data = sf_poly4, \n          aes(fill = \"sf_poly4\"),\n          alpha = 0.5) +\n  geom_sf(data = sf_points,\n          aes(fill = point),\n          pch = 21,\n          size = 4) +\n  labs(fill = NULL) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nFigure 2: Some example objects to demonstrate the topological relations\n\n\n\n\n\n\n#################### Symmetrical Relations ######################\n# The order in which sf objects are placed does not matter\n\n## st_intersects()----------------------------------------\nst_intersects(sf_poly1, sf_poly2, sparse = F) \n##      [,1]\n## [1,] TRUE\n\nst_intersects(sf_poly1, sf_points, sparse = F) \n##      [,1] [,2]  [,3]\n## [1,] TRUE TRUE FALSE\n\nst_intersects(sf_poly1, sf_poly3, sparse = F)\n##       [,1]\n## [1,] FALSE\n\nst_intersects(sf_poly2 ,sf_poly3, sparse = F) \n##      [,1]\n## [1,] TRUE\n\n\n# st_disjoint()------------------------------------------\nst_disjoint(sf_poly1, sf_poly4, sparse = F)\n##      [,1]\n## [1,] TRUE\n\nst_disjoint(sf_poly2, sf_poly3, sparse = F) \n##       [,1]\n## [1,] FALSE\n\n\n# st_touches()-------------------------------------------\nst_touches(sf_poly1, sf_poly2, sparse = F) \n##       [,1]\n## [1,] FALSE\n\nst_touches(sf_poly2, sf_poly3, sparse = F)\n##      [,1]\n## [1,] TRUE\n\nst_touches(sf_poly1, sf_points, sparse = F)\n##       [,1]  [,2]  [,3]\n## [1,] FALSE FALSE FALSE\n\n\n# st_crosses()-------------------------------------------\nst_crosses(sf_poly1, sf_poly2, sparse = F)\n##       [,1]\n## [1,] FALSE\n\nst_crosses(sf_poly1, sf_points, sparse = F)\n##       [,1]  [,2]  [,3]\n## [1,] FALSE FALSE FALSE\n\n# st_overlaps()\nst_overlaps(sf_poly1, sf_poly2, sparse = F)\n##      [,1]\n## [1,] TRUE\nst_overlaps(sf_poly1, sf_points, sparse = F)\n##       [,1]  [,2]  [,3]\n## [1,] FALSE FALSE FALSE\nst_overlaps(sf_poly3, sf_poly3, sparse = F)\n##       [,1]\n## [1,] FALSE\n\n\n# st_equals()-------------------------------------------\nst_equals(sf_poly1, sf_poly1, sparse = F)\n##      [,1]\n## [1,] TRUE\n\n\n\n# st_equals_exact()-------------------------------------\nst_equals_exact(sf_poly1, sf_poly2, par = 0.1, sparse = F)\n##       [,1]\n## [1,] FALSE\nst_equals_exact(sf_poly1, sf_poly2, par = 1, sparse = F)\n##      [,1]\n## [1,] TRUE\n\n\n# st_is_within_distance()-------------------------------\nst_is_within_distance(sf_poly1, sf_poly2, dist = 0.1, sparse = F)\n##      [,1]\n## [1,] TRUE\nst_is_within_distance(sf_poly2, sf_poly3, dist = 0.1, sparse = F)\n##      [,1]\n## [1,] TRUE\nst_is_within_distance(sf_poly3, sf_poly4, dist = 0.1, sparse = F)\n##       [,1]\n## [1,] FALSE\nst_is_within_distance(sf_poly3, sf_poly4, dist = 13, sparse = F)\n##       [,1]\n## [1,] FALSE\n\n\n#################### Non-Symmetrical Relations ####################\n# The order in which sf objects are placed changes the outcome\n\n# st_within()-------------------------------------------\nsf_points |&gt; \n  st_within(sf_poly1, sparse = F)\n##       [,1]\n## [1,]  TRUE\n## [2,]  TRUE\n## [3,] FALSE\n\nsf_poly1 |&gt; \n  st_within(sf_points, sparse = F)\n##       [,1]  [,2]  [,3]\n## [1,] FALSE FALSE FALSE\n\nsf_poly1 |&gt; \n  st_within(sf_poly2, sparse = F)\n##       [,1]\n## [1,] FALSE\n\n\n# st_contains()-----------------------------------------\nsf_poly1 |&gt; \n  st_contains(sf_points, sparse = F)\n##      [,1] [,2]  [,3]\n## [1,] TRUE TRUE FALSE\n\nsf_points |&gt; \n  st_contains(sf_poly1, sparse = F)\n##       [,1]\n## [1,] FALSE\n## [2,] FALSE\n## [3,] FALSE\n\n\n# st_covers()-------------------------------------------\nsf_poly1 |&gt; \n  st_covers(sf_points, sparse = F)\n##      [,1] [,2]  [,3]\n## [1,] TRUE TRUE FALSE\n\nsf_poly2 |&gt; \n  st_covers(sf_poly1, sparse = F)\n##       [,1]\n## [1,] FALSE\n\n\n# st_covered_by()---------------------------------------\nsf_points |&gt; \n  st_covered_by(sf_poly1, sparse = F)\n##       [,1]\n## [1,]  TRUE\n## [2,]  TRUE\n## [3,] FALSE\n\n\n\n4.2.3 Distance Relations\n\nDistance relations are continuous, unlike binary topological relations which return TRUE/FALSE values.\nThe st_distance() function calculates distances between two sf objects, returning a matrix with units of measurement (e.g., meters).\nst_centroid(): Computes the geometric centroid of a spatial feature, useful for representing a region’s central point in distance calculations.\nMatrix output:\n\nResults are returned as a matrix, even for single value calculations.\nComputes a distance matrix between all combinations of features in objects (e.g., distances between multiple points and polygons).\n\nPoint-to-polygon distance: Represents the shortest distance from a point to any part of the polygon.\nUsage in distance-based joins: st_distance() is also used for performing joins based on distance criteria.\nAn example code to find distance between central points of Auckland and Canterbury Regions, vs. Top three peaks in New Zealand, returned as a matrix,a nd shown below as a beautiful table using {gt}.\n\n\n# Central points of Auckland and Canterbury Regions\ndf1 &lt;- nz |&gt; \n  filter(str_detect(Name, \"Auck|Canter\")) |&gt; \n  st_centroid() |&gt; \n  select(Name, geom)\n\n# Top 3 highest peaks in New Zealand\ndf2 &lt;- nz_height |&gt; \n  slice_max(order_by = elevation, n = 3)\n\n# Finding the distance matrix\nst_distance(df1, df2) |&gt; \n  as_tibble() |&gt; \n  mutate(state = c(\"Auckland\", \"Canterbury\")) |&gt; \n  relocate(state) |&gt; \n  mutate(\n    across(\n      .cols = -state,\n      .fns = as.numeric\n    )\n  ) |&gt; \n  gt::gt() |&gt; \n  gt::fmt_number(\n    decimals = 1,\n    scale_by = 1e-3\n  ) |&gt; \n  gt::cols_label(V1 = \"Highest Peak\", \n                 V2 = \"Second\",\n                 V3 = \"Third\",\n                 state = \"Centroid of the State\") |&gt; \n  gt::tab_header(\n    title = \"Distance in kilometers\"\n  ) |&gt; \n  gtExtras::gt_theme_538()\n\n\n\nTable 1: Code output for use of st_centroid() and st_distance()\n\n\n\n\n\n\n\n\n\nDistance in kilometers\n\n\nCentroid of the State\nHighest Peak\nSecond\nThird\n\n\n\n\nAuckland\n856.6\n857.3\n856.9\n\n\nCanterbury\n115.5\n115.4\n115.5\n\n\n\n\n\n\n\n\n\n\n\n\n4.2.4 DE-9IM Strings\n\nThe Dimensionally Extended 9-Intersection Model (DE-9IM) underlies binary spatial predicates. This model forms the basis for many spatial operations and helps create custom spatial predicates.\nOrigins:\n\nInitially named “DE + 9IM,” it refers to the dimensions of intersections between the boundaries, interiors, and exteriors of two geometries (Clementini and Di Felice 1995).\nIt applies to two-dimensional geometries (points, lines, polygons) in Euclidean space, requiring data in a projected coordinate reference system (CRS).\n\nHow DE-9IM Works:\n\nThe model visualizes intersections between components of two geometries (interior, boundary, exterior) in a 3x3 matrix form, indicating the dimension of the intersection (0 for points, 1 for lines, 2 for polygons, and F for false).\nFlattening this matrix row-wise results in the DE-9IM string: “212111212”.\n\nUsing st_relate(): The st_relate() function returns DE-9IM strings to describe spatial relations.\nDeveloping Custom Predicates:\n\nBy interpreting DE-9IM strings, custom binary spatial predicates like queen and rook relations can be created:\n\nQueen relations (shared border or point): Pattern F***T****.\nRook relations (shared linear intersection): Pattern F***1****.\n\nCustom functions using st_relate():\n\n\nst_queen = function(x, y) \n  st_relate(x, y, pattern = \"F***T****\")\n\nst_rook = function(x, y) \n  st_relate(x, y, pattern = \"F***1****\")\n\nThis identifies which geometries in a grid have queen or rook relations to the central geometry.\n\n\n\n4.2.5 Spatial Joining with st_join()\n\nSpatial joins combine datasets based on spatial relationships instead of shared key variables (as in non-spatial joins). It adds columns from a source object (y) to a target object (x).\nJoin Details:\n\nDefault behavior: A left join, which retains all rows from x and includes rows with no match from y.\nOperators: Uses st_intersects() by default but can be modified via the join argument.\nHandles all geometry types: Works for points, lines, and polygons, though joins involving polygons may create duplicate rows for multiple matches in y.\n\nFlexibility:\n\nInner joins: Set left = FALSE to include only matched rows.\n\nThe st_join() function: The join argument defines the topological operator to determine these relationships, with the default being st_intersects().\n\nWe can customize this behavior by choosing alternative functions such as st_contains, st_within, st_overlaps, st_touches, or st_disjoint, among others, each defining a different geometric predicate.\nFor example, st_contains selects features where geometries of x fully encompass those of y, while st_within does the reverse.\nAdditionally, advanced options like st_is_within_distance allow proximity-based joins, and st_relate supports customized spatial relationships using a pattern.\n\nExample: Getting 25 random points in the world, and seeing in which countries they fall in Figure 3.\n\n\n\nCode\n# Getting 25 random points on the world,a dn then seeing in which countries they fall\nrandom_points &lt;- tibble(\n  x = round(\n    runif(\n    25, \n    min = st_bbox(world)$xmin, \n    max = st_bbox(world)$xmax\n    ),\n    2\n  ),\n  y = round(\n    runif(\n    25, \n    min = st_bbox(world)$ymin, \n    max = st_bbox(world)$ymax\n    ),\n    2\n  ),\n  id = LETTERS[1:25]\n) |&gt; \n  st_as_sf(coords = c(\"x\", \"y\")) |&gt; \n  st_set_crs(value = crs(world))\n\n\n# Easiest (but not tidyverse) way to subset\n# world[random_points, ]\n\n# Tidyverse way to filter: Names of Countries in which they fall\nintersecting_countries &lt;- world |&gt; \n  st_filter(random_points) |&gt; \n  pull(name_long)\n\n# The power of spatial joins: A tibble of countries where each random\n# point falls. st_join() by default performs a left_join()\nst_join(\n  random_points, \n  world |&gt; select(name_long)\n) |&gt; \n  drop_na() |&gt; \n  gt::gt() |&gt; \n  gtExtras::gt_theme_nytimes()\n\n\n\n\n\n\n\n\nid\ngeometry\nname_long\n\n\n\n\nA\nc(144.5, -84.79)\nAntarctica\n\n\nC\nc(-88.34, 54.48)\nCanada\n\n\nE\nc(-75.3, 60.22)\nCanada\n\n\nF\nc(135.09, 66.74)\nRussian Federation\n\n\nI\nc(105.49, 15.32)\nThailand\n\n\nN\nc(19.08, 29.12)\nLibya\n\n\nO\nc(113.88, 48.71)\nMongolia\n\n\nQ\nc(21.99, -33.51)\nSouth Africa\n\n\nU\nc(140.47, 59.39)\nRussian Federation\n\n\n\n\n\n\n\n\n\nCode\nset.seed(42)\n\nworld |&gt; \n  mutate(highlight = name_long %in% intersecting_countries) |&gt; \n  ggplot() +\n  geom_sf(\n    mapping = aes(\n      fill = highlight\n    ),\n    alpha = 0.5\n  ) +\n  scale_fill_manual(\n    values = c(\"transparent\", \"red\")\n  ) +\n  geom_sf(\n    data = random_points,\n    pch = 20,\n    size = 4,\n    colour = \"black\",\n    alpha = 0.5\n  ) +\n  ggrepel::geom_text_repel(\n    data = random_points,\n    mapping = aes(label = id, geometry = geometry),\n    size = 4,\n    colour = \"black\",\n    nudge_x = 2,\n    nudge_y = -2,\n    stat = \"sf_coordinates\"\n  ) +\n  labs(\n    title = \"25 random points on world map, and Countries in which they fall\",\n    x = NULL, y = NULL\n  ) +\n  theme(\n    legend.position = \"none\"\n  )\n\n\n\n\n\n\n\n\nFigure 3: Using st_join() to spatially join two data sets, based on the st_intersect() relation\n\n\n\n\n\n\n\n4.2.6 Distance-based Joins\n\nDistance-based joins are used when geographic datasets are spatially proximate but do not intersect. The sf package enables such joins using spatial relationships like proximity.\nExample Dataset used:\n\ncycle_hire: Official cycle hire points.\ncycle_hire_osm: Cycle hire points from OpenStreetMap.\nRelationship: These datasets are geographically close but do not overlap, as verified using st_intersects(), which returns FALSE for all points.\n\nImplementation:\n\nCheck Proximity:\n\nUse st_is_within_distance() to determine points within a threshold distance (e.g., 20 meters).\n\nPerform Distance-based Join:\n\nApply st_join() with the st_is_within_distance predicate and a dist argument.\nThe resulting dataset may contain duplicate rows if points in the target object (cycle_hire) match multiple points in the source (cycle_hire_osm).\n\n\nKey Observations:\n\nJoins retain the geometry of features in the target dataset (cycle_hire).\nDistance-based joins are effective for linking datasets that are close geographically but do not overlap.\n\n\nFigure 4 visualizes the spatial relationship between two datasets, cycle_hire and cycle_hire_osm, using a proximity filter. The st_filter() function from the sf package identifies points in the cycle_hire dataset that are within 10 meters of points in cycle_hire_osm, leveraging the st_is_within_distance predicate. The result is a subset of cycle_hire points, which are plotted using ggplot2. The plot includes:\n\nFiltered cycle_hire points (dark blue, fully opaque).\nAll cycle_hire points (dark blue, semi-transparent) for context.\nAll cycle_hire_osm points (red, semi-transparent) to show the proximity relationship.\n\n\n\nCode\ndata(\"cycle_hire\")\ndata(\"cycle_hire_osm\")\n\nggplot() +\n  geom_sf(\n    data = cycle_hire,\n    colour = \"blue\",\n    alpha = 0.5\n  ) +\n  geom_sf(\n    data = cycle_hire_osm,\n    colour = \"red\",\n    alpha = 0.5\n  )\n\n\n\n\n\n\n\n\n\nCode\n# Official Cycle hire points with added info from OSM points within 10 metres\n# \n# cycle_hire |&gt; \n#   st_join(\n#     cycle_hire_osm, \n#     join = st_is_within_distance,\n#     dist = units::set_units(10, \"m\")\n#   )\n\n\nJust checking, whether any of the two points in these two data sets exactly match. Well, they don’t!\n\nst_intersects(cycle_hire, cycle_hire_osm, sparse = F) |&gt; any()\n\n[1] FALSE\n\n\nNow, in Figure 4, we highlight only those points of bike hire in the official data, which are within 10 metres of the OSM data. The important function here is st_filter() along with the argument .predicate = st_is_within_distance() and the argument dist = ... .\n\n\nCode\n# Plot only points which have a OSM point within 10 metres\ncycle_hire |&gt; \n  st_filter(\n    cycle_hire_osm,\n    .predicate = st_is_within_distance,\n    dist = units::set_units(10, \"m\")\n  ) |&gt; \n  ggplot() +\n  geom_sf(size = 3, alpha = 0.75, colour = \"darkblue\") +\n  geom_sf(\n    data = cycle_hire, \n    alpha = 0.2, \n    colour = \"blue\",\n    size = 1\n  ) +\n  geom_sf(\n    data = cycle_hire_osm, \n    alpha = 0.2, \n    colour = \"red\",\n    size = 1\n  )\n\n\n\n\n\n\n\n\nFigure 4: Official Cycle Hire Points Within 10 Meters of OpenStreetMap Locations\n\n\n\n\n\n\n\n4.2.7 Spatial Aggregation\n\nSpatial data aggregation condenses data into fewer rows by summarizing multiple values of a variable into a single value per grouping variable, similar to attribute data aggregation. Following two approaches exist: —\n\nBase R’s aggregate(): Groups values based on spatial relationships and summarizes them with a specified function (e.g., mean).\nTidyverse Approach (group_by() and summarize()): Combines st_join() with grouping and summarizing to perform spatial aggregation while allowing flexibility in function application and column naming. (This approach is better, as shown in Figure 5)\n\nOutput Differences:\n\naggregate() may result in NA for unmatched regions.\nTidyverse methods preserve unmatched region names and allow for more flexible aggregation functions and output formatting.\n\nFunctions like median(), sd(), or other statistical summarizers can replace mean() for different aggregation purposes.\n\n\ndata(\"nz_height\")\ndata(\"nz\")\n\nst_join(x = nz, y = nz_height) |&gt; \n  group_by(Name) |&gt; \n  summarise(elevation = mean(elevation, na.rm = T)) |&gt; \n  ggplot(\n    mapping = aes(fill = elevation)\n  ) +\n  geom_sf() +\n  paletteer::scale_fill_paletteer_c(\n    \"grDevices::Terrain 2\",\n    na.value = \"white\"\n  )\n\n\n\n\n\n\n\nFigure 5: Spatial data aggregation with st_join() from {sf} and summarise() from {tidyverse}\n\n\n\n\n\n\n\n4.2.8 Joining In-congruent Layers\n\nSpatial congruence occurs when two layers (aggregating object y and target object x) share borders, enabling accurate spatial aggregation. Incongruence arises when no shared borders exist, complicating spatial operations.\nExample of Congruence:\n\nAdministrative boundaries, such as districts made of smaller units, typically exhibit spatial congruence.\n\nIssue with Incongruence:\n\nIn-congruent layers, like sub-zones with differing borders from aggregating zones, result in inaccurate aggregations (e.g., centroids of sub-zones).\n\nSolution: Areal Interpolation: Transfers values between areal units using:\n\nSimple area-weighted methods: Proportionally assigns values based on area overlap. This is implemented using st_interpolate_aw().\nAdvanced methods: Include algorithms like ‘pycnophylactic’ interpolation.\n\nExample Dataset:\n\nThe spData package includes incongruent (sub-zones) and aggregating_zones (larger zones). The value column in incongruent represents total regional income in million Euros, which must be aggregated into aggregating_zones.\n\nImplementation: st_interpolate_aw():\n\nThe st_interpolate_aw() function in the sf package performs areal-weighted interpolation of polygon data, allowing attributes from one spatial object (x) to be transferred to another (to) based on area overlap. The extensive argument determines whether attributes are spatially extensive (e.g., population, summed across areas) or spatially intensive (e.g., density, averaged). Additional options include keep_NA (to retain or exclude NA features) and na.rm (to remove features with NA attributes from x).\nAggregated results depend on the variable type:\n\nExtensive variables: Values increase with area (e.g., total income).\nIntensive variables: Values remain constant irrespective of area (e.g., averages).\n\nst_interpolate_aw() handles spatially extensive variables (e.g., total income) by summing values across areas.\nIn st_interpolate_aw(), for spatially intensive variables (e.g., averages, percentages), set extensive = FALSE to use averages instead of sums.\nNote: Warning messages indicate the assumption of uniform attribute distribution across areas.\n\n\n\ndata(\"aggregating_zones\")\ndata(\"incongruent\")\n\n# The two overall main zones for which the total income needs to be computed\naggregating_zones\n\nSimple feature collection with 2 features and 3 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 417686.2 ymin: 443703.6 xmax: 422959.3 ymax: 447036.8\nProjected CRS: OSGB 1936 / British National Grid\n      geo_code geo_label geo_labelw                       geometry\n5164 E02002332 Leeds 003       &lt;NA&gt; MULTIPOLYGON (((418731.9 44...\n6631 E02002333 Leeds 004       &lt;NA&gt; MULTIPOLYGON (((419196.4 44...\n\n# The 9 smaller counties or districts or sub-units which are not\n# congruent with the main zones\nincongruent\n\nSimple feature collection with 9 features and 2 fields\nAttribute-geometry relationships: aggregate (1), NA's (1)\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 417686.8 ymin: 443703 xmax: 422963 ymax: 446978\nProjected CRS: OSGB 1936 / British National Grid\n        level    value                       geometry\n1 Incongruent 4.037919 MULTIPOLYGON (((420799.6 44...\n2 Incongruent 5.014419 MULTIPOLYGON (((418664 4464...\n3 Incongruent 4.933000 MULTIPOLYGON (((419964 4462...\n4 Incongruent 5.120139 MULTIPOLYGON (((420368 4441...\n5 Incongruent 6.548912 MULTIPOLYGON (((420419.8 44...\n6 Incongruent 3.749791 MULTIPOLYGON (((421779 4451...\n7 Incongruent 5.432837 MULTIPOLYGON (((419577 4464...\n8 Incongruent 4.618049 MULTIPOLYGON (((417687.6 44...\n9 Incongruent 5.956771 MULTIPOLYGON (((418859.3 44...\n\n# We are using extensive = TRUE, because our variable is \n# total income, not average income\nincongruent |&gt; \n  # We need to keep only the numeric variable (and of course,\n  # the sticky geometry. Otherwise, R will not understand what\n  # to do with non-numeric columns)\n  select(value) |&gt; \n  st_interpolate_aw(aggregating_zones, extensive = TRUE)\n\nWarning in st_interpolate_aw.sf(select(incongruent, value), aggregating_zones,\n: st_interpolate_aw assumes attributes are constant or uniform over areas of x\n\n\nSimple feature collection with 2 features and 1 field\nAttribute-geometry relationship: aggregate (1)\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 417686.2 ymin: 443703.6 xmax: 422959.3 ymax: 447036.8\nProjected CRS: OSGB 1936 / British National Grid\n     value                       geometry\n1 19.61613 MULTIPOLYGON (((418731.9 44...\n2 25.66872 MULTIPOLYGON (((419196.4 44..."
  },
  {
    "objectID": "geocomputation/st_is_within_distance.html",
    "href": "geocomputation/st_is_within_distance.html",
    "title": "Using the power of {sf} to plot stores / outlets along a calculated route using sf::st_is_within_distance()",
    "section": "",
    "text": "A tutorial\nThis tutorial demonstrates how to combine geospatial data and tools in R to map store locations along a driving route. By leveraging the power of the {sf} package, we identify stores within a defined distance from a calculated route, enriched with data from OpenAddresses and AllThePlaces. The driving directions are fetched using {osrm}, and raster base maps are integrated via {ggmap} and Stadia Maps.\n\n\nData Preparation and Mapping\nFirst, the driving route between Sydney Opera House and Melbourne Cricket Ground is plotted using {osrm}’s osrmRoute(). Store data, in this case, McDonald’s locations in Australia, is sourced from AllThePlaces in GeoJSON format, converted into an sf object, and visualized on a map alongside the calculated route. Bounding boxes are created to focus the map and ensure a clean visual presentation, making it suitable for social media or reports.\n\n\nFiltering and Analysis\nUsing sf::st_is_within_distance(), stores within 500 meters of the route are identified and labeled. The route and stores are then plotted with customized aesthetics, distinguishing nearby stores with clear color coding. For enhanced visualization, logos or icons can replace points using {ggimage}. Additionally, raster base maps from Stadia Maps are overlaid, requiring a coordinate transformation to integrate smoothly with geom_sf() objects.\n\n\nLinks to Functions and Resources:\n\nRoute Calculation: osrmRoute()\nSpatial Data Handling: st_is_within_distance()\nStore Locations: AllThePlaces\nBase Maps: ggmap and Stadia Maps\nGeospatial Visualization: ggplot2\n\nThe resulting map provides a comprehensive visual tool for understanding proximity-based store access, with applications in retail analysis, logistics, and marketing.\n\n\nCode\nlibrary(tidyverse)   # Data Wrangling\nlibrary(sf)          # Handling Simple Features in R\nlibrary(scales)      # Easy handling numbers and scales\n\n\n\n\nStep 1: Get driving directions\n\n\nCode\n# The raw data to be entered\ndrive_stops &lt;- tibble(\n  station_name = c(\"Sydney Opera House\", \n                  \"Melbourne Cricket Ground\"),\n  city = c(\"Sydney\", \n           \"Melbourne\"),\n  lat = c(-33.85906634, -37.82358305),\n  lon = c(151.21353654, 144.98283670)\n) |&gt; \n  st_as_sf(coords = c(\"lon\", \"lat\"), crs = 4326)\n\nroute &lt;- osrm::osrmRoute(\n  src = drive_stops$geometry[1],\n  dst = drive_stops$geometry[2]\n)\n\n\n\n\nStep 2: Get list of McDonalds locations in Australia\nCredits: https://openaddresses.io/ and Source: https://www.alltheplaces.xyz/. Finding code for McDonald’s from th WikiData page for the website. The data format is given here. Getting the actual data link for Australia from the spiders page. Courtesy Data-Is-Plural, 24.04.2024 edition.\n\n\nCode\n# Importing raw data: McDonalds in USA\n\nurl1 &lt;- \"https://alltheplaces-data.openaddresses.io/runs/2024-11-16-13-32-12/output/mcdonalds_au.geojson\"\n\nmcdonalds &lt;- geojsonio::geojson_read(url1, what = \"sp\") |&gt; \n  st_as_sf(crs = 4326) |&gt; \n  janitor::clean_names()\n\naus_map &lt;- rnaturalearth::ne_countries(sovereignty = \"Australia\") \n\nggplot() +\n  geom_sf(data = mcdonalds, alpha = 0.15, colour = \"red\") +\n  geom_sf(data = aus_map, fill = NA) +\n  geom_sf(data = route, colour = \"blue\", lwd = 1)\n\n\n\n\n\n\n\n\n\n\n\nStep 3: Settle for a bounding box of 5:4 ratio (for nice twitter post)\n\n\nCode\nlonmin = 143.5\nlonmax &lt;- 151.5\nlatmin &lt;- -40.5\nlatmax &lt;- latmin + ((lonmax - lonmin) * 5/4)\n\n\nmy_new_bbox &lt;- st_polygon(\n  list(rbind(c(lonmin, latmin), \n             c(lonmin, latmax), \n             c(lonmax, latmax), \n             c(lonmax, latmin), \n             c(lonmin, latmin)))\n\n) |&gt; \n  st_sfc() |&gt; \n  st_set_crs(4326)\n\nmy_new_bbox\n\n\nGeometry set for 1 feature \nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 143.5 ymin: -40.5 xmax: 151.5 ymax: -30.5\nGeodetic CRS:  WGS 84\n\n\nCode\nggplot() +\n  geom_sf(data = mcdonalds, alpha = 0.15, colour = \"red\") +\n  geom_sf(data = aus_map, fill = NA) +\n  geom_sf(data = route, colour = \"blue\", lwd = 1) +\n  geom_sf(data = my_new_bbox, \n          linewidth = 2,\n          lineend = \"square\",\n          fill = NA,\n          alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nStep 4: Filter the driving directions and McDonalds locations to within a bounding box\n\n\nCode\naus_map &lt;- rnaturalearth::ne_countries(\n  sovereignty = \"Australia\",\n  scale = \"large\"\n  ) |&gt; \n  st_intersection(my_new_bbox)\n\nmcdonalds_bbox &lt;- mcdonalds |&gt; \n  st_intersection(my_new_bbox) |&gt; \n  select(drive_through, addr_street_address, addr_city, geometry)\n\nggplot() +\n  geom_sf(data = aus_map) +\n  geom_sf(data = mcdonalds_bbox, colour = \"red\", alpha = 0.2) +\n  geom_sf(data = route, colour = \"blue\")\n\n\n\n\n\n\n\n\n\n\n\nStep 5: Use sf::st_is_within_distance() to label Outlets near and far from the highway.\n\n\nCode\n# Within 500 metres of the driving route\nmcdonalds_bbox &lt;- mcdonalds_bbox |&gt; \n  mutate(\n    near_route = as_vector(\n        mcdonalds_bbox |&gt; \n        st_is_within_distance(\n          y = route, \n          dist = 500, \n          sparse = F\n        )\n      )\n  )\n\nmcdonalds_bbox\n\n\nSimple feature collection with 551 features and 4 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 143.5616 ymin: -38.60672 xmax: 151.4883 ymax: -30.97867\nGeodetic CRS:  WGS 84\nFirst 10 features:\n   drive_through                                   addr_street_address\n1            yes                              1500 Eastlink Northbound\n4           &lt;NA&gt;            Erina Fair Shopping Centre, Terrigal Drive\n5           &lt;NA&gt;              Highpoint Shopping Centre, Rosamond Road\n7           &lt;NA&gt;                             Westpoint Shopping Centre\n8           &lt;NA&gt;                Westfield Penrith, 569-589 High Street\n10          &lt;NA&gt; Macarthur Square Shopping Centre, 200 Gilchrist Drive\n11           yes      Waverley Gardens S/C, Cnr Police & Jackson Roads\n12          &lt;NA&gt;                                     Domestic Terminal\n13          &lt;NA&gt;              Westfield Shopping Centre, George Street\n15          &lt;NA&gt;       Rouse Hill Town Centre, Main St (Cnr Civic Way)\n      addr_city                   geometry near_route\n1      Scoresby POINT (145.2304 -37.89857)      FALSE\n4         Erina POINT (151.3928 -33.43665)      FALSE\n5   Maribyrnong POINT (144.8887 -37.77362)      FALSE\n7     Blacktown POINT (150.9085 -33.77018)      FALSE\n8       Penrith POINT (150.6948 -33.75077)      FALSE\n10 Campbelltown POINT (150.7977 -34.07348)       TRUE\n11     Mulgrave  POINT (145.189 -37.93494)      FALSE\n12       Mascot POINT (151.1798 -33.93414)      FALSE\n13    Liverpool POINT (150.9246 -33.91814)      FALSE\n15   Rouse Hill POINT (150.9252 -33.69134)      FALSE\n\n\nCode\nmcdonalds_bbox |&gt; \n  filter(near_route) |&gt; \n  relocate(near_route) |&gt; \n  st_drop_geometry() |&gt; \n  as_tibble() |&gt; \n  gt::gt() |&gt; \n  gt::cols_label_with(fn = snakecase::to_title_case) |&gt; \n  gtExtras::gt_theme_espn() |&gt; \n  gt::sub_missing(missing_text = \"\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNear Route\nDrive Through\nAddr Street Address\nAddr City\n\n\n\n\nTRUE\n\n\nMacarthur Square Shopping Centre, 200 Gilchrist Drive\nCampbelltown\n\n\nTRUE\nyes\nCnr Victoria Parade & Smith Street\nCollingwood\n\n\nTRUE\nyes\n199 Queens Parade\nClifton Hill\n\n\nTRUE\n\n\nCnr Alfred Street & Loftus St\nCircular Quay\n\n\nTRUE\nyes\nBP Service Centre, Southbound Carriageway, Hume Highway\nGlenrowan\n\n\nTRUE\n\n\nBP Service Centre, Northbound Side, Hume Highway\nGlenrowan\n\n\nTRUE\nyes\n7 Sowerby Street\nGoulburn\n\n\nTRUE\nyes\nCnr Davies & Arab Roads\nPadstow\n\n\nTRUE\nyes\n143 Mount Street\nGundagai\n\n\nTRUE\nyes\nCnr Camden Valley Way & Ash Road\nPrestons\n\n\nTRUE\nyes\nBP Service Centre 1015 Hume Freeway\nWallan\n\n\nTRUE\nyes\n1050 Hume Freeway\nWallan\n\n\nTRUE\nyes\n36 Hoddle Street\nAbbotsford\n\n\nTRUE\nyes\n411-423 Bell Street (Cnr St Georges Road)\nPreston\n\n\nTRUE\nyes\nCnr Common Street & Sydney Road\nGoulburn\n\n\nTRUE\n\n\nR127, 305a Botany Road\nZetland\n\n\n\n\n\n\n\n\n\nStep 6: Plot the driving directions and outlets (labelled by colours)\n\n\nCode\nggplot() +\n  geom_sf(data = route, \n          colour = \"darkgrey\", \n          linewidth = 1.5,\n          alpha = 0.5) +\n  geom_sf(data = aus_map, fill = NA) +\n  geom_sf(\n    data = mcdonalds_bbox, \n    mapping = aes(\n      colour = near_route,\n      alpha = near_route,\n      size = near_route\n    )\n  ) +\n  scale_alpha_manual(values = c(0.1, 0.9), name = \"Within 500m of driving route?\") +\n  scale_size_manual(values = c(1.5, 3), name = \"Within 500m of driving route?\") + \n  scale_colour_manual(values = c(\"darkblue\", \"red\"), name = \"Within 500m of driving route?\") +\n  ggthemes::theme_map() +\n  theme(\n    legend.position = \"inside\",\n    legend.position.inside = c(1,0.1),\n    legend.justification = c(1, 0)\n  )\n\n\n\n\n\n\n\n\n\n\n\nStep 7: Try icons in place of geom_point (geom_sf)\n\n\nCode\nlibrary(magick)\nmcd_icon &lt;- image_read(\"https://seeklogo.com/images/M/mcdonald-s-logo-2325D6C1EF-seeklogo.com.png\") |&gt;\n  image_resize(\"x50\") |&gt;\n  image_write(path = here::here(\"geocomputation\", \"images\", \"mcd_logo.png\"))\n\n\nggplot() +\n  # Base map of Australia within the bounding box\n  geom_sf(data = aus_map, fill = \"white\") +\n  \n  # The Driving Route\n  geom_sf(\n    data = route,\n    colour = \"darkgrey\",\n    linewidth = 1.5,\n    alpha = 0.5\n  ) +\n  \n  # All other McDonald's that are away from the drive\n  geom_sf(\n    data = mcdonalds_bbox |&gt;\n      filter(!near_route),\n    colour = \"darkblue\",\n    alpha = 0.2,\n    pch = 16\n  ) +\n  \n  # McDonald's that lie on the route and are drive through\n  ggimage::geom_image(\n    data = mcdonalds_bbox |&gt;\n      filter(near_route) |&gt;\n      filter(!is.na(drive_through)) |&gt; \n      mutate(image_path = \"geocomputation/images/mcd_logo.png\"),\n    mapping = aes(\n      geometry = geometry,\n      image = mcd_icon\n    ),\n    stat = \"sf_coordinates\",\n    size = 0.02\n  ) +\n  \n  # Labelling the McDonald's that lie on the route and \n  # are drive through using geom_text_repel()\n  ggrepel::geom_text_repel(\n    data = mcdonalds_bbox |&gt;\n      filter(near_route) |&gt; \n      filter(!is.na(drive_through)),\n    mapping = aes(\n      label = addr_city,\n      geometry = geometry\n    ),\n    stat = \"sf_coordinates\"\n  ) +\n  \n  coord_sf(expand = FALSE) +\n  ggthemes::theme_map() +\n  theme(\n    legend.position = \"inside\",\n    legend.position.inside = c(1, 0.1),\n    legend.justification = c(1, 0),\n    plot.background = element_rect(\n      fill = \"lightblue\"\n    )\n  )\n\n\n\n\n\n\n\n\n\n\n\nStep 8: Get a base map of raster images from stadia maps\n\n\nCode\n# Get Stadia Maps key: Tutorial at\n# https://aditya-dahiya.github.io/visage/geocomputation/ggmap_rasters.html\nggmap::register_stadiamaps(my_stadiamaps_key)\n\nbase_map_bbox &lt;- c(\n  latmin, latmax, lonmin, lonmax\n)\nnames(base_map_bbox) &lt;- c(\n  \"bottom\", \"top\", \"left\", \"right\"\n)\n\nbase_map &lt;- ggmap::get_stadiamap(\n  bbox = base_map_bbox,\n  zoom = 7,\n  maptype = \"stamen_terrain\"\n)\n\n# Credits: https://stackoverflow.com/questions/47749078/how-to-put-a-geom-sf-produced-map-on-top-of-a-ggmap-produced-raster by andyteucher on StackOverFlow (https://stackoverflow.com/users/1736291/andyteucher)\n\n# Define a function to fix the bbox to be in CRS EPSG:3857\nggmap_bbox &lt;- function(map) {\n  # Extract the bounding box (in lat/lon) from the ggmap\n  # to a numeric vector, and set the names to what\n  # sf::st_bbox expects:\n  map_bbox &lt;- setNames(\n    unlist(attr(map, \"bb\")),\n    c(\"ymin\", \"xmin\", \"ymax\", \"xmax\")\n  )\n\n  # Coonvert the bbox to an sf polygon, transform it to 3857,\n  # and convert back to a bbox (convoluted, but it works)\n  bbox_3857 &lt;- st_bbox(\n    st_transform(\n      st_as_sfc(\n        st_bbox(map_bbox, crs = 4326)\n        ), \n      3857\n    )\n  )\n\n  # Overwrite the bbox of the ggmap object with the transformed coordinates\n  attr(map, \"bb\")$ll.lat &lt;- bbox_3857[\"ymin\"]\n  attr(map, \"bb\")$ll.lon &lt;- bbox_3857[\"xmin\"]\n  attr(map, \"bb\")$ur.lat &lt;- bbox_3857[\"ymax\"]\n  attr(map, \"bb\")$ur.lon &lt;- bbox_3857[\"xmax\"]\n  map\n}\n\n# Use the function to convert our downloaded Raster Files into \n# the new CRS and new bounding box CRS\nbase_map2 &lt;- ggmap_bbox(base_map)\n\ntemp &lt;- ggmap::ggmap(base_map2) +\n  coord_sf(\n    crs = st_crs(3857),\n    expand = F\n  ) +\n  ggthemes::theme_map()\n\nggsave(\n  filename = here::here(\n    \"geocomputation\",\n    \"images\",\n    \"base_map_st_is_within_distance.png\"\n  ),\n  plot = temp,\n  width = 350,\n  height = 500,\n  units = \"mm\",\n  bg = \"white\"\n)\n\n\n\n\n\nStep 9: Decorate the final product\n\n\nCode\n# Starting the process of Overlaying the geom_sf() data on this\n# Most important is to add the inherit.aes = FALSE argument.\nlibrary(fontawesome)\nsysfonts::font_add_google(\"Saira Extra Condensed\", \"caption_font\")\n# Caption stuff for the plot\nsysfonts::font_add(\n  family = \"Font Awesome 6 Brands\",\n  regular = here::here(\"docs\", \"Font Awesome 6 Brands-Regular-400.otf\")\n)\ntext_hil &lt;- \"grey20\"\ntext_col &lt;- text_hil\ngithub &lt;- \"&#xf09b\"\ngithub_username &lt;- \"aditya-dahiya\"\nxtwitter &lt;- \"&#xe61b\"\nxtwitter_username &lt;- \"@adityadahiyaias\"\nsocial_caption_1 &lt;- glue::glue(\"&lt;span style='font-family:\\\"Font Awesome 6 Brands\\\";'&gt;{github};&lt;/span&gt; &lt;span style='color: {text_hil}'&gt;{github_username}  &lt;/span&gt;\")\nsocial_caption_2 &lt;- glue::glue(\"&lt;span style='font-family:\\\"Font Awesome 6 Brands\\\";'&gt;{xtwitter};&lt;/span&gt; &lt;span style='color: {text_hil}'&gt;{xtwitter_username}&lt;/span&gt;\")\nplot_caption &lt;- paste0(\n  \"**Data:** {ISOcodes} by Christian Buchta & Kurt Hornik\", \n  \" |  **Code:** \", \n  social_caption_1, \n  \" |  **Graphics:** \", \n  social_caption_2\n  )\nrm(github, github_username, xtwitter, \n   xtwitter_username, social_caption_1, \n   social_caption_2)\nshowtext::showtext_auto()\nbts &lt;- 90\n\ng &lt;- ggmap::ggmap(base_map2) +\n\n  # The Driving Route\n  geom_sf(\n    data = route,\n    colour = \"black\",\n    linewidth = 1.5,\n    alpha = 0.5,\n    inherit.aes = F\n  ) +\n  \n  \n  # All other McDonald's that are away from the drive\n  geom_sf(\n    data = mcdonalds_bbox |&gt;\n      filter(!near_route),\n    colour = \"red\",\n    alpha = 0.4,\n    size = 3,\n    pch = 16,\n    inherit.aes = F\n  ) +\n  \n  # McDonald's that lie on the route and are drive through\n  ggimage::geom_image(\n    data = mcdonalds_bbox |&gt;\n      filter(near_route) |&gt;\n      filter(!is.na(drive_through)) |&gt; \n      mutate(image_path = \"geocomputation/images/mcd_logo.png\"),\n    mapping = aes(\n      geometry = geometry,\n      image = mcd_icon\n    ),\n    stat = \"sf_coordinates\",\n    size = 0.02,\n    inherit.aes = F\n  ) +\n  \n  # Labelling the McDonald's that lie on the route and \n  # are drive through using geom_text_repel()\n  ggrepel::geom_text_repel(\n    data = mcdonalds_bbox |&gt;\n      filter(near_route) |&gt; \n      filter(!is.na(drive_through)),\n    mapping = aes(\n      label = str_wrap(paste0(addr_street_address,\n                              \", \",\n                              addr_city),\n                       15),\n      geometry = geometry\n    ),\n    stat = \"sf_coordinates\",\n    inherit.aes = F,\n    size = bts / 4,\n    force = 15,\n    family = \"caption_font\",\n    colour = text_hil,\n    lineheight = 0.2,\n    fontface = \"bold\"\n  ) +\n  \n  # Forcing the ggplot2 map to be in CRS: 3857\n  coord_sf(\n    crs = st_crs(3857),\n    expand = F\n  ) +\n  labs(\n    title = \"McDonald's Drive-Through\\nlocations along a drive\\nfrom Sydney to\\nMelbourne\",\n    subtitle = \"Using sf::st_is_within_distance() from {sf}\",\n    caption = plot_caption\n  ) +\n  ggthemes::theme_map(\n    base_family = \"caption_font\",\n    base_size = bts\n  ) +\n  theme(\n    plot.margin = margin(0,0,0,0, \"mm\"),\n    text = element_text(\n      colour = text_hil,\n      lineheight = 0.3\n    ),\n    plot.title = element_text(\n      margin = margin(20,0,-150,5, \"mm\"),\n      hjust = 0,\n      size = 3 * bts,\n      face = \"bold\"\n    ),\n    plot.subtitle = element_text(\n      margin = margin(150,0,-210,5, \"mm\"),\n      hjust = 0,\n      size = 1.5 * bts,\n      face = \"bold\"\n    ),\n    plot.caption = ggtext::element_textbox(\n      margin = margin(-50,0,20,0, \"mm\"),\n      hjust = 1\n    )\n  )\n\nggsave(\n  filename = here::here(\n    \"geocomputation\",\n    \"images\",\n    \"st_is_within_distance.png\"\n  ),\n  plot = g,\n  width = 350,\n  height = 500,\n  units = \"mm\",\n  bg = \"white\"\n)"
  },
  {
    "objectID": "geocomputation/chapter4.html#spatial-operations-on-raster-data",
    "href": "geocomputation/chapter4.html#spatial-operations-on-raster-data",
    "title": "Chapter 4: Spatial data operations",
    "section": "4.3 Spatial operations on raster data",
    "text": "4.3 Spatial operations on raster data\n\nDemonstrates advanced spatial raster operations.\nProvides an alternative to manually creating datasets by accessing them from the spData package:\n\nelev: Represents elevation data.\ngrain: Represents grain-related data.\n\n\nelev &lt;- rast(system.file(\"raster/elev.tif\", \n                        package = \"spData\"))\n\ngrain &lt;- rast(system.file(\"raster/grain.tif\", \n                         package = \"spData\"))\n\n# plot(elev)\n# plot(grain)\n\nggplot() +\n  geom_spatraster(data = elev) +\n  labs(title = \"elev SpatRaster\", caption = \"data: {spData}\")\n  \n\nggplot() +\n  geom_spatraster(data = grain) +\n  labs(title = \"grain SpatRaster\", caption = \"data: {spData}\")\n\n\n\n\n\n\n\n\n\n\n\n(a) elev\n\n\n\n\n\n\n\n\n\n\n\n(b) grain\n\n\n\n\n\n\n\nFigure 6: Section 4.3: Raster Datasets used: plotted using ggplot2 and {tidyterra}\n\n\n\n\n4.3.1 Spatial subsetting\n\nBuilds on Section 3.3, which covered retrieving raster values by cell IDs or row/column combinations.\nSpatial subsetting allows extraction of raster data by location (coordinates) or spatial objects:\n\nterra::extract(): Extracts raster values directly using coordinates. (Note: A function with the same name exists in the tidyverse, so be careful to add package name at start).\n\nSubsetting with another raster object:\n\nUse a secondary raster as a spatial mask to subset the primary raster, using terra::extract(ext(...)) .\nExample shown below: Subsetting elev using a smaller raster clip_raster (defining a specific extent).\nTwo kinds of Spatial outputs from subsetting:\n\nUse the drop argument with the [ ] operator to return subsetting results as raster objects.\nExample: Subsets the first two cells of elev with elev[1:2, drop = FALSE], whereas elev[1:2] returns the cell values of first two cells only.\n\n\nMasking raster data with logical values:\n\nCreates a raster mask (rmask) with NA and TRUE values.\nMasks the primary raster (elev) to retain only values corresponding to TRUE in the mask using:\n\n[ ] operator - use TRUE and FALSE.\nmask() function - use TRUE and NA.\n\n\nThe mask() function in the terra package applies a mask to a SpatRaster or SpatVector. It replaces values in a raster (x) with NA (or another value) where another raster or vector (mask) has NA or specified mask values. It’s useful for filtering, clipping, or focusing on specific areas.\nThe extract() function in the terra package retrieves values from a SpatRaster based on specified locations or geometries. Locations can be points (as a SpatVector, matrix, or data frame), cell numbers, or spatial objects like polygons. It supports methods for exact or weighted extraction, interpolation, and summary statistics for extracted data. Key arguments include:\n\nx: The SpatRaster to extract values from\ny: Locations (e.g., points, polygons, or cell numbers) to extract values for.\nfun: Summarizes extracted data for polygons (e.g., mean, sum).\ncells/xy: Optionally return cell numbers or coordinates.\nweights/exact: Extract weighted or exact fractions for polygons.\nbind: Combines extracted values with input geometries (SpatVector).\n\nThe code below demonstrates these spatial operations on raster data. Initially, it showcases how to extract raster values using coordinates with terra::extract() by specifying a set of coordinate pairs. Next, it demonstrates how to create a new raster (clip_raster) to subset the elev raster, focusing on extracting values only within the extent defined by the clip raster using both the [ ] operator and terra::extract(). The example highlights the importance of the drop = FALSE argument in the [ ] operator, which ensures that spatial structure is preserved when subsetting raster objects. Finally, the code illustrates the use of masking with a logical raster (temporary_mask), where specific cells in the elev raster are retained based on TRUE values in the mask. This process is essential for filtering or replacing values (e.g., assigning NA to erroneous data).\n\n\n# Let us extract some values from \"elev\" using coordinates\n# I want to extract coordiantes of \ncoords_extract &lt;- matrix(\n  c(-1.2, -1.2,\n    1.2, 1.2),\n  ncol = 2,\n  byrow = T\n)\n\ncoords_extract\n\n     [,1] [,2]\n[1,] -1.2 -1.2\n[2,]  1.2  1.2\n\nelev |&gt; \n  terra::extract(\n    y = coords_extract\n  )\n\n  elev\n1   31\n2    6\n\n# Let us create a new raster to clip the central four blocks of the elev raster\nclip_raster &lt;- rast(\n  xmin = -0.5, xmax = 0.5, \n  ymin = -0.5, ymax = 0.5,\n  resolution = 0.5, \n  vals = sample(1:25, 4)\n  )\n\n# Extracting only the values\nelev[clip_raster]\n\n  elev\n1   15\n2   16\n3   21\n4   22\n\n# This code somehow doesn't work for me!\n# elev |&gt; \n#   terra::extract(ext(clip_raster))\n\n# Explaining the meaning of argument drop = FALSE in the \n# base R subsetting operator \"[]\"\nelev[1:2]\n\n  elev\n1    1\n2    2\n\nelev[1:2, drop = FALSE]    \n\nclass       : SpatRaster \ndimensions  : 1, 2, 1  (nrow, ncol, nlyr)\nresolution  : 0.5, 0.5  (x, y)\nextent      : -1.5, -0.5, 1, 1.5  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (EPSG:4326) \nsource(s)   : memory\nvarname     : elev \nname        : elev \nmin value   :    1 \nmax value   :    2 \n\n# Creating a temporary_mask object\ntemporary_mask &lt;- elev\nvalues(temporary_mask) &lt;- sample(c(NA, TRUE), 36,\n                                 replace = T)\n# elev |&gt; \n#   mask(temporary_mask)\n\nggplot() +\n  geom_spatraster(data = clip_raster)\n\nggplot() +\n  geom_spatraster(data = temporary_mask) +\n  scale_fill_discrete(na.value = \"white\")\n\nggplot() +\n  geom_spatraster(data = elev |&gt; mask(temporary_mask)) +\n  scale_fill_continuous(na.value = \"white\")\n\n\n\n\n\n\n\n\n\n\n\n(a) Plotting clip_raster: a smaller raster\n\n\n\n\n\n\n\n\n\n\n\n(b) The temporary_mask raster\n\n\n\n\n\n\n\n\n\n\n\n(c) plotting the masked elev, based on a randomly generated temporary_mask\n\n\n\n\n\n\n\nFigure 7: Showing plots from the code of above\n\n\n\n\n\n4.3.3 Local operations\n\nLocal operations are cell-by-cell operations performed on one or more raster layers. Includes operations like addition, subtraction, squaring, logical comparisons, and logarithmic transformations. Examples are shown in Figure 8\nReclassification:\n\nNumeric values can be grouped into intervals (e.g., low, middle, high elevations).\nUse the classify() function with a reclassification matrix to assign new values to defined ranges.\n\n\n\nggplot() +\n  geom_spatraster(data = elev) +\n  ggtitle(\"`elev` - the original raster\") +\n  paletteer::scale_fill_paletteer_c(\"grDevices::terrain.colors\") +\n  theme(legend.position = \"bottom\")\n\nggplot() +\n  geom_spatraster(data = elev^2) +\n  ggtitle(\"elev^2\") +\n  paletteer::scale_fill_paletteer_c(\"grDevices::terrain.colors\") +\n  theme(legend.position = \"bottom\",\n        legend.key.width = unit(30, \"pt\"))\n\nggplot() +\n  geom_spatraster(data = log2(elev)) +\n  ggtitle(\"log2(elev)\") +\n  paletteer::scale_fill_paletteer_c(\"grDevices::terrain.colors\") +\n  theme(legend.position = \"bottom\",\n        legend.key.width = unit(30, \"pt\"))\n\n\nggplot() +\n  geom_spatraster(data = elev &gt; 10) +\n  ggtitle(\"elev &gt; 10\") +\n paletteer::scale_fill_paletteer_d(\"ggsci::alternating_igv\") +\n  theme(legend.position = \"bottom\",\n        legend.key.width = unit(30, \"pt\"))\n\n\n\n\n\n\n\n\n\n\n(a) elev\n\n\n\n\n\n\n\n\n\n\n\n(b) elev^2\n\n\n\n\n\n\n\n\n\n\n\n(c) log2(elev)\n\n\n\n\n\n\n\n\n\n\n\n(d) elev &gt; 10\n\n\n\n\n\n\nFigure 8\n\n\n\n\n\nEfficient alternatives for operations:\n\napp(): The app() function in the {terra} package applies a user-defined or pre-existing function to each cell’s values of a SpatRaster, treating layers as columns in a matrix. Functions should return outputs divisible by the total cell count.\ntapp(): The tapp() function in the {terra} package applies a function to subsets of layers in a SpatRaster grouped by an index. It allows for aggregation or summarization of layers based on grouping criteria such as indices, time periods (e.g., “years”, “months”), or custom functions.\nlapp(): The lapp() function in the {terra} package applies a user-defined function to the layers of a SpatRaster or SpatRasterDataset, treating each layer as an argument to the function. The function must accept a vector of layer values and return a vector or matrix of the same or compatible size. This is useful for combining or transforming layers, such as performing arithmetic operations between them. An example of lapp() is the NDVI Calculation:\n\nNDVI (Normalized Difference Vegetation Index) is a local operation to assess vegetation:\n\nFormula: (NIR - Red) / (NIR + Red).\n\nCalculated from satellite data (e.g., Landsat 8) with red and NIR bands.\n\nPositive NDVI values (&gt; 0.2) indicate vegetation.\nLargest values correspond to dense forests, while lowest values are related to lakes and snowy areas.\n\n\n\n\n\nmulti_rast = system.file(\"raster/landsat.tif\", package = \"spDataLarge\")\nmulti_rast = rast(multi_rast)\n# Rescale values to actual values (stored integers to save disk space)\nmulti_rast = (multi_rast * 0.0000275) - 0.2\n# Remove negative values due to clouds etc.\nmulti_rast[multi_rast &lt; 0] = 0\nobject.size(multi_rast)\n\n1304 bytes\n\nndvi_fun = function(nir, red){\n  (nir - red) / (nir + red)\n}\n\nndvi_rast = lapp(multi_rast[[c(4, 3)]], fun = ndvi_fun)\n\nggplot() +\n  geom_spatraster(\n    data = ndvi_rast,\n    mapping = aes(fill = lyr1)\n  ) +\n  paletteer::scale_fill_paletteer_c(\n    \"grDevices::Terrain 2\",\n    direction = -1,\n    limits = c(0, 1),\n    oob = scales::squish\n  ) +\n  labs(\n    title = \"Zion National Park - Satellite Photo Raster\",\n    subtitle = \"Using custom nvdi_fun() to find NVDI\\nand plot vegetation areas in {ggplot2}\",\n    fill = NULL\n  ) +\n  theme(\n    legend.position = \"bottom\",\n    legend.key.width = unit(40, \"pt\")\n  )\n\n\n\n\n\n\n\n\n\n\n4.3.4 Focal operations\n\nFocal operations consider a central cell and its neighbours within a defined neighbourhood (kernel, filter, or moving window).\n\nCommon neighbourhood size: 3x3 cells (central cell + 8 neighbours), but customizable sizes and shapes are supported.\nThe operation aggregates values within the neighbourhood and assigns the result to the central cell, iterating across all cells.\n\nImplementation in R:\n\nUse the focal() function to perform spatial filtering Figure 9. Parameters:\n\nw: Defines the weights of the moving window using a matrix, example in Figure 9 (c).\nfun: Specifies the aggregation function (e.g., min, sum, mean, var), as in Figure 9 (b)\n\n\nApplications:\n\nSpatial filtering or convolution for raster operations.\nLow-pass filters:\n\nUse the mean function to smooth and reduce extreme values.\nFor categorical data, replace the mean with the mode (most common value).\n\nHigh-pass filters:\n\nEnhance features using methods like Laplace or Sobel filters (e.g., line detection).\n\nTerrain processing:\n\nCompute topographic characteristics like slope, aspect, and flow directions using focal functions.\n\n\n\n\nggplot() +\n  geom_spatraster(data = elev) +\n  labs(title = \"elev SpatRaster\", caption = \"data: {spData}\")\n\nggplot() +\n  geom_spatraster(\n    data = elev |&gt; \n        terra::focal(\n        w = matrix(rep(1, 9), 3, 3),\n        fun = min\n      )\n  ) +\n  labs(title = \"Focal operation min on a 3X3 matric\",\n       subtitle = \"Simple min() function with na.rm = FALSE\")\n\nggplot() +\n  geom_spatraster(\n    data = elev |&gt; \n        terra::focal(\n        # Sobel filters (for edge detection):\n        w = matrix(c(-1,-2,-1,0,0,0,1,2,1), nrow = 3),\n        fun = mean,\n        na.rm = TRUE\n      )\n  ) +\n  labs(\n    title = \"Focal operation min on a 3X3 matric\",\n    subtitle = \"Sobel filter matrix for edge detection, with mean() function\"\n  )\n\n\n\n\n\n\n\n\n\n\n(a) Original elev raster\n\n\n\n\n\n\n\n\n\n\n\n(b) Focal operation with min() and a simple matrix of equal weights\n\n\n\n\n\n\n\n\n\n\n\n(c) Focal operation with mean() and a sobel filter matrix for edge detection\n\n\n\n\n\n\nFigure 9: Focal operations on Rasters using terra::focal()\n\n\n\n\n\n\n4.3.5 Zonal operations\n\nZonal operations aggregate raster cell values based on zones defined by a second raster with categorical values. Unlike focal operations, zones in zonal operations do not require neighboring cells to be adjacent.\nKey Characteristics:\n\nThe zonal() function in the terra package computes zonal statistics by summarizing the values of a SpatRaster for each “zone” defined by another SpatRaster. It applies a specified function (fun, e.g., mean, sum) to aggregate the data for each zone.\nThe result is typically a summary table, grouped by zones. Zones are defined by a secondary raster.\nOptional Output: A raster with calculated statistics for each zone can be generated by setting as.raster = TRUE.\n\nUsage:\n\nIdeal for summarizing raster values based on irregularly spread categorical zones.\nCommonly used in land classification, soil analysis, and other spatial analyses where zones are pre-defined.\n\n\nggplot() +\n  geom_spatraster(data = elev) +\n  labs(title = \"elev SpatRaster\", caption = \"data: {spData}\")\n  \n\nggplot() +\n  geom_spatraster(data = grain) +\n  labs(title = \"grain SpatRaster\", caption = \"data: {spData}\")\n\n\n\n\n\n\n\n\n\n\n\n(a) elev\n\n\n\n\n\n\n\n\n\n\n\n(b) grain\n\n\n\n\n\n\n\nFigure 10: The elev and grain rasters\n\n\n\n\nelev |&gt; \n  terra::zonal(\n    z = grain,\n    fun = mean\n  ) |&gt; \n  as_tibble()\n\n# A tibble: 3 × 2\n  grain  elev\n  &lt;chr&gt; &lt;dbl&gt;\n1 clay   14.8\n2 silt   21.2\n3 sand   18.7\n\n\n\n\n4.3.6 Global operations and distances\n\nGlobal operations consider the entire raster dataset as a single zone.\nCommon operations include:\n\nDescriptive statistics: Minimum, maximum, etc.\nDistance calculations: Compute distance from each cell to a target cell using terra::distance(). The terra::distance() function calculates the shortest distance from each cell in a raster to a set of target cells, which are identified based on a condition (e.g., where raster values are non-NA, equal to a specific value, or greater than a threshold). This is useful for spatial analysis, such as finding proximity to certain features or zones in a raster.\nWeighted distances: Factor in additional variables, such as elevation, to modify distance calculations.\nVisibility and viewshed analysis: Assess visible areas from a specific point.\n\nApplications:\n\nDistance to coastlines or other target areas.\nTopography-aware distance calculations.\nAdvanced spatial modeling like visibility analysis.\n\n\n\n# Create a sample SpatRaster\nr &lt;- rast(ncols = 10, nrows = 10, \n          xmin = 0, xmax = 10, \n          ymin = 0, ymax = 10)\nvalues(r) &lt;- NA\nvalues(r)[c(5, 15, 25)] &lt;- 1  # Assign specific cells as targets\n\n# Compute the distance to the non-NA cells\ndist_raster &lt;- distance(r)\n\n\n|---------|---------|---------|---------|\n=========================================\n                                          \n\ndist_raster &lt;- dist_raster * 1e-5\n\n# View the raster\nggplot() +\n  geom_spatraster(data = r) +\n  labs(title = \"Original Raster (Targets in Blue)\") +\n  theme(\n    legend.position = \"bottom\"\n  )\n\n# View the distance raster\nggplot() +\n  geom_spatraster(data = dist_raster) +\n  labs(title = \"Distance to Targets (in units)\",\n       fill = \"Distance in Degrees\") +\n  paletteer::scale_fill_paletteer_c(\"ggthemes::Red-Gold\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\n\n\n(a) Original raster\n\n\n\n\n\n\n\n\n\n\n\n(b) Distance raster\n\n\n\n\n\n\n\nFigure 11: Using the terra::distance()\n\n\n\n\n\n4.3.7 Map algebra counterparts in vector processing\n\nEquivalence between raster and vector operations:\n\nDistance raster (global operation) ≈ Buffer operation (vector) (Section 5.2.5).\nRaster reclassification ≈ Dissolving vector boundaries (Section 4.2.5).\nRaster overlay with masks ≈ Vector clipping (Section 5.2.5).\nZonal operations ≈ Aggregating vector geometries by zones.\n\n\n\n\n4.3.8 Merging rasters\n\nCombines multiple raster datasets into a single raster. Often required for datasets spanning multiple spatial scenes (e.g., satellite imagery, elevation data).\nmerge():\n\nPlaces rasters side by side.\nFor overlapping areas, prioritizes values from the first raster.\n\n\n\naut &lt;- geodata::elevation_30s(country = \"AUT\", path = tempdir())\nggplot() +\n  geom_spatraster(data = aut) +\n  scale_fill_wiki_c() +\n  ggtitle(\"Austria\")\n\n\n\n\n\n\n\ncze &lt;- geodata::elevation_30s(country = \"CZE\", path = tempdir())\nggplot() +\n  geom_spatraster(data = cze) +\n  scale_fill_wiki_c() +\n  ggtitle(\"Czechia\")\n\n\n\n\n\n\n\nsvk &lt;- geodata::elevation_30s(country = \"SVK\", path = tempdir())\nggplot() +\n  geom_spatraster(data = svk) +\n  scale_fill_wiki_c() +\n  ggtitle(\"Slovakia\")\n\n\n\n\n\n\n\naut_cze_svk &lt;- aut |&gt; \n  merge(svk) |&gt; \n  merge(cze)\n\nggplot() +\n  geom_spatraster(data = aut_cze_svk) +\n  scale_fill_wiki_c() +\n  ggtitle(\"Austria, Czechia and Slovakia\")\n\n\n\n\n\n\n\n\n\nmosaic():\n\nHandles overlaps by applying a function (e.g., mean) to the overlapping area.\nHelps smooth visible borders but may not eliminate them entirely."
  },
  {
    "objectID": "geocomputation/elevation_raster_maps.html",
    "href": "geocomputation/elevation_raster_maps.html",
    "title": "Using {geodata} to get elevation raster maps",
    "section": "",
    "text": "The geodata R package (Hijmans et al. 2024) provides functions to download elevation data for any country, primarily sourced from the Shuttle Radar Topography Mission (SRTM). The elevation_3s function retrieves high-resolution elevation data (approximately 90 meters, i.e., 3 arc seconds) for specified coordinates, while elevation_30s offers coarser resolution data (about 1 kilometre, i.e., 30 arc seconds) for entire countries. For global coverage, elevation_global allows users to obtain elevation data at resolutions ranging from 0.5 to 10 arc-minutes. These datasets are essential for various geospatial analyses, including topographic assessments and environmental modelling.\n\n\nCode\n# Load spatial and environmental datasets.\nlibrary(geodata)\n\n# Handle, analyze, and visualize raster and vector data.\nlibrary(terra)\n\n# Tidy data workflows with 'terra' objects.\nlibrary(tidyterra)\n\n# Data manipulation, visualization, and wrangling.\nlibrary(tidyverse)"
  },
  {
    "objectID": "geocomputation/elevation_raster_maps.html#package-geodata",
    "href": "geocomputation/elevation_raster_maps.html#package-geodata",
    "title": "Using {geodata} to get elevation raster maps",
    "section": "",
    "text": "The geodata R package (Hijmans et al. 2024) provides functions to download elevation data for any country, primarily sourced from the Shuttle Radar Topography Mission (SRTM). The elevation_3s function retrieves high-resolution elevation data (approximately 90 meters, i.e., 3 arc seconds) for specified coordinates, while elevation_30s offers coarser resolution data (about 1 kilometre, i.e., 30 arc seconds) for entire countries. For global coverage, elevation_global allows users to obtain elevation data at resolutions ranging from 0.5 to 10 arc-minutes. These datasets are essential for various geospatial analyses, including topographic assessments and environmental modelling.\n\n\nCode\n# Load spatial and environmental datasets.\nlibrary(geodata)\n\n# Handle, analyze, and visualize raster and vector data.\nlibrary(terra)\n\n# Tidy data workflows with 'terra' objects.\nlibrary(tidyterra)\n\n# Data manipulation, visualization, and wrangling.\nlibrary(tidyverse)"
  },
  {
    "objectID": "geocomputation/elevation_raster_maps.html#getting-world-elevation-map",
    "href": "geocomputation/elevation_raster_maps.html#getting-world-elevation-map",
    "title": "Using {geodata} to get elevation raster maps",
    "section": "Getting World Elevation Map",
    "text": "Getting World Elevation Map\nThis code downloads global elevation data at a 10-degree resolution using the geodata package, calculates its memory size in R, and visualizes it using ggplot2. The geom_spatraster function plots the raster data, applying a colour scale with squished limits (0-6000 meters), and customizes the map’s title, subtitle, and legend placement.\n\n\nCode\nworld &lt;- geodata::elevation_global(10, path = tempdir())\n\n# With ggplot2\ng &lt;- ggplot() +\n  geom_spatraster(data = world) +\n  scale_fill_wiki_c(\n    limits = c(0, 6000),\n    oob = scales::squish\n  ) +\n  labs(\n    title = \"World Elevation Map\",\n    subtitle = \"Resolution of 10 degrees\",\n    fill = \"Elevation (metres)\"\n  ) +\n  theme(\n    legend.position = \"bottom\",\n    legend.key.width = unit(50, \"pt\")\n  )\n\nggsave(\n  plot = g,\n  filename = here::here(\"geocomputation\",\n                        \"images\",\n                        \"elevation_raster_maps_1.png\"),\n  height = 1400,\n  width = 2000,\n  units = \"px\"\n)\n\n\n\n\n\n\n\n\nFigure 1: A simple elevation map of the world using data from {geodata} and geom_spatraster() from {terra}"
  },
  {
    "objectID": "geocomputation/elevation_raster_maps.html#countries-in-geodata",
    "href": "geocomputation/elevation_raster_maps.html#countries-in-geodata",
    "title": "Using {geodata} to get elevation raster maps",
    "section": "Countries in {geodata}",
    "text": "Countries in {geodata}\nThis code retrieves country codes from the geodata package, converts them into a tibble, and displays them in a styled, interactive table using the gt package. Column labels are formatted with snakecase and stringr, missing values are replaced with blank text, and a custom theme with a header title is applied for presentation.\n\n\nCode\ngeodata::country_codes() |&gt; \n  as_tibble() |&gt; \n  gt::gt() |&gt;\n  gt::cols_label_with(fn = snakecase::to_title_case) |&gt; \n  gt::cols_label_with(fn = str_to_upper) |&gt;\n  gt::sub_missing(missing_text = \"\") |&gt; \n  gt::opt_interactive() |&gt; \n  gtExtras::gt_theme_538() |&gt; \n  gt::tab_header(\n    title = \"List of countries available in {geodata}\"\n  )\n\n\n\n\nTable 1\n\n\n\n\n\n\nList of countries available in {geodata}"
  },
  {
    "objectID": "geocomputation/elevation_raster_maps.html#country-specific-raster-elevation-maps",
    "href": "geocomputation/elevation_raster_maps.html#country-specific-raster-elevation-maps",
    "title": "Using {geodata} to get elevation raster maps",
    "section": "Country-specific raster elevation maps",
    "text": "Country-specific raster elevation maps\nThis code downloads 30-arc-second resolution elevation data for Switzerland using the geodata package and visualizes it with ggplot2. The elevation is displayed as a raster map with a colour scale capped at 6000 meters, custom titles, subtitles, and a bottom-positioned legend with an adjusted width.\n\n\nCode\n# Taking a smaller country to save data download time\nswitzerland_raster &lt;- geodata::elevation_30s(\n  country = \"CHE\", \n  path = tempdir()\n  )\n\n# With ggplot2\ng &lt;- ggplot() +\n  geom_spatraster(data = switzerland_raster) +\n  scale_fill_wiki_c(\n    limits = c(0, 6000),\n    oob = scales::squish\n  ) +\n  labs(\n    title = \"Elevation Map of Switzerland\",\n    subtitle = \"Resolution of approx. 1 km (30 arc seconds)\",\n    fill = \"Elevation (metres)\"\n  ) +\n  theme(\n    legend.position = \"bottom\",\n    legend.key.width = unit(50, \"pt\")\n  )\n\nggsave(\n  plot = g,\n  filename = here::here(\"geocomputation\",\n                        \"images\",\n                        \"elevation_raster_maps_2.png\"),\n  height = 1400,\n  width = 2000,\n  units = \"px\"\n)\n\n\n\n\n\n\n\n\nFigure 2: Base raster map of Switzerland from {geodata}"
  },
  {
    "objectID": "geocomputation/elevation_raster_maps.html#getting-outline-map-of-switzerland-sf",
    "href": "geocomputation/elevation_raster_maps.html#getting-outline-map-of-switzerland-sf",
    "title": "Using {geodata} to get elevation raster maps",
    "section": "Getting outline map of Switzerland {sf}",
    "text": "Getting outline map of Switzerland {sf}\nThis code creates two visualizations of Switzerland using ggplot2. The first plot is a vector map generated from the {rnaturalearth} package, displaying Switzerland’s boundaries at a large scale (1:10 million). The second plot combines this vector boundary with a high-resolution raster elevation map from switzerland_raster, highlighting elevation levels up to 6000 meters. The raster data is overlaid with a transparent outline of Switzerland and utilizes a squished colour scale for elevation visualization.\n\n\nCode\nswitzerland_vector &lt;- rnaturalearth::ne_countries(\n  country = \"Switzerland\",\n  returnclass = \"sf\",\n  scale = \"large\"\n)\n\ng &lt;- ggplot() +\n  geom_sf(data = switzerland_vector) +\n  labs(\n    title = \"Vector Map of Switzerland from {rnaturalearth}\",\n    subtitle = \"Scale of 1:10 million\",\n    fill = \"Elevation (metres)\"\n  )\n\nggsave(\n  plot = g,\n  filename = here::here(\"geocomputation\",\n                        \"images\",\n                        \"elevation_raster_maps_3.png\"),\n  height = 1400,\n  width = 2000,\n  units = \"px\"\n)\n\ng &lt;- ggplot() +\n  geom_spatraster(data = switzerland_raster) +\n  geom_sf(\n    data = switzerland_vector,\n    linewidth = 1, \n    fill = NA,\n    colour = \"black\",\n    alpha = 0.8\n  ) +\n  coord_sf(\n    crs = 4326\n  ) +\n  scale_fill_wiki_c(\n    limits = c(0, 6000),\n    oob = scales::squish\n  ) +\n  labs(\n    title = \"Elevation Map of Switzerland\",\n    subtitle = \"Overlaid with a vector map with geom_sf()\",\n    fill = \"Elevation (metres)\"\n  ) +\n  theme(\n    legend.position = \"bottom\",\n    legend.key.width = unit(40, \"pt\")\n  )\n\n\nggsave(\n  plot = g,\n  filename = here::here(\"geocomputation\",\n                        \"images\",\n                        \"elevation_raster_maps_4.png\"),\n  height = 1400,\n  width = 2000,\n  units = \"px\"\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Switzerland: Vector map using geom_sf{}\n\n\n\n\n\n\n\n\n\n\n\n(b) Vector map of Switzerland, plotted using {sf}, overlaid with a raster map, plotted using {terra}\n\n\n\n\n\n\n\nFigure 3"
  },
  {
    "objectID": "geocomputation/elevation_raster_maps.html#raster-operations-spatial-subsetting",
    "href": "geocomputation/elevation_raster_maps.html#raster-operations-spatial-subsetting",
    "title": "Using {geodata} to get elevation raster maps",
    "section": "Raster Operations: Spatial Subsetting",
    "text": "Raster Operations: Spatial Subsetting\nThis code calculates the mean elevation of Switzerland using a raster dataset and filters the raster to show only areas above 2000 meters. It then visualizes these high-altitude regions as a raster map overlaid with Switzerland’s vector boundaries using ggplot2. The map employs a custom color palette, minimal theme, and detailed labels, emphasizing Switzerland’s mountain ranges above 2000 meters elevation.\n\n# Mean elevation above Sea Level in Switzerland\nswitzerland_raster |&gt; \n  values() |&gt; \n  as_tibble() |&gt; \n  summarise(mean = mean(CHE_elv_msk, na.rm = T)) |&gt; \n  pull(mean)\n\n#&gt; [1] 1289.186\n\nThe mean elevation of Switzerland is 1,289.19 metres.\n\n\nCode\n# Plotting only those portions of Switzerland that are above 2000 metres above sea level\nswit_mountains &lt;- switzerland_raster &gt; 2000\nswit_mountains &lt;- switzerland_raster[swit_mountains, drop = FALSE]\n\ng &lt;- ggplot() +\n  geom_spatraster(data = swit_mountains) +\n  geom_sf(\n    data = switzerland_vector,\n    linewidth = 1, \n    fill = NA,\n    colour = \"black\",\n    alpha = 0.8\n  ) +\n  coord_sf(\n    crs = 4326\n  ) +\n  paletteer::scale_fill_paletteer_c(\n    \"ggthemes::Brown\",\n    na.value = \"transparent\"\n    ) +\n  labs(\n    title = \"Switzerland mountain ranges\",\n    subtitle = \"Only showing areas above 2000 metres elevation\",\n    fill = \"Elevation (metres)\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    legend.key.width = unit(40, \"pt\")\n  )\n\n\nggsave(\n  plot = g,\n  filename = here::here(\"geocomputation\",\n                        \"images\",\n                        \"elevation_raster_maps_5.png\"),\n  height = 1400,\n  width = 2000,\n  units = \"px\"\n)\n\n\n\n\n\n\n\n\nFigure 4: Subsetting rasters: Displaying areas in Switzerland with altitude over 2000 metres"
  },
  {
    "objectID": "geocomputation/elevation_raster_maps.html#computing-distance-from-highest-point-in-switzerland",
    "href": "geocomputation/elevation_raster_maps.html#computing-distance-from-highest-point-in-switzerland",
    "title": "Using {geodata} to get elevation raster maps",
    "section": "Computing distance from highest point in Switzerland",
    "text": "Computing distance from highest point in Switzerland\nThis code identifies Switzerland’s highest elevation point at 4442 meters and filters for all three raster points above 4200 meters. It calculates distances from these points (and removes non-Switzerland areas: this is work-in-progress). Finally, it visualizes these extreme elevations on a map using ggplot2, overlaying the filtered raster data with Switzerland’s vector boundaries. The plot employs a custom brown color palette and highlights the topographic peaks within Switzerland exceeding 4200 meters.\n\n\nCode\n# Highest Point in Switzerland\nswitzerland_raster |&gt; \n  values() |&gt; \n  max(na.rm = TRUE)\n\n# It is 4442 metres above sea level.\n\n# Let us select all points above 4200 metres\nswit_4200 &lt;- switzerland_raster == 4442\nswit_4200 &lt;- switzerland_raster[swit_4200, drop = FALSE]\nswit_4200 &lt;- terra::distance(swit_4200)\nswit_4200 &lt;- swit_4200 / 1000\n\n# Remove non-Switzerland area\nvalues(swit_4200) &lt;- tibble(\n  dist = values(swit_4200),\n  actual = values(switzerland_raster)\n) |&gt; \n  mutate(\n    masked = if_else(\n      is.nan(actual),\n      NA,\n      dist\n    )\n  ) |&gt; \n  pull(masked)\n\n# Plotting the three points in Switzerland above 4200 m\ng &lt;- ggplot() +\n  geom_spatraster(data = swit_4200) +\n  coord_sf(\n    crs = 4326\n  ) +\n  paletteer::scale_fill_paletteer_c(\n    \"grDevices::Inferno\",\n    direction = -1,\n    na.value = \"transparent\"\n  ) +\n  labs(\n    title = \"Distance to Switzerland's highest points\",\n    subtitle = \"Distance from the highest points (&gt;4200 m elevation)\",\n    fill = \"Distance (km)\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    legend.key.width = unit(40, \"pt\")\n  )\n\n\nggsave(\n  plot = g,\n  filename = here::here(\"geocomputation\",\n                        \"images\",\n                        \"elevation_raster_maps_6.png\"),\n  height = 1400,\n  width = 2000,\n  units = \"px\"\n)\n\n\n\n\n\n\n\n\nFigure 5: Distance from the highest point in Switzerland"
  },
  {
    "objectID": "geocomputation/elevation_raster_maps.html#next-steps",
    "href": "geocomputation/elevation_raster_maps.html#next-steps",
    "title": "Using {geodata} to get elevation raster maps",
    "section": "Next steps",
    "text": "Next steps\nStudy this page, and write more about other awesome functions in {geodata}."
  },
  {
    "objectID": "geocomputation/chapter4.html#exercises",
    "href": "geocomputation/chapter4.html#exercises",
    "title": "Chapter 4: Spatial data operations",
    "section": "4.4 Exercises",
    "text": "4.4 Exercises\n\nE1.\nIt was established in Section 4.2 that Canterbury was the region of New Zealand containing most of the 101 highest points in the country. How many of these high points does the Canterbury region contain?\nCanterbury contains 70 of these high points.\n\ndata(\"nz\")\ndata(\"nz_height\")\n\nnz_height |&gt; \n  st_intersection(\n    nz |&gt; filter(Name == \"Canterbury\")\n  ) |&gt; \n  nrow()\n\n[1] 70\n\n\nBonus: plot the result using the plot() function to show all of New Zealand, canterbury region highlighted in yellow, high points in Canterbury represented by red crosses (hint: pch = 7) and high points in other parts of New Zealand represented by blue circles. See the help page ?points for details with an illustration of different pch values.\n\nnz_height |&gt; \n  mutate(\n    in_canterbury = nz_height |&gt; \n      st_intersects(\n        nz |&gt; filter(Name == \"Canterbury\"),\n        sparse = FALSE\n      )\n  ) |&gt; \n  ggplot() +\n  geom_sf(\n    data = nz |&gt; mutate(fill_var = Name == \"Canterbury\"),\n    mapping = aes(fill = fill_var)\n  ) +\n  geom_sf(\n    mapping = aes(shape = in_canterbury, colour = in_canterbury)\n  ) +\n  scale_shape_manual(values = c(16, 4)) +\n  scale_colour_manual(values = c(\"blue\", \"red\")) +\n  scale_fill_manual(values = c(\"transparent\", \"yellow\")) +\n  labs(\n    fill = \"Is the region Canterbury?\",\n    colour = \"Peaks are in Canterbury?\",\n    shape = \"Peaks are in Canterbury?\"\n  ) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\n\n\nE2.\nWhich region has the second highest number of nz_height points, and how many does it have?\nThe region with second highest number of nz_height points is West Coast. It has 22 such points.\n\nnz_height |&gt; \n  st_join(nz) |&gt; \n  st_drop_geometry() |&gt; \n  group_by(Name) |&gt; \n  count()\n\n# A tibble: 7 × 2\n# Groups:   Name [7]\n  Name                  n\n  &lt;chr&gt;             &lt;int&gt;\n1 Canterbury           70\n2 Manawatu-Wanganui     2\n3 Marlborough           1\n4 Otago                 2\n5 Southland             1\n6 Waikato               3\n7 West Coast           22\n\n\n\n\n\nE3.\nGeneralizing the question to all regions: how many of New Zealand’s 16 regions contain points which belong to the top 101 highest points in the country? Which regions?\n\nBonus: create a table listing these regions in order of the number of points and their name.\n\nSeven (7) regions of New Zealand contain points which belong to top 101 highest points in the country. The table is shown below.\n\nnz_height |&gt; \n  st_join(nz) |&gt; \n  st_drop_geometry() |&gt; \n  group_by(Name) |&gt; \n  count(name = \"Number of points\", sort = T) |&gt; \n  ungroup() |&gt; \n  mutate(`S.No.` = row_number()) |&gt; \n  relocate(`S.No.`) |&gt;\n  gt::gt() |&gt; \n  gtExtras::gt_theme_538() |&gt; \n  gt::tab_header(\n    title = \"Number of highest points in each region of New Zealand\"\n  )\n\n\n\nTable 2: Table listing the regions\n\n\n\n\n\n\n\n\n\nNumber of highest points in each region of New Zealand\n\n\nS.No.\nName\nNumber of points\n\n\n\n\n1\nCanterbury\n70\n\n\n2\nWest Coast\n22\n\n\n3\nWaikato\n3\n\n\n4\nManawatu-Wanganui\n2\n\n\n5\nOtago\n2\n\n\n6\nMarlborough\n1\n\n\n7\nSouthland\n1\n\n\n\n\n\n\n\n\n\n\n\nTest your knowledge of spatial predicates by finding out and plotting how US states relate to each other and other spatial objects.\n\n\nE4.\nThe starting point of this exercise is to create an object representing Colorado state in the USA. Do this with the command colorado = us_states[us_states$NAME == \"Colorado\",] (base R) or with the filter() function (tidyverse) and plot the resulting object in the context of US states.\n\ndata(\"us_states\")\n\ncolorado &lt;- us_states |&gt; \n  filter(NAME == \"Colorado\")\n\nggplot() +\n  geom_sf(data = colorado) +\n  ggtitle(\"Map of Colorado State\") +\n  coord_sf(\n    crs = \"EPSG:5070\"\n  )\n\n\n\n\n\n\n\nFigure 12: Map of Colorado State\n\n\n\n\n\n\nCreate a new object representing all the states that geographically intersect with Colorado and plot the result (hint: the most concise way to do this is with the subsetting method [).\n\n\nggplot() +\n  geom_sf(\n    data = us_states,\n    fill = \"transparent\"\n  ) +\n  geom_sf(\n    data = colorado,\n    fill = \"yellow\"\n  ) +\n  geom_sf_text(\n    data = colorado,\n    mapping = aes(\n      label = NAME\n    ),\n    family = \"caption_font\",\n    fontface = \"bold\"\n  ) +\n  coord_sf(\n    crs = \"EPSG:5070\"\n  ) +\n  labs(\n    x = NULL, y = NULL,\n    title = \"Map of USA states, with Colorado highlighted\"\n  )\n\n\n\n\n\n\n\nFigure 13: Colorado, within USA’s states; with projection changed to Albers Equal Area Projection\n\n\n\n\n\n\nCreate another object representing all the objects that touch (have a shared boundary with) Colorado and plot the result (hint: remember you can use the argument op = st_intersects and other spatial relations during spatial subsetting operations in base R).\n\n\nbordering &lt;- us_states |&gt; \n  mutate(\n    border_colorado = as_vector(\n      as_vector(\n        us_states |&gt; \n        st_intersects(colorado, sparse = FALSE)\n      )\n    )\n  )\n\nggplot() +\n  geom_sf(\n    data = bordering,\n    mapping = aes(\n      fill = border_colorado\n    )\n  ) +\n  scale_fill_manual(\n    values = c(\"transparent\", \"orange\")\n  ) +\n  geom_sf_text(\n    data = filter(bordering, border_colorado),\n    mapping = aes(\n      label = NAME\n    ),\n    family = \"caption_font\"\n  ) +\n  geom_sf(\n    data = colorado,\n    fill = \"red\"\n  ) +\n  geom_sf_text(\n    data = colorado,\n    mapping = aes(\n      label = NAME\n    ),\n    family = \"caption_font\",\n    fontface = \"bold\"\n  ) +\n  coord_sf(\n    crs = \"EPSG:5070\"\n  ) +\n  labs(\n    x = NULL, y = NULL,\n    title = \"Map of USA states, with states bordering Colorado highlighted in orange\"\n  ) +\n  theme(\n    legend.position = \"none\"\n  )\n\n\n\n\n\n\n\n\n\nBonus: create a straight line from the centroid of the District of Columbia near the East coast to the centroid of California near the West coast of the USA (hint: functions st_centroid(), st_union() and st_cast() described in Chapter 5 may help) and identify which states this long East-West line crosses.\n\n\nwdc_centre &lt;- st_centroid(\n  us_states |&gt; filter(NAME == \"District of Columbia\")\n) |&gt; \n  pull(geometry)\n\ncal_centre &lt;- st_centroid(\n  us_states |&gt; filter(NAME == \"California\")\n) |&gt; \n  pull(geometry)\n\nstraight_line &lt;- st_union(\n  wdc_centre,\n  cal_centre\n) |&gt; \n  st_cast(\n    \"LINESTRING\"\n  )\n\nus_states |&gt; \n  mutate(\n    on_the_way = as_vector(\n      st_intersects(\n        us_states, \n        straight_line, \n        sparse = FALSE\n      )\n    )\n  ) |&gt; \n  ggplot() +\n  geom_sf(\n    mapping = aes(\n      fill = on_the_way\n    )\n  ) +\n  scale_fill_manual(\n    values = c(\"transparent\", \"orange\")\n  ) +\n  geom_sf(\n    data = straight_line,\n    linewidth = 0.5\n  ) +\n  geom_sf(\n    data = cal_centre,\n    size = 2\n  ) +\n  geom_sf(\n    data = wdc_centre,\n    size = 2\n  ) +\n  coord_sf(\n    crs = \"EPSG:5070\"\n  ) +\n  labs(\n    subtitle = \"Line from Centroids of District of Columbia and California;\\nand highlighting the states that it crosses through\"\n  ) +\n  theme(\n    legend.position = \"none\"\n  )\n\n\n\n\n\n\n\n\n\n\n\nE5.\nUse dem = rast(system.file(\"raster/dem.tif\", package = \"spDataLarge\")), and reclassify the elevation in three classes: low (&lt;300), medium and high (&gt;500). Secondly, read the NDVI raster (ndvi = rast(system.file(\"raster/ndvi.tif\", package = \"spDataLarge\"))) and compute the mean NDVI and the mean elevation for each altitudinal class.\n\ndem &lt;- rast(system.file(\"raster/dem.tif\", package = \"spDataLarge\"))\n\nggplot() +\n  geom_spatraster(data = dem) +\n  paletteer::scale_fill_paletteer_c(\"grDevices::Terrain 2\")\n\n\n\n\n\n\n\n\n\n\n\nE6.\nApply a line detection filter to rast(system.file(\"ex/logo.tif\", package = \"terra\")). Plot the result. Hint: Read ?terra::focal().\n\n\n\nE7.\nCalculate the Normalized Difference Water Index (NDWI; (green - nir)/(green + nir)) of a Landsat image. Use the Landsat image provided by the spDataLarge package (system.file(\"raster/landsat.tif\", package = \"spDataLarge\")). Also, calculate a correlation between NDVI and NDWI for this area (hint: you can use the layerCor() function).\n\n\n\nE8.\nA StackOverflow post (stackoverflow.com/questions/35555709) shows how to compute distances to the nearest coastline using raster::distance(). Try to do something similar but with terra::distance(): retrieve a digital elevation model of Spain, and compute a raster which represents distances to the coast across the country (hint: use geodata::elevation_30s()). Convert the resulting distances from meters to kilometers. Note: it may be wise to increase the cell size of the input raster to reduce compute time during this operation (aggregate()).\nE9. Try to modify the approach used in the above exercise by weighting the distance raster with the elevation raster; every 100 altitudinal meters should increase the distance to the coast by 10 km. Next, compute and visualize the difference between the raster created using the Euclidean distance (E7) and the raster weighted by elevation."
  },
  {
    "objectID": "geocomputation/crs_projections.html",
    "href": "geocomputation/crs_projections.html",
    "title": "Various CRS projections for use with {sf} plots in {ggplot2}",
    "section": "",
    "text": "No.\nProjection Name\nEPSG /ESRI Code\nExample & coord_sf() code\nDescription\nUse Case\n\n\n\n\n1\nWGS 84 (Geographic)\n4326\nFigure 1\nEPSG:4326\nDefault geographic coordinate system using latitude and longitude.\nWorking with raw geographic coordinates.\n\n\n2\nWeb Mercator\n3857\nFigure 2\nEPSG:3857\nUsed by most web mapping services like Google Maps, OpenStreetMap.\nVisualizing data on interactive maps or raster tiles.\n\n\n3\nUTM Zone 33N\n32633\nFigure 3\nEPSG:32633\nUniversal Transverse Mercator for Zone 33 North (WGS 84).\nDetailed mapping with minimal distortion for Zone 33N.\n\n\n4\nUTM Zone 33S\n32733\nFigure 4\nEPSG:32733\nUniversal Transverse Mercator for Zone 33 South (WGS 84).\nDetailed mapping with minimal distortion for Zone 33S.\n\n\n5\nNAD83\n4269\nFigure 5\nEPSG:4269\nNorth American Datum 1983.\nStandard for North American datasets.\n\n\n6\nETRS89 / LAEA Europe\n3035\nFigure 6\nEPSG:3035\nLambert Azimuthal Equal Area projection for Europe.\nMapping datasets across Europe with minimal area distortion.\n\n\n7\nWGS 84 / Pseudo-Mercator\n3857\nFigure 7\nEPSG:3857\nSimilar to Web Mercator but suited for global-scale applications.\nQuick global visualizations and compatibility with tile layers.\n\n\n8\nAlbers Equal Area\n5070\nFigure 8\nEPSG:5070\nAlbers Equal Area for continental-scale datasets in the US.\nUS-focused analysis with equal-area properties.\n\n\n9\nLambert Conformal Conic\n102004 (ESRI)\nFigure 9\nESRI:102004\nProjection widely used for mapping in the US.\nRegional analysis and thematic mapping in North America.\n\n\n10\nMollweide\n54009 (ESRI)\nFigure 10\nESRI:54009\nEqual-area pseudocylindrical projection for global maps.\nGlobal-scale thematic maps with equal area representation.\n\n\n11\nRobinson\n54030 (ESRI)\nFigure 11\nESRI:54030\nA compromise projection for visually pleasing world maps.\nWorld maps for general use, emphasizing aesthetics.\n\n\n12\nSinusoidal\n54008 (ESRI)\nFigure 12\nESRI:54008\nPseudocylindrical equal-area projection.\nGlobal-scale analysis with equal-area properties.\n\n\n13\nBonne\n54024 (ESRI)\nFigure 13\nESRI:54024\nEqual-area projection, often used for continents.\nRegional mapping with minimized distortion.\n\n\n14\nWorld Van der Grinten I\n54029 (ESRI)\nFigure 14\nESRI:54029\nProjection displaying the entire world in a circular format.\nAesthetic and general-purpose world maps.\n\n\n15\nPlate Carrée\n32662\nFigure 15\nEPSG:32662\nSimple projection with equally spaced latitudes and longitudes.\nBasic visualization of geographic data.\n\n\n16\nTransverse Mercator\n4326\nFigure 16\nEPSG:4326\nCylindrical projection ideal for mapping narrow regions.\nRegional and local-scale mapping (often used with UTM zones).\n\n\n17\nNorth Pole Stereographic\n3413\nFigure 17\nEPSG:3413\nStereographic projection for mapping the Arctic region.\nMapping polar data in the Arctic with minimal distortion.\n\n\n18\nSouth Pole Stereographic\n3031\nFigure 18\nEPSG:3031\nStereographic projection for mapping the Antarctic region.\nMapping polar data in the Antarctic with minimal distortion.\n\n\n19\nInterrupted Goode Homolosine\n54052 (ESRI)\nFigure 19\nESRI:54052\nComposite projection for minimal distortion of landmasses.\nGlobal mapping that emphasizes land area accuracy.\n\n\n20\nKrovak\n5514\nFigure 20\nEPSG:5514\nProjection widely used in the Czech Republic and Slovakia.\nMapping datasets specific to these regions.\n\n\n21\nAsia North Lambert Conformal\n102026 (ESRI)\nFigure 21\nESRI:102026\nLambert Conformal projection for northern Asia.\nMapping datasets across northern Asia.\n\n\n22\nAustralia Albers\n3577\nFigure 22\nEPSG:3577\nEqual-area projection for Australia.\nRegional mapping of Australia with minimized area distortion.\n\n\n\nSetting up the basic code, libraries and getting world map data\n\n\nCode\nlibrary(tidyverse)          # Data wrangling\nlibrary(sf)                 # Simple Features in R\nlibrary(rnaturalearth)      # Map data\n\nworld &lt;- ne_countries(\n  scale = \"medium\",\n  returnclass = \"sf\"\n) |&gt; \n  select(name, name_long, \n         iso_a2, iso_a3, \n         geometry, continent)"
  },
  {
    "objectID": "geocomputation/crs_projections.html#a-table-of-various-projections",
    "href": "geocomputation/crs_projections.html#a-table-of-various-projections",
    "title": "Various CRS projections for use with {sf} plots in {ggplot2}",
    "section": "",
    "text": "No.\nProjection Name\nEPSG /ESRI Code\nExample & coord_sf() code\nDescription\nUse Case\n\n\n\n\n1\nWGS 84 (Geographic)\n4326\nFigure 1\nEPSG:4326\nDefault geographic coordinate system using latitude and longitude.\nWorking with raw geographic coordinates.\n\n\n2\nWeb Mercator\n3857\nFigure 2\nEPSG:3857\nUsed by most web mapping services like Google Maps, OpenStreetMap.\nVisualizing data on interactive maps or raster tiles.\n\n\n3\nUTM Zone 33N\n32633\nFigure 3\nEPSG:32633\nUniversal Transverse Mercator for Zone 33 North (WGS 84).\nDetailed mapping with minimal distortion for Zone 33N.\n\n\n4\nUTM Zone 33S\n32733\nFigure 4\nEPSG:32733\nUniversal Transverse Mercator for Zone 33 South (WGS 84).\nDetailed mapping with minimal distortion for Zone 33S.\n\n\n5\nNAD83\n4269\nFigure 5\nEPSG:4269\nNorth American Datum 1983.\nStandard for North American datasets.\n\n\n6\nETRS89 / LAEA Europe\n3035\nFigure 6\nEPSG:3035\nLambert Azimuthal Equal Area projection for Europe.\nMapping datasets across Europe with minimal area distortion.\n\n\n7\nWGS 84 / Pseudo-Mercator\n3857\nFigure 7\nEPSG:3857\nSimilar to Web Mercator but suited for global-scale applications.\nQuick global visualizations and compatibility with tile layers.\n\n\n8\nAlbers Equal Area\n5070\nFigure 8\nEPSG:5070\nAlbers Equal Area for continental-scale datasets in the US.\nUS-focused analysis with equal-area properties.\n\n\n9\nLambert Conformal Conic\n102004 (ESRI)\nFigure 9\nESRI:102004\nProjection widely used for mapping in the US.\nRegional analysis and thematic mapping in North America.\n\n\n10\nMollweide\n54009 (ESRI)\nFigure 10\nESRI:54009\nEqual-area pseudocylindrical projection for global maps.\nGlobal-scale thematic maps with equal area representation.\n\n\n11\nRobinson\n54030 (ESRI)\nFigure 11\nESRI:54030\nA compromise projection for visually pleasing world maps.\nWorld maps for general use, emphasizing aesthetics.\n\n\n12\nSinusoidal\n54008 (ESRI)\nFigure 12\nESRI:54008\nPseudocylindrical equal-area projection.\nGlobal-scale analysis with equal-area properties.\n\n\n13\nBonne\n54024 (ESRI)\nFigure 13\nESRI:54024\nEqual-area projection, often used for continents.\nRegional mapping with minimized distortion.\n\n\n14\nWorld Van der Grinten I\n54029 (ESRI)\nFigure 14\nESRI:54029\nProjection displaying the entire world in a circular format.\nAesthetic and general-purpose world maps.\n\n\n15\nPlate Carrée\n32662\nFigure 15\nEPSG:32662\nSimple projection with equally spaced latitudes and longitudes.\nBasic visualization of geographic data.\n\n\n16\nTransverse Mercator\n4326\nFigure 16\nEPSG:4326\nCylindrical projection ideal for mapping narrow regions.\nRegional and local-scale mapping (often used with UTM zones).\n\n\n17\nNorth Pole Stereographic\n3413\nFigure 17\nEPSG:3413\nStereographic projection for mapping the Arctic region.\nMapping polar data in the Arctic with minimal distortion.\n\n\n18\nSouth Pole Stereographic\n3031\nFigure 18\nEPSG:3031\nStereographic projection for mapping the Antarctic region.\nMapping polar data in the Antarctic with minimal distortion.\n\n\n19\nInterrupted Goode Homolosine\n54052 (ESRI)\nFigure 19\nESRI:54052\nComposite projection for minimal distortion of landmasses.\nGlobal mapping that emphasizes land area accuracy.\n\n\n20\nKrovak\n5514\nFigure 20\nEPSG:5514\nProjection widely used in the Czech Republic and Slovakia.\nMapping datasets specific to these regions.\n\n\n21\nAsia North Lambert Conformal\n102026 (ESRI)\nFigure 21\nESRI:102026\nLambert Conformal projection for northern Asia.\nMapping datasets across northern Asia.\n\n\n22\nAustralia Albers\n3577\nFigure 22\nEPSG:3577\nEqual-area projection for Australia.\nRegional mapping of Australia with minimized area distortion.\n\n\n\nSetting up the basic code, libraries and getting world map data\n\n\nCode\nlibrary(tidyverse)          # Data wrangling\nlibrary(sf)                 # Simple Features in R\nlibrary(rnaturalearth)      # Map data\n\nworld &lt;- ne_countries(\n  scale = \"medium\",\n  returnclass = \"sf\"\n) |&gt; \n  select(name, name_long, \n         iso_a2, iso_a3, \n         geometry, continent)"
  },
  {
    "objectID": "geocomputation/crs_projections.html#details-on-different-projections-their-usage-examples-and-code",
    "href": "geocomputation/crs_projections.html#details-on-different-projections-their-usage-examples-and-code",
    "title": "Various CRS projections for use with {sf} plots in {ggplot2}",
    "section": "Details on different projections, their usage, examples and code",
    "text": "Details on different projections, their usage, examples and code\n\n1. WGS 84 (Geographic)\nThe WGS 84 projection, identified by EPSG:4326, is the default geographic coordinate system used for latitude and longitude. It is the most common system for raw geographic data and is widely used in GPS devices and mapping applications. This projection is excellent for datasets that involve global coverage but does not preserve area, shape, or distance due to its geographic nature.\n\n\nCode\ng &lt;- ggplot() +\n  geom_sf(data = world) +\n  coord_sf(\n    crs = \"EPSG:4326\"\n  ) +\n  theme_minimal() +\n  labs(\n    title = \"WGS 84 (Geographic) Projection\",\n    subtitle = \"EPSG:4326. Default geographic coordinate system using latitude and longitude.\"\n  )\n\nggsave(\n  plot = g,\n  filename = here::here(\"geocomputation\", \"images\",\n                        \"crs_projections_1.png\"),\n  height = 1200,\n  width = 1800,\n  units = \"px\"\n)\n\n\n\n\n\n\n\n\nFigure 1: WGS 84 (Geographic) Projection\n\n\n\n\n\n\n2. Web Mercator\nThe Web Mercator projection, represented by EPSG:3857, is widely used by web mapping platforms like Google Maps and OpenStreetMap. It is a conformal projection, meaning it preserves angles but distorts area, especially near the poles. It is best suited for interactive maps or raster tiles for visualizing data at various zoom levels.\n\n\n\n\n\n\nNote\n\n\n\nAntarctica cannot be plotted with Web Mercator projection, as it become hugely elongated. Must remove Antarctica before plotting in Web Mercator.\n\n\n\n\nCode\ng &lt;- ggplot() +\n  geom_sf(\n    data = world |&gt; \n      filter(name != \"Antarctica\")\n  ) +\n  coord_sf(\n    crs = \"EPSG:3857\"\n  ) +\n  theme_minimal() +\n  labs(\n    title = \"Web Mercator Projection\",\n    subtitle = \"EPSG:3857. Best for interactive Maps; preserves angles.\"\n  )\n\nggsave(\n  plot = g,\n  filename = here::here(\"geocomputation\", \"images\",\n                        \"crs_projections_2.png\"),\n  height = 1200,\n  width = 1800,\n  units = \"px\"\n)\n\n\n\n\n\n\n\n\nFigure 2: Web Mercator Projection\n\n\n\n\n\n\n3. UTM Zone 33N\nThe Universal Transverse Mercator (UTM) Zone 33N, identified by EPSG:32633, is a projection system designed for mapping specific regions with minimal distortion. UTM divides the world into 6° longitudinal zones, and Zone 33N is suited for areas within its coverage, typically in Europe. It is ideal for regional-scale analysis and detailed mapping.\n\n\n\n\n\n\nNote\n\n\n\nIn order to be able to use xlim = c(-20, 45), and ylim = c(33, 70) within the coord_sf(), to focus on Europe, we must use default_crs = sf::st_crs(4326). The deafult_crs argument tells the ggplot2 that the limits’ numbers are mentioned in which CRS system. And, the 4326 CRS is the default longitude-latitude CRS system.\n\n\n\n\nCode\ng &lt;- ggplot() +\n  geom_sf(\n    data = world |&gt; \n      filter(continent == \"Europe\")\n  ) +\n  coord_sf(\n    crs = \"EPSG:32633\"\n  ) +\n  theme_minimal() +\n  labs(\n    title = \"UTM Zone 33N Projection: For Europe\",\n    subtitle = \"Minimal distortion for European Region.\"\n  )\n\nggsave(\n  plot = g,\n  filename = here::here(\"geocomputation\", \"images\",\n                        \"crs_projections_3_1.png\"),\n  height = 1200,\n  width = 1800,\n  units = \"px\"\n)\n\ng &lt;- world |&gt; \n  filter(continent == \"Europe\") |&gt; \n  filter(!(name %in% c(\"Russia\", \"Iceland\"))) |&gt; \n  ggplot() +\n  geom_sf() +\n  geom_sf_text(\n    mapping = aes(label = name),\n    check_overlap = TRUE,\n    size = 1.5\n  ) +\n  coord_sf(\n    crs = \"EPSG:32633\",\n    xlim = c(-20, 45),\n    ylim = c(33, 70),\n    default_crs = sf::st_crs(4326)\n  ) +\n  theme_minimal() +\n  labs(\n    x = NULL, y = NULL,\n    title = \"UTM Zone 33N Projection: For Europe\",\n    subtitle = \"After removing Russia and setting xlim & ylim\"\n  )\n\nggsave(\n  plot = g,\n  filename = here::here(\"geocomputation\", \"images\",\n                        \"crs_projections_3.png\"),\n  height = 1200,\n  width = 1800,\n  units = \"px\"\n)\n\n\n\n\n\n\n\n\n\nFigure 3: UTM Zone 33N Projection\n\n\n\n\n\n\n4. UTM Zone 33S\nThe UTM Zone 33S, associated with EPSG:32733, is similar to Zone 33N but designed for the southern hemisphere. It minimizes distortion within its zone and is widely used for detailed mapping in areas south of the equator within its longitudinal range. It is particularly useful for engineering and cadastral surveys. Area of use: Between 12°E and 18°E, southern hemisphere between 80°S and equator, onshore and offshore. Angola. Congo. Democratic Republic of the Congo (Zaire).\n\n\nCode\ng &lt;- world |&gt; \n  filter(name %in% c(\"Angola\", \"Congo\", \"Dem. Rep. Congo\",\n                     \"Namibia\")) |&gt; \n  ggplot() +\n  geom_sf() +\n  geom_sf_text(\n    mapping = aes(label = name),\n    check_overlap = TRUE,\n    size = 4\n  ) +\n  coord_sf(\n    crs = \"EPSG:32733\",\n    clip = \"off\"\n    ) +\n  theme_minimal() +\n  labs(\n    x = NULL, y = NULL,\n    title = \"UTM Zone 33S Projection\",\n    subtitle = \"For Southern Hemisphere: Africa\"\n  )\n\nggsave(\n  plot = g,\n  filename = here::here(\"geocomputation\", \"images\",\n                        \"crs_projections_4.png\"),\n  height = 1200,\n  width = 1800,\n  units = \"px\"\n)\n\n\n\n\n\n\n\n\nFigure 4: UTM Zone 33S Projection\n\n\n\n\n\n\n5. NAD83\nThe North American Datum 1983 (NAD83), identified by EPSG:4269, is a standard reference system used across North America. It serves as the foundation for many regional and national mapping projects in the US and Canada. This projection ensures compatibility with datasets collected in the region.\n\n\nCode\ng &lt;- world |&gt; \n  filter(continent == \"North America\") |&gt; \n  ggplot() +\n  geom_sf() +\n  geom_sf_text(\n    mapping = aes(\n      label = name,\n      size = as.numeric(st_area(geometry))\n    ),\n    check_overlap = TRUE\n  ) +\n  scale_size(range = c(0.75, 3)) +\n  coord_sf(\n    crs = \"EPSG:4269\",\n    clip = \"on\",\n    xlim = c(-160, -40),\n    default_crs = st_crs(4326)\n    ) +\n  theme_minimal() +\n  labs(\n    x = NULL, y = NULL,\n    title = \"North American Datum 1983 (NAD83) Projection\",\n    subtitle = \"For Canada and USA\"\n  ) +\n  theme(\n    legend.position = \"none\"\n  )\n\nggsave(\n  plot = g,\n  filename = here::here(\"geocomputation\", \"images\",\n                        \"crs_projections_5.png\"),\n  height = 1200,\n  width = 1800,\n  units = \"px\"\n)\n\n\n\n\n\n\n\n\nFigure 5: NAD83 Projection\n\n\n\n\n\n\n6. ETRS89 / LAEA Europe\nThe ETRS89 Lambert Azimuthal Equal Area projection, represented by EPSG:3035, is optimized for mapping datasets across Europe. It preserves area relationships, making it suitable for thematic maps like population density or land use. This projection is commonly used in European Union projects and cross-country analyses.\n\n\nCode\ng &lt;- world |&gt; \n  filter(continent == \"Europe\") |&gt; \n  ggplot() +\n  geom_sf() +\n  geom_sf_text(\n    mapping = aes(label = name),\n    check_overlap = TRUE,\n    size = 1.5\n  ) +\n  coord_sf(\n    crs = \"EPSG:3035\",\n    xlim = c(-15, 45),\n    ylim = c(33, 70),\n    default_crs = sf::st_crs(4326)\n  ) +\n  theme_minimal() +\n  labs(\n    x = NULL, y = NULL,\n    title = \"ETRS89 / LAEA Europe Projection\",\n    subtitle = \"European Union projects\"\n  )\n\nggsave(\n  plot = g,\n  filename = here::here(\"geocomputation\", \"images\",\n                        \"crs_projections_6.png\"),\n  height = 1200,\n  width = 1800,\n  units = \"px\"\n)\n\n\n\n\n\n\n\n\nFigure 6: ETRS89 / LAEA Europe Projection\n\n\n\n\n\n\n7. WGS 84 / Pseudo-Mercator\nThe WGS 84 / Pseudo-Mercator projection, also known as EPSG:3857, is closely related to the Web Mercator projection. It is designed for global-scale applications and is widely used for compatibility with web mapping platforms. This projection simplifies visualization but does not preserve distances or areas accurately.\n\n\n\n\n\n\nNote\n\n\n\nAntarctica cannot be plotted with Web Mercator projection, as it become hugely elongated. Must remove Antarctica before plotting in Web Mercator.\n\n\n\n\nCode\ng &lt;- ggplot() +\n  geom_sf(data = world |&gt; \n            filter(name != \"Antarctica\")) +\n  coord_sf(\n    crs = \"EPSG:3857\"\n  ) +\n  theme_minimal() +\n  labs(\n    title = \"WGS 84 / Pseudo-Mercator Projection (EPSG:3857)\",\n    subtitle = \"Simplifies visualization but does not preserve distances or areas accurately.\"\n  )\n\nggsave(\n  plot = g,\n  filename = here::here(\"geocomputation\", \"images\",\n                        \"crs_projections_7.png\"),\n  height = 1200,\n  width = 1800,\n  units = \"px\"\n)\n\n\n\n\n\n\n\n\nFigure 7: WGS 84 / Pseudo-Mercator Projection\n\n\n\n\n\n\n8. Albers Equal Area\nThe Albers Equal Area projection, identified by EPSG:5070, is particularly useful for mapping datasets across the United States. This projection preserves area relationships, making it suitable for applications like land-use planning or resource management. It is often used in environmental studies and thematic mapping.\n\n\nCode\ng &lt;- world |&gt; \n  # filter(name == \"United States of America\") |&gt; \n  ggplot() +\n  geom_sf(\n    fill = NA\n  ) +\n  geom_sf_text(\n    mapping = aes(label = name),\n    check_overlap = TRUE,\n    size = 1.5\n  ) +\n  coord_sf(\n    crs = \"EPSG:5070\",\n    # xlim = c(-15, 45),\n    # ylim = c(33, 70),\n    # default_crs = sf::st_crs(4326)\n  ) +\n  theme_minimal() +\n  labs(\n    x = NULL, y = NULL,\n    title = \"Albers Equal Area Projection\",\n    subtitle = \"For mainland USA\"\n  )\n\nggsave(\n  plot = g,\n  filename = here::here(\"geocomputation\", \"images\",\n                        \"crs_projections_8.png\"),\n  height = 1200,\n  width = 1800,\n  units = \"px\"\n)\n\ng &lt;- world |&gt; \n  filter(name == \"United States of America\") |&gt; \n  ggplot() +\n  geom_sf() +\n  geom_sf_text(\n    mapping = aes(label = name),\n    check_overlap = TRUE,\n    size = 4\n  ) +\n  coord_sf(\n    crs = \"EPSG:5070\",\n    xlim = c(-125, -67),\n    ylim = c(25, 53),\n    default_crs = sf::st_crs(4326)\n  ) +\n  theme_minimal() +\n  labs(\n    x = NULL, y = NULL,\n    title = \"Albers Equal Area Projection\",\n    subtitle = \"Focussing on mainland USA\"\n  )\n\nggsave(\n  plot = g,\n  filename = here::here(\"geocomputation\", \"images\",\n                        \"crs_projections_8_2.png\"),\n  height = 1200,\n  width = 1800,\n  units = \"px\"\n)\n\n\n\n\n\nAlbers Equal Area Projection\n\n\n\n\n\n\n\n\nFigure 8: Albers Equal Area Projection\n\n\n\n\n\n\n9. Lambert Conformal Conic (ESRI)\nThe Lambert Conformal Conic projection, represented by ESRI:102004, is a conformal projection widely used for mapping in North America. It minimizes distortion for regions with east-west orientation. This projection is often employed for regional-scale thematic mapping and analysis.\n\n\nCode\ng &lt;- world |&gt; \n  filter(continent == \"North America\") |&gt; \n  ggplot() +\n  geom_sf(\n    fill = NA\n  ) +\n  geom_sf_text(\n    mapping = aes(\n      label = name,\n      size = as.numeric(st_area(geometry))\n    ),\n    check_overlap = TRUE\n  ) +\n  scale_size(range = c(0.5, 3)) +\n  coord_sf(\n    crs = \"ESRI:102004\",\n    xlim = c(-160, -40),\n    ylim = c(5, 85),\n    default_crs = sf::st_crs(4326)\n  ) +\n  theme_minimal() +\n  labs(\n    x = NULL, y = NULL,\n    title = \"Lambert Conformal Conic Projection\",\n    subtitle = \"For mapping North America. Minimizes East-West distortion\"\n  ) +\n  theme(\n    legend.position = \"none\",\n    plot.title.position = \"plot\"\n  )\n\nggsave(\n  plot = g,\n  filename = here::here(\"geocomputation\", \"images\",\n                        \"crs_projections_9.png\"),\n  height = 1200,\n  width = 1800,\n  units = \"px\"\n)\n\n\n\n\n\n\n\n\nFigure 9: Lambert Conformal Conic Projection\n\n\n\n\n\n\n10. Mollweide (ESRI)\nThe Mollweide projection, identified by ESRI:54009, is an equal-area pseudo-cylindrical projection. It is ideal for global-scale thematic maps, such as climate or population density maps, where preserving area relationships is important. Its elliptical shape makes it visually distinct and effective for representing the entire world.\n\n\nCode\ng &lt;- ggplot() +\n  geom_sf(\n    data = world\n  ) +\n  coord_sf(\n    crs = \"ESRI:54009\"\n  ) +\n  theme_minimal() +\n  labs(\n    title = \"Mollweide Projection (ESRI:54009)\",\n    subtitle = \"For world maps, preserving area-relationships\"\n  )\n\nggsave(\n  plot = g,\n  filename = here::here(\"geocomputation\", \"images\",\n                        \"crs_projections_10.png\"),\n  height = 1200,\n  width = 1800,\n  units = \"px\"\n)\n\n\n\n\n\n\n\n\nFigure 10: Mollweide Projection\n\n\n\n\n\n\n11. Robinson (ESRI)\nThe Robinson projection, represented by ESRI:54030, is a compromise projection designed to create visually appealing world maps. It strikes a balance between distortion of shape, area, and distance, making it suitable for general-purpose global mapping. It is widely used in atlases and educational materials.\n\n\nCode\ng &lt;- ggplot() +\n  geom_sf(\n    data = world\n  ) +\n  coord_sf(\n    crs = \"ESRI:54030\"\n  ) +\n  theme_minimal() +\n  labs(\n    title = \"Robinson Projection (ESRI:54030)\",\n    subtitle = \"General purpose, visually appealing global maps.\"\n  )\n\nggsave(\n  plot = g,\n  filename = here::here(\"geocomputation\", \"images\",\n                        \"crs_projections_11.png\"),\n  height = 1200,\n  width = 1800,\n  units = \"px\"\n)\n\n\n\n\n\n\n\n\nFigure 11: Robinson Projection\n\n\n\n\n\n\n12. Sinusoidal (ESRI)\nThe Sinusoidal projection, identified by ESRI:54008, is an equal-area projection that is widely used for global-scale analysis. It is particularly effective for thematic maps showing area distribution, such as land cover or climate zones. Its straightforward representation of meridians makes it easy to interpret.\n\n\nCode\ng &lt;- ggplot() +\n  geom_sf(\n    data = world\n  ) +\n  coord_sf(\n    crs = \"ESRI:54008\"\n  ) +\n  theme_minimal() +\n  labs(\n    title = \"Sinusoidal Projection (ESRI:54008)\",\n    subtitle = \"An equal area projection, meridians are easier to interpret.\"\n  )\n\nggsave(\n  plot = g,\n  filename = here::here(\"geocomputation\", \"images\",\n                        \"crs_projections_12.png\"),\n  height = 1200,\n  width = 1800,\n  units = \"px\"\n)\n\n\n\n\n\n\n\n\nFigure 12: Sinusoidal Projection\n\n\n\n\n\n\n13. Bonne (ESRI)\nThe Bonne projection, represented by ESRI:54024, is an equal-area projection often used for mapping continents. It minimizes area distortion while maintaining a pleasing, compact layout. It is suitable for thematic maps where regional relationships are critical.\n\n\nCode\ng &lt;- ggplot() +\n  geom_sf(\n    data = world\n  ) +\n  coord_sf(\n    crs = \"ESRI:54024\"\n  ) +\n  theme_minimal() +\n  labs(\n    title = \"Bonne Projection (ESRI:54024)\",\n    subtitle = \"An equal area projection, with focus on regional relationships.\"\n  )\n\nggsave(\n  plot = g,\n  filename = here::here(\"geocomputation\", \"images\",\n                        \"crs_projections_13.png\"),\n  height = 1200,\n  width = 1800,\n  units = \"px\"\n)\n\n\n\n\n\n\n\n\nFigure 13: Bonne Projection\n\n\n\n\n\n\n14. World Van der Grinten I (ESRI)\nThe World Van der Grinten I projection, identified by ESRI:54029, displays the entire world in a circular format. It offers an aesthetically pleasing view of global datasets, though it sacrifices accuracy in terms of area and shape. It is often used for decorative or general-purpose maps.\n\n\n\n\n\n\nNote\n\n\n\nThe World Van der Grinten I projection, being circular, significantly expands Antarctica. SO it is best not to plot Antarctica with a world map in this projection.\n\n\n\n\nCode\ng &lt;- ggplot() +\n  geom_sf(\n    data = world |&gt; \n      filter(name != \"Antarctica\")\n  ) +\n  coord_sf(\n    crs = \"ESRI:54029\"\n  ) +\n  theme_minimal() +\n  labs(\n    title = \"World Van der Grinten Projection (ESRI:54029)\",\n    subtitle = \"An aesthetically pleasing, circular decorative World Map.\"\n  )\n\nggsave(\n  plot = g,\n  filename = here::here(\"geocomputation\", \"images\",\n                        \"crs_projections_14.png\"),\n  height = 1200,\n  width = 1800,\n  units = \"px\"\n)\n\n\n\n\n\n\n\n\nFigure 14: World Van der Grinten I Projection\n\n\n\n\n\n\n15. Plate Carrée\nThe Plate Carrée projection, represented by EPSG:32662, is one of the simplest projections with equally spaced latitudes and longitudes. It is easy to work with but distorts area and shape significantly away from the equator. It is suitable for visualizing raw geographic data.\n\n\nCode\ng &lt;- ggplot() +\n  geom_sf(\n    data = world\n  ) +\n  coord_sf(\n    crs = \"EPSG:32662\"\n  ) +\n  theme_minimal() +\n  labs(\n    title = \"Plate Carrée Projection (EPSG:32662)\",\n    subtitle = \"For working with Raw data. Has equally spaced latitudes and longitudes.\"\n  )\n\nggsave(\n  plot = g,\n  filename = here::here(\"geocomputation\", \"images\",\n                        \"crs_projections_15.png\"),\n  height = 1200,\n  width = 1800,\n  units = \"px\"\n)\n\n\n\n\n\n\n\n\nFigure 15: Plate Carrée Projection\n\n\n\n\n\n\n16. Transverse Mercator\nThe Transverse Mercator projection, associated with EPSG:4326, is a cylindrical projection ideal for narrow regions. It minimizes distortion along the central meridian, making it widely used for mapping zones like UTM. It is often employed in engineering and cadastral surveys.\n\n\nCode\ng &lt;- ggplot() +\n  geom_sf(\n    data = world\n  ) +\n  coord_sf(\n    crs = \"EPSG:4326\"\n  ) +\n  theme_minimal() +\n  labs(\n    title = \"Transverse Mercator Projection (EPSG:4326)\",\n    subtitle = \"Cylindrical Projection.\"\n  )\n\nggsave(\n  plot = g,\n  filename = here::here(\"geocomputation\", \"images\",\n                        \"crs_projections_16.png\"),\n  height = 1200,\n  width = 1800,\n  units = \"px\"\n)\n\n\n\n\n\n\n\n\nFigure 16: Transverse Mercator Projection\n\n\n\n\n\n\n17. North Pole Stereographic\nThe North Pole Stereographic projection, identified by EPSG:3413, is designed for mapping the Arctic region. It minimizes distortion near the pole, making it suitable for polar datasets, including sea ice and Arctic biodiversity.\n\n\nCode\ng &lt;- ggplot() +\n  geom_sf(\n    data = world,\n    fill = \"grey80\",\n    alpha = 0.3\n  ) +\n  coord_sf(\n    crs = \"EPSG:3413\",\n    ylim = c(50, 90),\n    xlim = c(-180, 180),\n    default_crs = st_crs(4326),\n    clip = \"on\"\n  ) +\n  theme_minimal() +\n  labs(\n    title = \"North Pole Stereographic Projection (EPSG:3413)\",\n    subtitle = \"For mapping the Arctic Region.\"\n  )\n\nggsave(\n  plot = g,\n  filename = here::here(\"geocomputation\", \"images\",\n                        \"crs_projections_17.png\"),\n  height = 1200,\n  width = 1800,\n  units = \"px\"\n)\n\n\n\n\n\n\n\n\nFigure 17: North Pole Stereographic Projection\n\n\n\n\n\n\n18. South Pole Stereographic\nThe South Pole Stereographic projection, represented by EPSG:3031, is specifically designed for mapping the Antarctic region. It preserves the geometric properties near the pole and is commonly used for research on Antarctic ice sheets and ecosystems.\n\n\nCode\ng &lt;- ggplot() +\n  geom_sf(\n    data = world |&gt; \n      filter(name == \"Antarctica\")\n  ) +\n  coord_sf(\n    crs = \"EPSG:3031\",\n    # ylim = c(-90, -60),\n    # xlim = c(-180, 180),\n    # default_crs = st_crs(4326)\n  ) +\n  theme_minimal() +\n  labs(\n    title = \"South Pole Stereographic Projection (EPSG:3031)\",\n    subtitle = \"For mapping the Antarctic Region.\"\n  )\n\nggsave(\n  plot = g,\n  filename = here::here(\"geocomputation\", \"images\",\n                        \"crs_projections_18.png\"),\n  height = 1200,\n  width = 1800,\n  units = \"px\"\n)\n\n\n\n\n\n\n\n\nFigure 18: South Pole Stereographic Projection\n\n\n\n\n\n\n19. Interrupted Goode Homolosine (ESRI)\nThe Interrupted Goode Homolosine projection, identified by EPSG:54052, is a composite projection designed to minimize distortion of landmasses. It is particularly effective for global mapping that emphasizes land area accuracy and is often used in environmental studies.\n\n\n\n\n\n\nNote\n\n\n\nThis interrupted composite projection severely distorts and pulls apart Greenland and Antarctica, so avoid plotting them with this projection.\n\n\n\n\nCode\ng &lt;- ggplot() +\n  geom_sf(\n    data = world |&gt; \n      filter(!(name %in% c(\"Greenland\", \"Antarctica\")))\n  ) +\n  coord_sf(\n    crs = \"ESRI:54052\"\n  ) +\n  theme_minimal() +\n  labs(\n    title = \"Interrupted Goode Homolosine Projection (ESRI:4326)\",\n    subtitle = \"Composite Projection. Minimzes distortion of landmasses\"\n  )\n\nggsave(\n  plot = g,\n  filename = here::here(\"geocomputation\", \"images\",\n                        \"crs_projections_19.png\"),\n  height = 1200,\n  width = 1800,\n  units = \"px\"\n)\n\n\n\n\n\n\n\n\nFigure 19: Interrupted Goode Homolosine Projection\n\n\n\n\n\n\n20. Krovak\nThe Krovak projection, associated with EPSG:5514, is widely used in the Czech Republic and Slovakia. It is tailored to their geographic extents, ensuring minimal distortion for regional applications. It is ideal for cadastral and engineering projects in these areas.\n\n\nCode\ng &lt;- world |&gt; \n  filter(name %in% c(\"Czechia\", \"Slovakia\")) |&gt; \n  ggplot() +\n  geom_sf() +\n  geom_sf_text(\n    aes(label = name)\n  ) +\n  coord_sf(\n    crs = \"EPSG:5514\"\n  ) +\n  theme_minimal() +\n  labs(\n    title = \"Krovak Projection (EPSG:5514)\",\n    subtitle = \"Used for Czechia and Slovakia, for minimal distortion in those regions\"\n  )\n\nggsave(\n  plot = g,\n  filename = here::here(\"geocomputation\", \"images\",\n                        \"crs_projections_20.png\"),\n  height = 1200,\n  width = 1800,\n  units = \"px\"\n)\n\n\n\n\n\n\n\n\nFigure 20: Krovak Projection\n\n\n\n\n\n\n21. Asia North Lambert Conformal (ESRI)\nThe Asia North Lambert Conformal Conic projection, identified by ESRI:102026, is designed for northern Asia. It is suitable for mapping datasets across this vast region with minimal distortion. It is commonly used in regional studies and thematic mapping.\n\n\nCode\ng &lt;- world |&gt; \n  filter(continent == \"Asia\" | name == \"Russia\") |&gt; \n  ggplot() +\n  geom_sf() +\n  coord_sf(\n    crs = \"ESRI:102026\"\n  ) +\n  theme_minimal() +\n  labs(\n    title = \"Asia North Lambert Conformal Projection\",\n    subtitle = \"Used for plotting Northern Asia within minimal distortion\"\n  ) +\n  theme(\n    plot.title.position = \"plot\"\n  )\n\nggsave(\n  plot = g,\n  filename = here::here(\"geocomputation\", \"images\",\n                        \"crs_projections_21.png\"),\n  height = 1200,\n  width = 1800,\n  units = \"px\"\n)\n\n\n\n\n\n\n\n\nFigure 21: Asia North Lambert Conformal Projection\n\n\n\n\n\n\n22. Australia Albers\nThe Australia Albers projection, represented by EPSG:3577, is an equal-area projection optimized for Australia. It minimizes area distortion and is commonly used for environmental studies and resource management across the continent.\n\n\nCode\ng &lt;- world |&gt; \n  filter(name %in% c(\"Australia\")) |&gt; \n  ggplot() +\n  geom_sf() +\n  coord_sf(\n    crs = \"EPSG:3577\",\n    default_crs = st_crs(4326),\n    ylim = c(-43, -10)\n  ) +\n  theme_minimal() +\n  labs(\n    title = \"Australia Albers Projection\",\n    subtitle = \"A projection optimized for Australia\"\n  ) +\n  theme(\n    plot.title.position = \"plot\"\n  )\n\nggsave(\n  plot = g,\n  filename = here::here(\"geocomputation\", \"images\",\n                        \"crs_projections_22.png\"),\n  height = 1200,\n  width = 1800,\n  units = \"px\"\n)\n\n\n\n\n\n\n\n\nFigure 22: Australia Albers Projection"
  },
  {
    "objectID": "book_solutions/chapter4.html",
    "href": "book_solutions/chapter4.html",
    "title": "Chapter 4: Spatial data operations",
    "section": "",
    "text": "library(sf)        # Simple Features in R\nlibrary(terra)     # Handling rasters in R\nlibrary(tidyterra) # For plotting rasters in ggplot2\nlibrary(magrittr)  # Using pipes with raster objects\nlibrary(tidyverse) # All things tidy; Data Wrangling\nlibrary(spData)    # Spatial Datasets\n\n\nsysfonts::font_add_google(\"Saira Extra Condensed\", \"caption_font\")\nsysfonts::font_add_google(\"Saira\", \"body_font\")\ntheme_set(theme_minimal(base_family = \"body_font\",\n                        base_size = 16))\nshowtext::showtext_auto()"
  },
  {
    "objectID": "book_solutions/chapter4.html#introduction-to-spatial-operations",
    "href": "book_solutions/chapter4.html#introduction-to-spatial-operations",
    "title": "Chapter 4: Spatial data operations",
    "section": "4.1 Introduction to Spatial Operations",
    "text": "4.1 Introduction to Spatial Operations\n\nSpatial Operations: Include spatial joins for vectors and local/focal operations for rasters, allowing modification based on location and shape.\n\nRelation to Non-Spatial Operations: Many spatial operations (e.g., subsetting, joining) have non-spatial counterparts.\n\nSpatial Joins: Can be done in multiple ways (e.g., intersect, within distance), unlike non-spatial joins (refer to fuzzyjoin package (Robinson 2020) for alternatives).\n\nTypes of Spatial Relationships: Includes operations like intersects and disjoint. Distance calculations explore spatial relationships.\n\nRaster Operations:\n\nSubsetting (Section 4.3.1)\nMap Algebra: Modifies raster cell values through local, focal, zonal, and global operations (Sections 4.3.3 to 4.3.6).\nMerging Rasters: Demonstrated with reproducible examples (Section 4.3.8).\n\nCoordinate Reference System (CRS): Consistency in CRS is essential for spatial operations.."
  },
  {
    "objectID": "book_solutions/chapter4.html#spatial-operations-on-vector-data",
    "href": "book_solutions/chapter4.html#spatial-operations-on-vector-data",
    "title": "Chapter 4: Spatial data operations",
    "section": "4.2 Spatial operations on vector data",
    "text": "4.2 Spatial operations on vector data\n\n4.2.1 Spatial Subsetting: use st_filter()\n\nSpatial subsetting extracts features from a spatial object (x) that relate spatially to another object (y).\nSyntax: Use the [ ] operator: x[y, , op = st_intersects].\n\nx: Target sf object.\ny: Subsetting sf object.\nop: Topological relation (default is st_intersects).\nsf package documentation\n\nDefault Operator: st_intersects() selects features intersecting with the subsetting object. Alternative operators like st_disjoint() can be used for different relations.\n\nExample: nz_height[canterbury, ] returns high points within Canterbury from the nz_height dataset in the spData package (spData documentation).\n\nTopological Relations: Include touches, crosses, and within. These determine spatial relationships between features in x and y.\nSparse Geometry Binary Predicate (sgbp):\n\nUsing st_intersects(), an sgbp list object is created.\nConvert sgbp to logical vector for subsetting using lengths({sgbp_object_name} &gt; 0)\nUsing sparse = FALSE argument in st_intersects() returns a dense matrix.\n\nTidyverse Alternative: st_filter() from the sf package simplifies spatial subsetting, increasing compatibility with dplyr.\nOutput Consistency: Subsets created using [ ], logical vectors, or st_filter() are equivalent in spatial operations.\n\n\n\nCode\ndata(\"nz\")\ndata(\"nz_height\")\n\nclass(nz)\n## [1] \"sf\"         \"data.frame\"\n\n# A plot for all regions and all peaks\nnz |&gt; \n  ggplot() +\n  geom_sf(fill = \"white\") +\n  ggrepel::geom_text_repel(\n    mapping = aes(\n      label = Name,\n      geometry = geom\n    ),\n    size = 4,\n    family = \"caption_font\",\n    stat = \"sf_coordinates\"\n  ) +\n  geom_sf(\n    data = nz_height,\n    pch = 2,\n    colour = \"red\",\n    size = 3\n  ) +\n  scale_fill_manual(\n    values = c(\"white\", \"pink\")\n  ) +\n  labs(\n    title = \"All peaks in New Zealand, and all regions.\"\n  ) +\n  theme_void() +\n  theme(\n    plot.background = element_rect(\n      fill = \"lightblue\",\n      colour = NA\n    ),\n    legend.position = \"none\"\n  )\n\n# Total peaks in New Zealand\nnz_height |&gt; dim()\n## [1] 101   3\n\n# Peaks within Canterbury in New Zealand\n\n# Base R Version\ncanterbury &lt;- nz |&gt; filter(Name == \"Canterbury\")\nnz_height[canterbury,] |&gt; dim()\n## [1] 70  3\n\n# Tidyverse Version\nnz_height |&gt;\n  st_filter(\n    nz |&gt; filter(Name == \"Canterbury\"),\n    .predicate = st_intersects\n  ) |&gt; \n  dim()\n## [1] 70  3\n\n# Getting the peaks which are inside Canterbury\ncanterbury_ids &lt;- nz_height |&gt;\n  st_filter(\n    nz |&gt; filter(Name == \"Canterbury\"),\n    .predicate = st_intersects\n  ) |&gt; \n  pull(t50_fid)\n\nnz_height |&gt; \n  mutate(in_canterbury = t50_fid %in% canterbury_ids) |&gt; \n  ggplot() +\n  \n  # Base NZ Map and Label for Canterbury\n  geom_sf(\n    data = nz,\n    mapping = aes(\n      fill = Name == \"Canterbury\"\n    )\n  ) +\n  geom_sf_text(\n    data = filter(nz, Name == \"Canterbury\"),\n    mapping = aes(\n      label = Name,\n      geometry = geom\n    ),\n    size = 4,\n    family = \"caption_font\"\n  ) +\n  \n  # Plotting the peaks, and colouring by presence in Canterbury\n  geom_sf(\n    mapping = aes(\n      colour = in_canterbury,\n      size = in_canterbury\n    ),\n    pch = 2\n  ) +\n  \n  scale_fill_manual(\n    values = c(\"white\", \"lightpink\")\n  ) +\n  scale_colour_manual(\n    values = c(\"black\", \"red\")\n  ) +\n  guides(\n    fill = \"none\"\n  ) +\n  labs(\n    colour = \"Peaks within Canterbury Region?\",\n    size = \"Peaks within Canterbury Region?\",\n    title = \"Highlighting Peaks within Canterbury region\"\n  ) +\n  theme_void() +\n  theme(\n    plot.background = element_rect(\n      fill = \"lightblue\"\n    ),\n    legend.position = \"bottom\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n(a) New Zealand Map with all the peaks\n\n\n\n\n\n\n\n\n\n\n\n(b) New Zealand Map focussing on peaks that intersect with Canterbury\n\n\n\n\n\n\nFigure 1: Spatial Subsetting and plotting with tidyverse and ggplot2 methods\n\n\n\n\nExample code for st_intersects() and st_disjoint() : these functions produce a sparse predicate list only. Hence, correct way to use them would be st_filter() with .predicate = &lt;function&gt; argument.\n\nnz_height |&gt; \n  st_intersects(\n    filter(nz, Name == \"Canterbury\")\n  )\n\nSparse geometry binary predicate list of length 101, where the\npredicate was `intersects'\nfirst 10 elements:\n 1: (empty)\n 2: (empty)\n 3: (empty)\n 4: (empty)\n 5: 1\n 6: 1\n 7: 1\n 8: 1\n 9: 1\n 10: 1\n\n# The 70 peaks within Canterbury region\nnz_height |&gt; \n  st_filter(\n    filter(nz, Name == \"Canterbury\"),\n    .predicate = st_intersects\n  )\n\nSimple feature collection with 70 features and 2 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 1365809 ymin: 5158491 xmax: 1654899 ymax: 5350463\nProjected CRS: NZGD2000 / New Zealand Transverse Mercator 2000\nFirst 10 features:\n   t50_fid elevation                geometry\n1  2362630      2749 POINT (1378170 5158491)\n2  2362814      2822 POINT (1389460 5168749)\n3  2362817      2778 POINT (1390166 5169466)\n4  2363991      3004 POINT (1372357 5172729)\n5  2363993      3114 POINT (1372062 5173236)\n6  2363994      2882 POINT (1372810 5173419)\n7  2363995      2796 POINT (1372579 5173989)\n8  2363997      3070 POINT (1373796 5174144)\n9  2363998      3061 POINT (1373955 5174231)\n10 2363999      3077 POINT (1373984 5175228)\n\n# The 31 peaks outside Canterbury Region\nnz_height |&gt; \n  st_filter(\n    filter(nz, Name == \"Canterbury\"),\n    .predicate = st_disjoint\n  )\n\nSimple feature collection with 31 features and 2 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 1204143 ymin: 5048309 xmax: 1822492 ymax: 5650492\nProjected CRS: NZGD2000 / New Zealand Transverse Mercator 2000\nFirst 10 features:\n   t50_fid elevation                geometry\n1  2353944      2723 POINT (1204143 5049971)\n2  2354404      2820 POINT (1234725 5048309)\n3  2354405      2830 POINT (1235915 5048745)\n4  2369113      3033 POINT (1259702 5076570)\n5  2363996      2759 POINT (1373264 5175442)\n6  2364028      2756 POINT (1374183 5177165)\n7  2364029      2800 POINT (1374469 5176966)\n8  2364031      2788 POINT (1375422 5177253)\n9  2364166      2782 POINT (1383006 5181085)\n10 2364167      2905 POINT (1383486 5181270)\n\n\n\n\n4.2.2 Topological Relations\n\nTopological relations describe spatial relationships between objects using logical TRUE or FALSE statements (Egenhofer and Herring, 1990).\nSymmetrical vs. non-symmetrical relations:\n\nSymmetrical relations (e.g., equals, intersects, crosses) yield the same result when order of input is swapped.\nNon-symmetrical relations (e.g., contains, within) depend on the order of input geometries.\n\nBinary predicates in sf package test spatial relationships between vector geometries. See vignette(“sf3”). The following binary predicates exist in sf : —\n\n\n\n\n\n\n\n\n\nFunction\nDescription\nSymmetrical?\n\n\n\n\nst_intersects\nChecks if geometries intersect.\nYes\n\n\nst_disjoint\nChecks if geometries do not intersect (are disjoint).\nYes\n\n\nst_touches\nChecks if geometries have at least one boundary point in common.\nYes\n\n\nst_crosses\nChecks if a geometry crosses another (e.g., a line crosses a polygon).\nYes\n\n\nst_overlaps\nChecks if geometries have some but not all interior points in common.\nYes\n\n\nst_equals\nChecks if geometries are topologically equal.\nYes\n\n\nst_within\nChecks if a geometry is completely contained within another.\nNo\n\n\nst_contains\nChecks if a geometry contains another completely.\nNo\n\n\nst_contains_properly\nChecks if a geometry contains another but not vice versa.\nNo\n\n\nst_covers\nChecks if a geometry covers another (includes boundary).\nNo\n\n\nst_covered_by\nChecks if a geometry is covered by another (includes boundary).\nNo\n\n\nst_equals_exact\nChecks if geometries are exactly equal within a given tolerance.\nYes\n\n\nst_is_within_distance\nChecks if geometries are within a specified distance from each other.\nYes\n\n\n\n\nSparse matrix output: Functions like st_intersects() use sparse matrices to save memory by only registering positive results; setting sparse = FALSE returns a dense matrix.\n\n\n\nCode\n# Create two polygons\n polygon1 &lt;- st_polygon(\n   list(matrix(c(0, 0, 1, 0, 1, 1, 0, 1, 0, 0),\n     ncol = 2,\n     byrow = TRUE\n   ))\n )\n\n polygon2 &lt;- st_polygon(\n   list(matrix(c(0.5, 0.5, 1.5, 0.5, 1.5, 1.5, 0.5, 1.5, 0.5, 0.5),\n     ncol = 2,\n     byrow = TRUE\n   ))\n )\n\n polygon3 &lt;- st_polygon(\n   list(matrix(c(0.2, 1.2,\n                 0.5, 1.2, \n                 0.5, 1.5, \n                 0.2, 1.5, \n                 0.2, 1.2),\n     ncol = 2,\n     byrow = TRUE\n   ))\n )\n\n polygon4 &lt;- st_polygon(\n   list(matrix(c(1.2, 0.2, \n                 1.5, 0.2, \n                 1.5, 0.4, \n                 1.2, 0.4, \n                 1.2, 0.2),\n     ncol = 2,\n     byrow = TRUE\n   ))\n )\n \n # Convert to sf objects\n sf_poly1 &lt;- st_sfc(polygon1, crs = 4326)\n sf_poly2 &lt;- st_sfc(polygon2, crs = 4326)\n sf_poly3 &lt;- st_sfc(polygon3, crs = 4326)\n sf_poly4 &lt;- st_sfc(polygon4, crs = 4326)\n \n # Create a collection of points\n points &lt;- st_sfc(\n   st_point(c(0.25, 0.25)),\n   st_point(c(0.75, 0.75)),\n   st_point(c(1.25, 1.25)),\n   crs = 4326\n )\n\n sf_points &lt;- tibble(\n   point = c(\"p1\", \"p2\", \"p3\"),\n   geometry = points\n ) |&gt;\n   st_as_sf() |&gt;\n   st_set_crs(4326)\n\n# Keeping environment clean\nrm(polygon1, polygon2, \n   polygon3, polygon4,\n   points)\n\n# Visualize the objects\nggplot() +\n  geom_sf(data = sf_poly1, \n          aes(fill = \"sf_poly1\"),\n          alpha = 0.5) +\n  geom_sf(data = sf_poly2, \n          aes(fill = \"sf_poly2\"),\n          alpha = 0.5) +\n  geom_sf(data = sf_poly3, \n          aes(fill = \"sf_poly3\"),\n          alpha = 0.5) +\n  geom_sf(data = sf_poly4, \n          aes(fill = \"sf_poly4\"),\n          alpha = 0.5) +\n  geom_sf(data = sf_points,\n          aes(fill = point),\n          pch = 21,\n          size = 4) +\n  labs(fill = NULL) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nFigure 2: Some example objects to demonstrate the topological relations\n\n\n\n\n\n\n#################### Symmetrical Relations ######################\n# The order in which sf objects are placed does not matter\n\n## st_intersects()----------------------------------------\nst_intersects(sf_poly1, sf_poly2, sparse = F) \n##      [,1]\n## [1,] TRUE\n\nst_intersects(sf_poly1, sf_points, sparse = F) \n##      [,1] [,2]  [,3]\n## [1,] TRUE TRUE FALSE\n\nst_intersects(sf_poly1, sf_poly3, sparse = F)\n##       [,1]\n## [1,] FALSE\n\nst_intersects(sf_poly2 ,sf_poly3, sparse = F) \n##      [,1]\n## [1,] TRUE\n\n\n# st_disjoint()------------------------------------------\nst_disjoint(sf_poly1, sf_poly4, sparse = F)\n##      [,1]\n## [1,] TRUE\n\nst_disjoint(sf_poly2, sf_poly3, sparse = F) \n##       [,1]\n## [1,] FALSE\n\n\n# st_touches()-------------------------------------------\nst_touches(sf_poly1, sf_poly2, sparse = F) \n##       [,1]\n## [1,] FALSE\n\nst_touches(sf_poly2, sf_poly3, sparse = F)\n##      [,1]\n## [1,] TRUE\n\nst_touches(sf_poly1, sf_points, sparse = F)\n##       [,1]  [,2]  [,3]\n## [1,] FALSE FALSE FALSE\n\n\n# st_crosses()-------------------------------------------\nst_crosses(sf_poly1, sf_poly2, sparse = F)\n##       [,1]\n## [1,] FALSE\n\nst_crosses(sf_poly1, sf_points, sparse = F)\n##       [,1]  [,2]  [,3]\n## [1,] FALSE FALSE FALSE\n\n# st_overlaps()\nst_overlaps(sf_poly1, sf_poly2, sparse = F)\n##      [,1]\n## [1,] TRUE\nst_overlaps(sf_poly1, sf_points, sparse = F)\n##       [,1]  [,2]  [,3]\n## [1,] FALSE FALSE FALSE\nst_overlaps(sf_poly3, sf_poly3, sparse = F)\n##       [,1]\n## [1,] FALSE\n\n\n# st_equals()-------------------------------------------\nst_equals(sf_poly1, sf_poly1, sparse = F)\n##      [,1]\n## [1,] TRUE\n\n\n\n# st_equals_exact()-------------------------------------\nst_equals_exact(sf_poly1, sf_poly2, par = 0.1, sparse = F)\n##       [,1]\n## [1,] FALSE\nst_equals_exact(sf_poly1, sf_poly2, par = 1, sparse = F)\n##      [,1]\n## [1,] TRUE\n\n\n# st_is_within_distance()-------------------------------\nst_is_within_distance(sf_poly1, sf_poly2, dist = 0.1, sparse = F)\n##      [,1]\n## [1,] TRUE\nst_is_within_distance(sf_poly2, sf_poly3, dist = 0.1, sparse = F)\n##      [,1]\n## [1,] TRUE\nst_is_within_distance(sf_poly3, sf_poly4, dist = 0.1, sparse = F)\n##       [,1]\n## [1,] FALSE\nst_is_within_distance(sf_poly3, sf_poly4, dist = 13, sparse = F)\n##       [,1]\n## [1,] FALSE\n\n\n#################### Non-Symmetrical Relations ####################\n# The order in which sf objects are placed changes the outcome\n\n# st_within()-------------------------------------------\nsf_points |&gt; \n  st_within(sf_poly1, sparse = F)\n##       [,1]\n## [1,]  TRUE\n## [2,]  TRUE\n## [3,] FALSE\n\nsf_poly1 |&gt; \n  st_within(sf_points, sparse = F)\n##       [,1]  [,2]  [,3]\n## [1,] FALSE FALSE FALSE\n\nsf_poly1 |&gt; \n  st_within(sf_poly2, sparse = F)\n##       [,1]\n## [1,] FALSE\n\n\n# st_contains()-----------------------------------------\nsf_poly1 |&gt; \n  st_contains(sf_points, sparse = F)\n##      [,1] [,2]  [,3]\n## [1,] TRUE TRUE FALSE\n\nsf_points |&gt; \n  st_contains(sf_poly1, sparse = F)\n##       [,1]\n## [1,] FALSE\n## [2,] FALSE\n## [3,] FALSE\n\n\n# st_covers()-------------------------------------------\nsf_poly1 |&gt; \n  st_covers(sf_points, sparse = F)\n##      [,1] [,2]  [,3]\n## [1,] TRUE TRUE FALSE\n\nsf_poly2 |&gt; \n  st_covers(sf_poly1, sparse = F)\n##       [,1]\n## [1,] FALSE\n\n\n# st_covered_by()---------------------------------------\nsf_points |&gt; \n  st_covered_by(sf_poly1, sparse = F)\n##       [,1]\n## [1,]  TRUE\n## [2,]  TRUE\n## [3,] FALSE\n\n\n\n4.2.3 Distance Relations\n\nDistance relations are continuous, unlike binary topological relations which return TRUE/FALSE values.\nThe st_distance() function calculates distances between two sf objects, returning a matrix with units of measurement (e.g., meters).\nst_centroid(): Computes the geometric centroid of a spatial feature, useful for representing a region’s central point in distance calculations.\nMatrix output:\n\nResults are returned as a matrix, even for single value calculations.\nComputes a distance matrix between all combinations of features in objects (e.g., distances between multiple points and polygons).\n\nPoint-to-polygon distance: Represents the shortest distance from a point to any part of the polygon.\nUsage in distance-based joins: st_distance() is also used for performing joins based on distance criteria.\nAn example code to find distance between central points of Auckland and Canterbury Regions, vs. Top three peaks in New Zealand, returned as a matrix,a nd shown below as a beautiful table using {gt}.\n\n\n# Central points of Auckland and Canterbury Regions\ndf1 &lt;- nz |&gt; \n  filter(str_detect(Name, \"Auck|Canter\")) |&gt; \n  st_centroid() |&gt; \n  select(Name, geom)\n\n# Top 3 highest peaks in New Zealand\ndf2 &lt;- nz_height |&gt; \n  slice_max(order_by = elevation, n = 3)\n\n# Finding the distance matrix\nst_distance(df1, df2) |&gt; \n  as_tibble() |&gt; \n  mutate(state = c(\"Auckland\", \"Canterbury\")) |&gt; \n  relocate(state) |&gt; \n  mutate(\n    across(\n      .cols = -state,\n      .fns = as.numeric\n    )\n  ) |&gt; \n  gt::gt() |&gt; \n  gt::fmt_number(\n    decimals = 1,\n    scale_by = 1e-3\n  ) |&gt; \n  gt::cols_label(V1 = \"Highest Peak\", \n                 V2 = \"Second\",\n                 V3 = \"Third\",\n                 state = \"Centroid of the State\") |&gt; \n  gt::tab_header(\n    title = \"Distance in kilometers\"\n  ) |&gt; \n  gtExtras::gt_theme_538()\n\n\n\nTable 1: Code output for use of st_centroid() and st_distance()\n\n\n\n\n\n\n\n\n\nDistance in kilometers\n\n\nCentroid of the State\nHighest Peak\nSecond\nThird\n\n\n\n\nAuckland\n856.6\n857.3\n856.9\n\n\nCanterbury\n115.5\n115.4\n115.5\n\n\n\n\n\n\n\n\n\n\n\n\n4.2.4 DE-9IM Strings\n\nThe Dimensionally Extended 9-Intersection Model (DE-9IM) underlies binary spatial predicates. This model forms the basis for many spatial operations and helps create custom spatial predicates.\nOrigins:\n\nInitially named “DE + 9IM,” it refers to the dimensions of intersections between the boundaries, interiors, and exteriors of two geometries (Clementini and Di Felice 1995).\nIt applies to two-dimensional geometries (points, lines, polygons) in Euclidean space, requiring data in a projected coordinate reference system (CRS).\n\nHow DE-9IM Works:\n\nThe model visualizes intersections between components of two geometries (interior, boundary, exterior) in a 3x3 matrix form, indicating the dimension of the intersection (0 for points, 1 for lines, 2 for polygons, and F for false).\nFlattening this matrix row-wise results in the DE-9IM string: “212111212”.\n\nUsing st_relate(): The st_relate() function returns DE-9IM strings to describe spatial relations.\nDeveloping Custom Predicates:\n\nBy interpreting DE-9IM strings, custom binary spatial predicates like queen and rook relations can be created:\n\nQueen relations (shared border or point): Pattern F***T****.\nRook relations (shared linear intersection): Pattern F***1****.\n\nCustom functions using st_relate():\n\n\nst_queen = function(x, y) \n  st_relate(x, y, pattern = \"F***T****\")\n\nst_rook = function(x, y) \n  st_relate(x, y, pattern = \"F***1****\")\n\nThis identifies which geometries in a grid have queen or rook relations to the central geometry.\n\n\n\n4.2.5 Spatial Joining with st_join()\n\nSpatial joins combine datasets based on spatial relationships instead of shared key variables (as in non-spatial joins). It adds columns from a source object (y) to a target object (x).\nJoin Details:\n\nDefault behavior: A left join, which retains all rows from x and includes rows with no match from y.\nOperators: Uses st_intersects() by default but can be modified via the join argument.\nHandles all geometry types: Works for points, lines, and polygons, though joins involving polygons may create duplicate rows for multiple matches in y.\n\nFlexibility:\n\nInner joins: Set left = FALSE to include only matched rows.\n\nThe st_join() function: The join argument defines the topological operator to determine these relationships, with the default being st_intersects().\n\nWe can customize this behavior by choosing alternative functions such as st_contains, st_within, st_overlaps, st_touches, or st_disjoint, among others, each defining a different geometric predicate.\nFor example, st_contains selects features where geometries of x fully encompass those of y, while st_within does the reverse.\nAdditionally, advanced options like st_is_within_distance allow proximity-based joins, and st_relate supports customized spatial relationships using a pattern.\n\nExample: Getting 25 random points in the world, and seeing in which countries they fall in Figure 3.\n\n\n\nCode\n# Getting 25 random points on the world,a dn then seeing in which countries they fall\nrandom_points &lt;- tibble(\n  x = round(\n    runif(\n    25, \n    min = st_bbox(world)$xmin, \n    max = st_bbox(world)$xmax\n    ),\n    2\n  ),\n  y = round(\n    runif(\n    25, \n    min = st_bbox(world)$ymin, \n    max = st_bbox(world)$ymax\n    ),\n    2\n  ),\n  id = LETTERS[1:25]\n) |&gt; \n  st_as_sf(coords = c(\"x\", \"y\")) |&gt; \n  st_set_crs(value = crs(world))\n\n\n# Easiest (but not tidyverse) way to subset\n# world[random_points, ]\n\n# Tidyverse way to filter: Names of Countries in which they fall\nintersecting_countries &lt;- world |&gt; \n  st_filter(random_points) |&gt; \n  pull(name_long)\n\n# The power of spatial joins: A tibble of countries where each random\n# point falls. st_join() by default performs a left_join()\nst_join(\n  random_points, \n  world |&gt; select(name_long)\n) |&gt; \n  drop_na() |&gt; \n  gt::gt() |&gt; \n  gtExtras::gt_theme_nytimes()\n\n\n\n\n\n\n\n\nid\ngeometry\nname_long\n\n\n\n\nI\nc(43.05, 61.96)\nRussian Federation\n\n\nN\nc(112.59, 71.68)\nRussian Federation\n\n\nO\nc(59.22, 33.55)\nIran\n\n\nP\nc(93.88, 52.24)\nRussian Federation\n\n\nR\nc(62.63, 51.25)\nKazakhstan\n\n\nS\nc(-17.61, -88.84)\nAntarctica\n\n\n\n\n\n\n\n\n\nCode\nset.seed(42)\n\nworld |&gt; \n  mutate(highlight = name_long %in% intersecting_countries) |&gt; \n  ggplot() +\n  geom_sf(\n    mapping = aes(\n      fill = highlight\n    ),\n    alpha = 0.5\n  ) +\n  scale_fill_manual(\n    values = c(\"transparent\", \"red\")\n  ) +\n  geom_sf(\n    data = random_points,\n    pch = 20,\n    size = 4,\n    colour = \"black\",\n    alpha = 0.5\n  ) +\n  ggrepel::geom_text_repel(\n    data = random_points,\n    mapping = aes(label = id, geometry = geometry),\n    size = 4,\n    colour = \"black\",\n    nudge_x = 2,\n    nudge_y = -2,\n    stat = \"sf_coordinates\"\n  ) +\n  labs(\n    title = \"25 random points on world map, and Countries in which they fall\",\n    x = NULL, y = NULL\n  ) +\n  theme(\n    legend.position = \"none\"\n  )\n\n\n\n\n\n\n\n\nFigure 3: Using st_join() to spatially join two data sets, based on the st_intersect() relation\n\n\n\n\n\n\n\n4.2.6 Distance-based Joins\n\nDistance-based joins are used when geographic datasets are spatially proximate but do not intersect. The sf package enables such joins using spatial relationships like proximity.\nExample Dataset used:\n\ncycle_hire: Official cycle hire points.\ncycle_hire_osm: Cycle hire points from OpenStreetMap.\nRelationship: These datasets are geographically close but do not overlap, as verified using st_intersects(), which returns FALSE for all points.\n\nImplementation:\n\nCheck Proximity:\n\nUse st_is_within_distance() to determine points within a threshold distance (e.g., 20 meters).\n\nPerform Distance-based Join:\n\nApply st_join() with the st_is_within_distance predicate and a dist argument.\nThe resulting dataset may contain duplicate rows if points in the target object (cycle_hire) match multiple points in the source (cycle_hire_osm).\n\n\nKey Observations:\n\nJoins retain the geometry of features in the target dataset (cycle_hire).\nDistance-based joins are effective for linking datasets that are close geographically but do not overlap.\n\n\nFigure 4 visualizes the spatial relationship between two datasets, cycle_hire and cycle_hire_osm, using a proximity filter. The st_filter() function from the sf package identifies points in the cycle_hire dataset that are within 10 meters of points in cycle_hire_osm, leveraging the st_is_within_distance predicate. The result is a subset of cycle_hire points, which are plotted using ggplot2. The plot includes:\n\nFiltered cycle_hire points (dark blue, fully opaque).\nAll cycle_hire points (dark blue, semi-transparent) for context.\nAll cycle_hire_osm points (red, semi-transparent) to show the proximity relationship.\n\n\n\nCode\ndata(\"cycle_hire\")\ndata(\"cycle_hire_osm\")\n\nggplot() +\n  geom_sf(\n    data = cycle_hire,\n    colour = \"blue\",\n    alpha = 0.5\n  ) +\n  geom_sf(\n    data = cycle_hire_osm,\n    colour = \"red\",\n    alpha = 0.5\n  )\n\n\n\n\n\n\n\n\n\nCode\n# Official Cycle hire points with added info from OSM points within 10 metres\n# \n# cycle_hire |&gt; \n#   st_join(\n#     cycle_hire_osm, \n#     join = st_is_within_distance,\n#     dist = units::set_units(10, \"m\")\n#   )\n\n\nJust checking, whether any of the two points in these two data sets exactly match. Well, they don’t!\n\nst_intersects(cycle_hire, cycle_hire_osm, sparse = F) |&gt; any()\n\n[1] FALSE\n\n\nNow, in Figure 4, we highlight only those points of bike hire in the official data, which are within 10 metres of the OSM data. The important function here is st_filter() along with the argument .predicate = st_is_within_distance() and the argument dist = ... .\n\n\nCode\n# Plot only points which have a OSM point within 10 metres\ncycle_hire |&gt; \n  st_filter(\n    cycle_hire_osm,\n    .predicate = st_is_within_distance,\n    dist = units::set_units(10, \"m\")\n  ) |&gt; \n  ggplot() +\n  geom_sf(size = 3, alpha = 0.75, colour = \"darkblue\") +\n  geom_sf(\n    data = cycle_hire, \n    alpha = 0.2, \n    colour = \"blue\",\n    size = 1\n  ) +\n  geom_sf(\n    data = cycle_hire_osm, \n    alpha = 0.2, \n    colour = \"red\",\n    size = 1\n  )\n\n\n\n\n\n\n\n\nFigure 4: Official Cycle Hire Points Within 10 Meters of OpenStreetMap Locations\n\n\n\n\n\n\n\n4.2.7 Spatial Aggregation\n\nSpatial data aggregation condenses data into fewer rows by summarizing multiple values of a variable into a single value per grouping variable, similar to attribute data aggregation. Following two approaches exist: —\n\nBase R’s aggregate(): Groups values based on spatial relationships and summarizes them with a specified function (e.g., mean).\nTidyverse Approach (group_by() and summarize()): Combines st_join() with grouping and summarizing to perform spatial aggregation while allowing flexibility in function application and column naming. (This approach is better, as shown in Figure 5)\n\nOutput Differences:\n\naggregate() may result in NA for unmatched regions.\nTidyverse methods preserve unmatched region names and allow for more flexible aggregation functions and output formatting.\n\nFunctions like median(), sd(), or other statistical summarizers can replace mean() for different aggregation purposes.\n\n\ndata(\"nz_height\")\ndata(\"nz\")\n\nst_join(x = nz, y = nz_height) |&gt; \n  group_by(Name) |&gt; \n  summarise(elevation = mean(elevation, na.rm = T)) |&gt; \n  ggplot(\n    mapping = aes(fill = elevation)\n  ) +\n  geom_sf() +\n  paletteer::scale_fill_paletteer_c(\n    \"grDevices::Terrain 2\",\n    na.value = \"white\"\n  )\n\n\n\n\n\n\n\nFigure 5: Spatial data aggregation with st_join() from {sf} and summarise() from {tidyverse}\n\n\n\n\n\n\n\n4.2.8 Joining In-congruent Layers\n\nSpatial congruence occurs when two layers (aggregating object y and target object x) share borders, enabling accurate spatial aggregation. Incongruence arises when no shared borders exist, complicating spatial operations.\nExample of Congruence:\n\nAdministrative boundaries, such as districts made of smaller units, typically exhibit spatial congruence.\n\nIssue with Incongruence:\n\nIn-congruent layers, like sub-zones with differing borders from aggregating zones, result in inaccurate aggregations (e.g., centroids of sub-zones).\n\nSolution: Areal Interpolation: Transfers values between areal units using:\n\nSimple area-weighted methods: Proportionally assigns values based on area overlap. This is implemented using st_interpolate_aw().\nAdvanced methods: Include algorithms like ‘pycnophylactic’ interpolation.\n\nExample Dataset:\n\nThe spData package includes incongruent (sub-zones) and aggregating_zones (larger zones). The value column in incongruent represents total regional income in million Euros, which must be aggregated into aggregating_zones.\n\nImplementation: st_interpolate_aw():\n\nThe st_interpolate_aw() function in the sf package performs areal-weighted interpolation of polygon data, allowing attributes from one spatial object (x) to be transferred to another (to) based on area overlap. The extensive argument determines whether attributes are spatially extensive (e.g., population, summed across areas) or spatially intensive (e.g., density, averaged). Additional options include keep_NA (to retain or exclude NA features) and na.rm (to remove features with NA attributes from x).\nAggregated results depend on the variable type:\n\nExtensive variables: Values increase with area (e.g., total income).\nIntensive variables: Values remain constant irrespective of area (e.g., averages).\n\nst_interpolate_aw() handles spatially extensive variables (e.g., total income) by summing values across areas.\nIn st_interpolate_aw(), for spatially intensive variables (e.g., averages, percentages), set extensive = FALSE to use averages instead of sums.\nNote: Warning messages indicate the assumption of uniform attribute distribution across areas.\n\n\n\ndata(\"aggregating_zones\")\ndata(\"incongruent\")\n\n# The two overall main zones for which the total income needs to be computed\naggregating_zones\n\nSimple feature collection with 2 features and 3 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 417686.2 ymin: 443703.6 xmax: 422959.3 ymax: 447036.8\nProjected CRS: OSGB 1936 / British National Grid\n      geo_code geo_label geo_labelw                       geometry\n5164 E02002332 Leeds 003       &lt;NA&gt; MULTIPOLYGON (((418731.9 44...\n6631 E02002333 Leeds 004       &lt;NA&gt; MULTIPOLYGON (((419196.4 44...\n\n# The 9 smaller counties or districts or sub-units which are not\n# congruent with the main zones\nincongruent\n\nSimple feature collection with 9 features and 2 fields\nAttribute-geometry relationships: aggregate (1), NA's (1)\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 417686.8 ymin: 443703 xmax: 422963 ymax: 446978\nProjected CRS: OSGB 1936 / British National Grid\n        level    value                       geometry\n1 Incongruent 4.037919 MULTIPOLYGON (((420799.6 44...\n2 Incongruent 5.014419 MULTIPOLYGON (((418664 4464...\n3 Incongruent 4.933000 MULTIPOLYGON (((419964 4462...\n4 Incongruent 5.120139 MULTIPOLYGON (((420368 4441...\n5 Incongruent 6.548912 MULTIPOLYGON (((420419.8 44...\n6 Incongruent 3.749791 MULTIPOLYGON (((421779 4451...\n7 Incongruent 5.432837 MULTIPOLYGON (((419577 4464...\n8 Incongruent 4.618049 MULTIPOLYGON (((417687.6 44...\n9 Incongruent 5.956771 MULTIPOLYGON (((418859.3 44...\n\n# We are using extensive = TRUE, because our variable is \n# total income, not average income\nincongruent |&gt; \n  # We need to keep only the numeric variable (and of course,\n  # the sticky geometry. Otherwise, R will not understand what\n  # to do with non-numeric columns)\n  select(value) |&gt; \n  st_interpolate_aw(aggregating_zones, extensive = TRUE)\n\nWarning in st_interpolate_aw.sf(select(incongruent, value), aggregating_zones,\n: st_interpolate_aw assumes attributes are constant or uniform over areas of x\n\n\nSimple feature collection with 2 features and 1 field\nAttribute-geometry relationship: aggregate (1)\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 417686.2 ymin: 443703.6 xmax: 422959.3 ymax: 447036.8\nProjected CRS: OSGB 1936 / British National Grid\n     value                       geometry\n1 19.61613 MULTIPOLYGON (((418731.9 44...\n2 25.66872 MULTIPOLYGON (((419196.4 44..."
  },
  {
    "objectID": "book_solutions/chapter4.html#spatial-operations-on-raster-data",
    "href": "book_solutions/chapter4.html#spatial-operations-on-raster-data",
    "title": "Chapter 4: Spatial data operations",
    "section": "4.3 Spatial operations on raster data",
    "text": "4.3 Spatial operations on raster data\n\nDemonstrates advanced spatial raster operations.\nProvides an alternative to manually creating datasets by accessing them from the spData package:\n\nelev: Represents elevation data.\ngrain: Represents grain-related data.\n\n\nelev &lt;- rast(system.file(\"raster/elev.tif\", \n                        package = \"spData\"))\n\ngrain &lt;- rast(system.file(\"raster/grain.tif\", \n                         package = \"spData\"))\n\n# plot(elev)\n# plot(grain)\n\nggplot() +\n  geom_spatraster(data = elev) +\n  labs(title = \"elev SpatRaster\", caption = \"data: {spData}\")\n  \n\nggplot() +\n  geom_spatraster(data = grain) +\n  labs(title = \"grain SpatRaster\", caption = \"data: {spData}\")\n\n\n\n\n\n\n\n\n\n\n\n(a) elev\n\n\n\n\n\n\n\n\n\n\n\n(b) grain\n\n\n\n\n\n\n\nFigure 6: Section 4.3: Raster Datasets used: plotted using ggplot2 and {tidyterra}\n\n\n\n\n4.3.1 Spatial subsetting\n\nBuilds on Section 3.3, which covered retrieving raster values by cell IDs or row/column combinations.\nSpatial subsetting allows extraction of raster data by location (coordinates) or spatial objects:\n\nterra::extract(): Extracts raster values directly using coordinates. (Note: A function with the same name exists in the tidyverse, so be careful to add package name at start).\n\nSubsetting with another raster object:\n\nUse a secondary raster as a spatial mask to subset the primary raster, using terra::extract(ext(...)) .\nExample shown below: Subsetting elev using a smaller raster clip_raster (defining a specific extent).\nTwo kinds of Spatial outputs from subsetting:\n\nUse the drop argument with the [ ] operator to return subsetting results as raster objects.\nExample: Subsets the first two cells of elev with elev[1:2, drop = FALSE], whereas elev[1:2] returns the cell values of first two cells only.\n\n\nMasking raster data with logical values:\n\nCreates a raster mask (rmask) with NA and TRUE values.\nMasks the primary raster (elev) to retain only values corresponding to TRUE in the mask using:\n\n[ ] operator - use TRUE and FALSE.\nmask() function - use TRUE and NA.\n\n\nThe mask() function in the terra package applies a mask to a SpatRaster or SpatVector. It replaces values in a raster (x) with NA (or another value) where another raster or vector (mask) has NA or specified mask values. It’s useful for filtering, clipping, or focusing on specific areas.\nThe extract() function in the terra package retrieves values from a SpatRaster based on specified locations or geometries. Locations can be points (as a SpatVector, matrix, or data frame), cell numbers, or spatial objects like polygons. It supports methods for exact or weighted extraction, interpolation, and summary statistics for extracted data. Key arguments include:\n\nx: The SpatRaster to extract values from\ny: Locations (e.g., points, polygons, or cell numbers) to extract values for.\nfun: Summarizes extracted data for polygons (e.g., mean, sum).\ncells/xy: Optionally return cell numbers or coordinates.\nweights/exact: Extract weighted or exact fractions for polygons.\nbind: Combines extracted values with input geometries (SpatVector).\n\nThe code below demonstrates these spatial operations on raster data. Initially, it showcases how to extract raster values using coordinates with terra::extract() by specifying a set of coordinate pairs. Next, it demonstrates how to create a new raster (clip_raster) to subset the elev raster, focusing on extracting values only within the extent defined by the clip raster using both the [ ] operator and terra::extract(). The example highlights the importance of the drop = FALSE argument in the [ ] operator, which ensures that spatial structure is preserved when subsetting raster objects. Finally, the code illustrates the use of masking with a logical raster (temporary_mask), where specific cells in the elev raster are retained based on TRUE values in the mask. This process is essential for filtering or replacing values (e.g., assigning NA to erroneous data).\n\n\n# Let us extract some values from \"elev\" using coordinates\n# I want to extract coordiantes of \ncoords_extract &lt;- matrix(\n  c(-1.2, -1.2,\n    1.2, 1.2),\n  ncol = 2,\n  byrow = T\n)\n\ncoords_extract\n\n     [,1] [,2]\n[1,] -1.2 -1.2\n[2,]  1.2  1.2\n\nelev |&gt; \n  terra::extract(\n    y = coords_extract\n  )\n\n  elev\n1   31\n2    6\n\n# Let us create a new raster to clip the central four blocks of the elev raster\nclip_raster &lt;- rast(\n  xmin = -0.5, xmax = 0.5, \n  ymin = -0.5, ymax = 0.5,\n  resolution = 0.5, \n  vals = sample(1:25, 4)\n  )\n\n# Extracting only the values\nelev[clip_raster]\n\n  elev\n1   15\n2   16\n3   21\n4   22\n\n# This code somehow doesn't work for me!\n# elev |&gt; \n#   terra::extract(ext(clip_raster))\n\n# Explaining the meaning of argument drop = FALSE in the \n# base R subsetting operator \"[]\"\nelev[1:2]\n\n  elev\n1    1\n2    2\n\nelev[1:2, drop = FALSE]    \n\nclass       : SpatRaster \ndimensions  : 1, 2, 1  (nrow, ncol, nlyr)\nresolution  : 0.5, 0.5  (x, y)\nextent      : -1.5, -0.5, 1, 1.5  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (EPSG:4326) \nsource(s)   : memory\nvarname     : elev \nname        : elev \nmin value   :    1 \nmax value   :    2 \n\n# Creating a temporary_mask object\ntemporary_mask &lt;- elev\nvalues(temporary_mask) &lt;- sample(c(NA, TRUE), 36,\n                                 replace = T)\n# elev |&gt; \n#   mask(temporary_mask)\n\nggplot() +\n  geom_spatraster(data = clip_raster)\n\nggplot() +\n  geom_spatraster(data = temporary_mask) +\n  scale_fill_discrete(na.value = \"white\")\n\nggplot() +\n  geom_spatraster(data = elev |&gt; mask(temporary_mask)) +\n  scale_fill_continuous(na.value = \"white\")\n\n\n\n\n\n\n\n\n\n\n\n(a) Plotting clip_raster: a smaller raster\n\n\n\n\n\n\n\n\n\n\n\n(b) The temporary_mask raster\n\n\n\n\n\n\n\n\n\n\n\n(c) plotting the masked elev, based on a randomly generated temporary_mask\n\n\n\n\n\n\n\nFigure 7: Showing plots from the code of above\n\n\n\n\n\n4.3.3 Local operations\n\nLocal operations are cell-by-cell operations performed on one or more raster layers. Includes operations like addition, subtraction, squaring, logical comparisons, and logarithmic transformations. Examples are shown in Figure 8\nReclassification:\n\nNumeric values can be grouped into intervals (e.g., low, middle, high elevations).\nUse the classify() function with a reclassification matrix to assign new values to defined ranges.\n\n\n\nggplot() +\n  geom_spatraster(data = elev) +\n  ggtitle(\"`elev` - the original raster\") +\n  paletteer::scale_fill_paletteer_c(\"grDevices::terrain.colors\") +\n  theme(legend.position = \"bottom\")\n\nggplot() +\n  geom_spatraster(data = elev^2) +\n  ggtitle(\"elev^2\") +\n  paletteer::scale_fill_paletteer_c(\"grDevices::terrain.colors\") +\n  theme(legend.position = \"bottom\",\n        legend.key.width = unit(30, \"pt\"))\n\nggplot() +\n  geom_spatraster(data = log2(elev)) +\n  ggtitle(\"log2(elev)\") +\n  paletteer::scale_fill_paletteer_c(\"grDevices::terrain.colors\") +\n  theme(legend.position = \"bottom\",\n        legend.key.width = unit(30, \"pt\"))\n\n\nggplot() +\n  geom_spatraster(data = elev &gt; 10) +\n  ggtitle(\"elev &gt; 10\") +\n paletteer::scale_fill_paletteer_d(\"ggsci::alternating_igv\") +\n  theme(legend.position = \"bottom\",\n        legend.key.width = unit(30, \"pt\"))\n\n\n\n\n\n\n\n\n\n\n(a) elev\n\n\n\n\n\n\n\n\n\n\n\n(b) elev^2\n\n\n\n\n\n\n\n\n\n\n\n(c) log2(elev)\n\n\n\n\n\n\n\n\n\n\n\n(d) elev &gt; 10\n\n\n\n\n\n\nFigure 8\n\n\n\n\n\nEfficient alternatives for operations:\n\napp(): The app() function in the {terra} package applies a user-defined or pre-existing function to each cell’s values of a SpatRaster, treating layers as columns in a matrix. Functions should return outputs divisible by the total cell count.\ntapp(): The tapp() function in the {terra} package applies a function to subsets of layers in a SpatRaster grouped by an index. It allows for aggregation or summarization of layers based on grouping criteria such as indices, time periods (e.g., “years”, “months”), or custom functions.\nlapp(): The lapp() function in the {terra} package applies a user-defined function to the layers of a SpatRaster or SpatRasterDataset, treating each layer as an argument to the function. The function must accept a vector of layer values and return a vector or matrix of the same or compatible size. This is useful for combining or transforming layers, such as performing arithmetic operations between them. An example of lapp() is the NDVI Calculation:\n\nNDVI (Normalized Difference Vegetation Index) is a local operation to assess vegetation:\n\nFormula: (NIR - Red) / (NIR + Red).\n\nCalculated from satellite data (e.g., Landsat 8) with red and NIR bands.\n\nPositive NDVI values (&gt; 0.2) indicate vegetation.\nLargest values correspond to dense forests, while lowest values are related to lakes and snowy areas.\n\n\n\n\n\nmulti_rast = system.file(\"raster/landsat.tif\", package = \"spDataLarge\")\nmulti_rast = rast(multi_rast)\n# Rescale values to actual values (stored integers to save disk space)\nmulti_rast = (multi_rast * 0.0000275) - 0.2\n# Remove negative values due to clouds etc.\nmulti_rast[multi_rast &lt; 0] = 0\nobject.size(multi_rast)\n\n1304 bytes\n\nndvi_fun = function(nir, red){\n  (nir - red) / (nir + red)\n}\n\nndvi_rast = lapp(multi_rast[[c(4, 3)]], fun = ndvi_fun)\n\nggplot() +\n  geom_spatraster(\n    data = ndvi_rast,\n    mapping = aes(fill = lyr1)\n  ) +\n  paletteer::scale_fill_paletteer_c(\n    \"grDevices::Terrain 2\",\n    direction = -1,\n    limits = c(0, 1),\n    oob = scales::squish\n  ) +\n  labs(\n    title = \"Zion National Park - Satellite Photo Raster\",\n    subtitle = \"Using custom nvdi_fun() to find NVDI\\nand plot vegetation areas in {ggplot2}\",\n    fill = NULL\n  ) +\n  theme(\n    legend.position = \"bottom\",\n    legend.key.width = unit(40, \"pt\")\n  )\n\n\n\n\n\n\n\n\n\n\n4.3.4 Focal operations\n\nFocal operations consider a central cell and its neighbours within a defined neighbourhood (kernel, filter, or moving window).\n\nCommon neighbourhood size: 3x3 cells (central cell + 8 neighbours), but customizable sizes and shapes are supported.\nThe operation aggregates values within the neighbourhood and assigns the result to the central cell, iterating across all cells.\n\nImplementation in R:\n\nUse the focal() function to perform spatial filtering Figure 9. Parameters:\n\nw: Defines the weights of the moving window using a matrix, example in Figure 9 (c).\nfun: Specifies the aggregation function (e.g., min, sum, mean, var), as in Figure 9 (b)\n\n\nApplications:\n\nSpatial filtering or convolution for raster operations.\nLow-pass filters:\n\nUse the mean function to smooth and reduce extreme values.\nFor categorical data, replace the mean with the mode (most common value).\n\nHigh-pass filters:\n\nEnhance features using methods like Laplace or Sobel filters (e.g., line detection).\n\nTerrain processing:\n\nCompute topographic characteristics like slope, aspect, and flow directions using focal functions.\n\n\n\n\nggplot() +\n  geom_spatraster(data = elev) +\n  labs(title = \"elev SpatRaster\", caption = \"data: {spData}\")\n\nggplot() +\n  geom_spatraster(\n    data = elev |&gt; \n        terra::focal(\n        w = matrix(rep(1, 9), 3, 3),\n        fun = min\n      )\n  ) +\n  labs(title = \"Focal operation min on a 3X3 matric\",\n       subtitle = \"Simple min() function with na.rm = FALSE\")\n\nggplot() +\n  geom_spatraster(\n    data = elev |&gt; \n        terra::focal(\n        # Sobel filters (for edge detection):\n        w = matrix(c(-1,-2,-1,0,0,0,1,2,1), nrow = 3),\n        fun = mean,\n        na.rm = TRUE\n      )\n  ) +\n  labs(\n    title = \"Focal operation min on a 3X3 matric\",\n    subtitle = \"Sobel filter matrix for edge detection, with mean() function\"\n  )\n\n\n\n\n\n\n\n\n\n\n(a) Original elev raster\n\n\n\n\n\n\n\n\n\n\n\n(b) Focal operation with min() and a simple matrix of equal weights\n\n\n\n\n\n\n\n\n\n\n\n(c) Focal operation with mean() and a sobel filter matrix for edge detection\n\n\n\n\n\n\nFigure 9: Focal operations on Rasters using terra::focal()\n\n\n\n\n\n\n4.3.5 Zonal operations\n\nZonal operations aggregate raster cell values based on zones defined by a second raster with categorical values. Unlike focal operations, zones in zonal operations do not require neighboring cells to be adjacent.\nKey Characteristics:\n\nThe zonal() function in the terra package computes zonal statistics by summarizing the values of a SpatRaster for each “zone” defined by another SpatRaster. It applies a specified function (fun, e.g., mean, sum) to aggregate the data for each zone.\nThe result is typically a summary table, grouped by zones. Zones are defined by a secondary raster.\nOptional Output: A raster with calculated statistics for each zone can be generated by setting as.raster = TRUE.\n\nUsage:\n\nIdeal for summarizing raster values based on irregularly spread categorical zones.\nCommonly used in land classification, soil analysis, and other spatial analyses where zones are pre-defined.\n\n\nggplot() +\n  geom_spatraster(data = elev) +\n  labs(title = \"elev SpatRaster\", caption = \"data: {spData}\")\n  \n\nggplot() +\n  geom_spatraster(data = grain) +\n  labs(title = \"grain SpatRaster\", caption = \"data: {spData}\")\n\n\n\n\n\n\n\n\n\n\n\n(a) elev\n\n\n\n\n\n\n\n\n\n\n\n(b) grain\n\n\n\n\n\n\n\nFigure 10: The elev and grain rasters\n\n\n\n\nelev |&gt; \n  terra::zonal(\n    z = grain,\n    fun = mean\n  ) |&gt; \n  as_tibble()\n\n# A tibble: 3 × 2\n  grain  elev\n  &lt;chr&gt; &lt;dbl&gt;\n1 clay   14.8\n2 silt   21.2\n3 sand   18.7\n\n\n\n\n4.3.6 Global operations and distances\n\nGlobal operations consider the entire raster dataset as a single zone.\nCommon operations include:\n\nDescriptive statistics: Minimum, maximum, etc.\nDistance calculations: Compute distance from each cell to a target cell using terra::distance(). The terra::distance() function calculates the shortest distance from each cell in a raster to a set of target cells, which are identified based on a condition (e.g., where raster values are non-NA, equal to a specific value, or greater than a threshold). This is useful for spatial analysis, such as finding proximity to certain features or zones in a raster.\nWeighted distances: Factor in additional variables, such as elevation, to modify distance calculations.\nVisibility and viewshed analysis: Assess visible areas from a specific point.\n\nApplications:\n\nDistance to coastlines or other target areas.\nTopography-aware distance calculations.\nAdvanced spatial modeling like visibility analysis.\n\n\n\n# Create a sample SpatRaster\nr &lt;- rast(ncols = 10, nrows = 10, \n          xmin = 0, xmax = 10, \n          ymin = 0, ymax = 10)\nvalues(r) &lt;- NA\nvalues(r)[c(5, 15, 25)] &lt;- 1  # Assign specific cells as targets\n\n# Compute the distance to the non-NA cells\ndist_raster &lt;- distance(r)\n\n\n|---------|---------|---------|---------|\n=========================================\n                                          \n\ndist_raster &lt;- dist_raster * 1e-5\n\n# View the raster\nggplot() +\n  geom_spatraster(data = r) +\n  labs(title = \"Original Raster (Targets in Blue)\") +\n  theme(\n    legend.position = \"bottom\"\n  )\n\n# View the distance raster\nggplot() +\n  geom_spatraster(data = dist_raster) +\n  labs(title = \"Distance to Targets (in units)\",\n       fill = \"Distance in Degrees\") +\n  paletteer::scale_fill_paletteer_c(\"ggthemes::Red-Gold\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\n\n\n(a) Original raster\n\n\n\n\n\n\n\n\n\n\n\n(b) Distance raster\n\n\n\n\n\n\n\nFigure 11: Using the terra::distance()\n\n\n\n\n\n4.3.7 Map algebra counterparts in vector processing\n\nEquivalence between raster and vector operations:\n\nDistance raster (global operation) ≈ Buffer operation (vector) (Section 5.2.5).\nRaster reclassification ≈ Dissolving vector boundaries (Section 4.2.5).\nRaster overlay with masks ≈ Vector clipping (Section 5.2.5).\nZonal operations ≈ Aggregating vector geometries by zones.\n\n\n\n\n4.3.8 Merging rasters\n\nCombines multiple raster datasets into a single raster. Often required for datasets spanning multiple spatial scenes (e.g., satellite imagery, elevation data).\nmerge():\n\nPlaces rasters side by side.\nFor overlapping areas, prioritizes values from the first raster.\n\n\n\naut &lt;- geodata::elevation_30s(country = \"AUT\", path = tempdir())\nggplot() +\n  geom_spatraster(data = aut) +\n  scale_fill_wiki_c() +\n  ggtitle(\"Austria\")\n\n\n\n\n\n\n\ncze &lt;- geodata::elevation_30s(country = \"CZE\", path = tempdir())\nggplot() +\n  geom_spatraster(data = cze) +\n  scale_fill_wiki_c() +\n  ggtitle(\"Czechia\")\n\n\n\n\n\n\n\nsvk &lt;- geodata::elevation_30s(country = \"SVK\", path = tempdir())\nggplot() +\n  geom_spatraster(data = svk) +\n  scale_fill_wiki_c() +\n  ggtitle(\"Slovakia\")\n\n\n\n\n\n\n\naut_cze_svk &lt;- aut |&gt; \n  merge(svk) |&gt; \n  merge(cze)\n\nggplot() +\n  geom_spatraster(data = aut_cze_svk) +\n  scale_fill_wiki_c() +\n  ggtitle(\"Austria, Czechia and Slovakia\")\n\n\n\n\n\n\n\n\n\nmosaic():\n\nHandles overlaps by applying a function (e.g., mean) to the overlapping area.\nHelps smooth visible borders but may not eliminate them entirely."
  },
  {
    "objectID": "book_solutions/chapter4.html#exercises",
    "href": "book_solutions/chapter4.html#exercises",
    "title": "Chapter 4: Spatial data operations",
    "section": "4.4 Exercises",
    "text": "4.4 Exercises\n\nE1.\nIt was established in Section 4.2 that Canterbury was the region of New Zealand containing most of the 101 highest points in the country. How many of these high points does the Canterbury region contain?\nCanterbury contains 70 of these high points.\n\ndata(\"nz\")\ndata(\"nz_height\")\n\nnz_height |&gt; \n  st_intersection(\n    nz |&gt; filter(Name == \"Canterbury\")\n  ) |&gt; \n  nrow()\n\n[1] 70\n\n\nBonus: plot the result using the plot() function to show all of New Zealand, canterbury region highlighted in yellow, high points in Canterbury represented by red crosses (hint: pch = 7) and high points in other parts of New Zealand represented by blue circles. See the help page ?points for details with an illustration of different pch values.\n\nnz_height |&gt; \n  mutate(\n    in_canterbury = nz_height |&gt; \n      st_intersects(\n        nz |&gt; filter(Name == \"Canterbury\"),\n        sparse = FALSE\n      )\n  ) |&gt; \n  ggplot() +\n  geom_sf(\n    data = nz |&gt; mutate(fill_var = Name == \"Canterbury\"),\n    mapping = aes(fill = fill_var)\n  ) +\n  geom_sf(\n    mapping = aes(shape = in_canterbury, colour = in_canterbury)\n  ) +\n  scale_shape_manual(values = c(16, 4)) +\n  scale_colour_manual(values = c(\"blue\", \"red\")) +\n  scale_fill_manual(values = c(\"transparent\", \"yellow\")) +\n  labs(\n    fill = \"Is the region Canterbury?\",\n    colour = \"Peaks are in Canterbury?\",\n    shape = \"Peaks are in Canterbury?\"\n  ) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\n\n\nE2.\nWhich region has the second highest number of nz_height points, and how many does it have?\nThe region with second highest number of nz_height points is West Coast. It has 22 such points.\n\nnz_height |&gt; \n  st_join(nz) |&gt; \n  st_drop_geometry() |&gt; \n  group_by(Name) |&gt; \n  count()\n\n# A tibble: 7 × 2\n# Groups:   Name [7]\n  Name                  n\n  &lt;chr&gt;             &lt;int&gt;\n1 Canterbury           70\n2 Manawatu-Wanganui     2\n3 Marlborough           1\n4 Otago                 2\n5 Southland             1\n6 Waikato               3\n7 West Coast           22\n\n\n\n\n\nE3.\nGeneralizing the question to all regions: how many of New Zealand’s 16 regions contain points which belong to the top 101 highest points in the country? Which regions?\n\nBonus: create a table listing these regions in order of the number of points and their name.\n\nSeven (7) regions of New Zealand contain points which belong to top 101 highest points in the country. The table is shown below.\n\nnz_height |&gt; \n  st_join(nz) |&gt; \n  st_drop_geometry() |&gt; \n  group_by(Name) |&gt; \n  count(name = \"Number of points\", sort = T) |&gt; \n  ungroup() |&gt; \n  mutate(`S.No.` = row_number()) |&gt; \n  relocate(`S.No.`) |&gt;\n  gt::gt() |&gt; \n  gtExtras::gt_theme_538() |&gt; \n  gt::tab_header(\n    title = \"Number of highest points in each region of New Zealand\"\n  )\n\n\n\nTable 2: Table listing the regions\n\n\n\n\n\n\n\n\n\nNumber of highest points in each region of New Zealand\n\n\nS.No.\nName\nNumber of points\n\n\n\n\n1\nCanterbury\n70\n\n\n2\nWest Coast\n22\n\n\n3\nWaikato\n3\n\n\n4\nManawatu-Wanganui\n2\n\n\n5\nOtago\n2\n\n\n6\nMarlborough\n1\n\n\n7\nSouthland\n1\n\n\n\n\n\n\n\n\n\n\n\nTest your knowledge of spatial predicates by finding out and plotting how US states relate to each other and other spatial objects.\n\n\nE4.\nThe starting point of this exercise is to create an object representing Colorado state in the USA. Do this with the command colorado = us_states[us_states$NAME == \"Colorado\",] (base R) or with the filter() function (tidyverse) and plot the resulting object in the context of US states.\n\ndata(\"us_states\")\n\ncolorado &lt;- us_states |&gt; \n  filter(NAME == \"Colorado\")\n\nggplot() +\n  geom_sf(data = colorado) +\n  ggtitle(\"Map of Colorado State\") +\n  coord_sf(\n    crs = \"EPSG:5070\"\n  )\n\n\n\n\n\n\n\nFigure 12: Map of Colorado State\n\n\n\n\n\n\nCreate a new object representing all the states that geographically intersect with Colorado and plot the result (hint: the most concise way to do this is with the subsetting method [).\n\n\nggplot() +\n  geom_sf(\n    data = us_states,\n    fill = \"transparent\"\n  ) +\n  geom_sf(\n    data = colorado,\n    fill = \"yellow\"\n  ) +\n  geom_sf_text(\n    data = colorado,\n    mapping = aes(\n      label = NAME\n    ),\n    family = \"caption_font\",\n    fontface = \"bold\"\n  ) +\n  coord_sf(\n    crs = \"EPSG:5070\"\n  ) +\n  labs(\n    x = NULL, y = NULL,\n    title = \"Map of USA states, with Colorado highlighted\"\n  )\n\n\n\n\n\n\n\nFigure 13: Colorado, within USA’s states; with projection changed to Albers Equal Area Projection\n\n\n\n\n\n\nCreate another object representing all the objects that touch (have a shared boundary with) Colorado and plot the result (hint: remember you can use the argument op = st_intersects and other spatial relations during spatial subsetting operations in base R).\n\n\nbordering &lt;- us_states |&gt; \n  mutate(\n    border_colorado = as_vector(\n      as_vector(\n        us_states |&gt; \n        st_intersects(colorado, sparse = FALSE)\n      )\n    )\n  )\n\nggplot() +\n  geom_sf(\n    data = bordering,\n    mapping = aes(\n      fill = border_colorado\n    )\n  ) +\n  scale_fill_manual(\n    values = c(\"transparent\", \"orange\")\n  ) +\n  geom_sf_text(\n    data = filter(bordering, border_colorado),\n    mapping = aes(\n      label = NAME\n    ),\n    family = \"caption_font\"\n  ) +\n  geom_sf(\n    data = colorado,\n    fill = \"red\"\n  ) +\n  geom_sf_text(\n    data = colorado,\n    mapping = aes(\n      label = NAME\n    ),\n    family = \"caption_font\",\n    fontface = \"bold\"\n  ) +\n  coord_sf(\n    crs = \"EPSG:5070\"\n  ) +\n  labs(\n    x = NULL, y = NULL,\n    title = \"Map of USA states, with states bordering Colorado highlighted in orange\"\n  ) +\n  theme(\n    legend.position = \"none\"\n  )\n\n\n\n\n\n\n\n\n\nBonus: create a straight line from the centroid of the District of Columbia near the East coast to the centroid of California near the West coast of the USA (hint: functions st_centroid(), st_union() and st_cast() described in Chapter 5 may help) and identify which states this long East-West line crosses.\n\n\nwdc_centre &lt;- st_centroid(\n  us_states |&gt; filter(NAME == \"District of Columbia\")\n) |&gt; \n  pull(geometry)\n\ncal_centre &lt;- st_centroid(\n  us_states |&gt; filter(NAME == \"California\")\n) |&gt; \n  pull(geometry)\n\nstraight_line &lt;- st_union(\n  wdc_centre,\n  cal_centre\n) |&gt; \n  st_cast(\n    \"LINESTRING\"\n  )\n\nus_states |&gt; \n  mutate(\n    on_the_way = as_vector(\n      st_intersects(\n        us_states, \n        straight_line, \n        sparse = FALSE\n      )\n    )\n  ) |&gt; \n  ggplot() +\n  geom_sf(\n    mapping = aes(\n      fill = on_the_way\n    )\n  ) +\n  scale_fill_manual(\n    values = c(\"transparent\", \"orange\")\n  ) +\n  geom_sf(\n    data = straight_line,\n    linewidth = 0.5\n  ) +\n  geom_sf(\n    data = cal_centre,\n    size = 2\n  ) +\n  geom_sf(\n    data = wdc_centre,\n    size = 2\n  ) +\n  coord_sf(\n    crs = \"EPSG:5070\"\n  ) +\n  labs(\n    subtitle = \"Line from Centroids of District of Columbia and California;\\nand highlighting the states that it crosses through\"\n  ) +\n  theme(\n    legend.position = \"none\"\n  )\n\n\n\n\n\n\n\n\n\n\n\nE5.\nUse dem = rast(system.file(\"raster/dem.tif\", package = \"spDataLarge\")), and reclassify the elevation in three classes: low (&lt;300), medium and high (&gt;500). Secondly, read the NDVI raster (ndvi = rast(system.file(\"raster/ndvi.tif\", package = \"spDataLarge\"))) and compute the mean NDVI and the mean elevation for each altitudinal class.\n\ndem &lt;- rast(system.file(\"raster/dem.tif\", package = \"spDataLarge\"))\n\nggplot() +\n  geom_spatraster(data = dem) +\n  paletteer::scale_fill_paletteer_c(\"grDevices::Terrain 2\") +\n  ggtitle(\"Base raster `dem`\")\n\ndem1 &lt;- dem\n\nvalues(dem1) &lt;- values(dem) |&gt; \n  as_tibble() |&gt; \n  mutate(\n    dem_class = case_when(\n      dem &lt; 300 ~ \"Low\",\n      dem &gt; 500 ~ \"High\",\n      .default = \"Medium\"\n    )\n  ) |&gt; \n  pull(dem_class)\n\nggplot() +\n  geom_spatraster(data = dem1) +\n  scale_fill_manual(values = c(\"#F1E4E3FF\", \"#00A600FF\", \"#EAB550FF\")) +\n  ggtitle(\"The raster `dem` with elevation classified into 3 levels\")\n\n\n\n\n\n\n\n\n\n\n(a) Base raster\n\n\n\n\n\n\n\n\n\n\n\n(b) Reclassified raster\n\n\n\n\n\n\nFigure 14: Classifying elevation into high, middle and low\n\n\n\n\n\nndvi &lt;- rast(system.file(\"raster/ndvi.tif\", package = \"spDataLarge\"))\n\ntibble(\n  elevation_class = values(dem1),\n  elevation = values(dem),\n  ndvi = values(ndvi)\n) |&gt; \n  group_by(elevation_class) |&gt; \n  summarise(\n    mean_elevation = mean(elevation),\n    mean_ndvi = mean(ndvi)\n  ) |&gt; \n  gt::gt() |&gt; \n  gt::fmt_number(\n    columns = c(mean_elevation, mean_ndvi)\n  ) |&gt; \n  gt::cols_label_with(fn = snakecase::to_title_case) |&gt; \n  gt::tab_header(\n    title = \"Mean elevation and NDVI for each altitude class\"\n  ) |&gt; \n  gtExtras::gt_theme_538()\n\n\n\nTable 3: Mean elevation and NDVI for each altitude class\n\n\n\n\n\n\n\n\n\nMean elevation and NDVI for each altitude class\n\n\nElevation Class\nMean Elevation\nMean Ndvi\n\n\n\n\n1\n765.22\n−0.21\n\n\n2\n273.79\n−0.36\n\n\n3\n391.61\n−0.29\n\n\n\n\n\n\n\n\n\n\n\n\n\nE6.\nApply a line detection filter to rast(system.file(\"ex/logo.tif\", package = \"terra\")). Plot the result. Hint: Read ?terra::focal().\nThe code below demonstrates edge detection on a raster image using Sobel filters with the {terra} package in R. The Sobel filters, represented as matrices fx and fy, are defined for detecting edges in horizontal and vertical directions, respectively. The focal() function applies these filters to the raster image, performing convolution to emphasize areas of rapid intensity change (edges). The processed images are then plotted, one showing horizontal edges (filtered with fx) in black and white, and the other showing vertical edges (filtered with fy) in white and black. This illustrates how Sobel filters can be used for edge detection in spatial raster data.\nlogo &lt;- rast(system.file(\"ex/logo.tif\", package = \"terra\"))\n\nplot(logo)\n\n# Sobel filters (for edge detection):\nfx &lt;- matrix(c(-1,-2,-1,0,0,0,1,2,1), nrow = 3)\nfy &lt;- matrix(c(1,0,-1,2,0,-2,1,0,-1), nrow = 3)\n\nlogo |&gt; \n  terra::focal(w = fx) |&gt; \n  plot(col = c(\"white\", \"black\"))\n\nlogo |&gt; \n  terra::focal(w = fy) |&gt; \n  plot(col = c(\"black\", \"white\"))\n\n\n\n\n\n\n\n\n\n\n\n(a) Base raster Logo\n\n\n\n\n\n\n\n\n\n\n\n(b) Horizontal edges detected with fx\n\n\n\n\n\n\n\n\n\n\n\n(c) Vertical edges detected with fy\n\n\n\n\n\n\n\nFigure 15: Edge detection with terra::focal()\n\n\n\n\n\n\nE7.\nCalculate the Normalized Difference Water Index (NDWI; (green - nir)/(green + nir)) of a Landsat image. Use the Landsat image provided by the spDataLarge package (system.file(\"raster/landsat.tif\", package = \"spDataLarge\")). Also, calculate a correlation between NDVI and NDWI for this area (hint: you can use the layerCor() function).\nThis code processes and visualizes raster data for Zion National Park, performing computations to derive vegetation and water indices and then plotting the results. The raster, containing layers for Red, Green, Blue, and Near Infrared (NIR) bands, is rescaled to real-world values, with negative values replaced by zeros.\nUsing custom functions, the NDVI (Normalized Difference Vegetation Index) and NDWI (Normalized Difference Water Index) are calculated from the NIR, Red, and Green bands. The resulting indices are converted into a tidy SpatRaster format for plotting.\nThe code below also calculates the correlation between the NDVI and NDWI layers as -0.96, thus telling us the NDVI and NDWI are negatively correlated (inversely correlated).\n\n#################### LONG, BASE R METHOD ########################\n\n#################### I Don't Use This ###########################\n\n# Download the Zion National Park Raster File with layers of \n# Red, Green, Blue and NIR (Near Infra Red)\nlandsat &lt;- rast(\n  system.file(\"raster/landsat.tif\", package = \"spDataLarge\")\n)\n\n# Applying a scale factor to return values to actual ones.\n# The data-set was scaled to save disk space\nlandsat = (landsat * 0.0000275) - 0.2\n\n# Remove and replace negative values, since these were due to clouds\nlandsat[landsat &lt; 0] = 0\n\n# Write a custom function for computing values of \n# NDVI (normalized difference vegetation index) in R\nndvi_fun = function(nir, red){\n  (nir - red) / (nir + red)\n}\n\n# Create a new raster with NDVI values using terra::lapp()\nlandsat_ndvi &lt;- lapp(landsat[[c(4, 3)]], fun = ndvi_fun)\n\n# Write a custom function for computing values of \n# NDWI (normalized difference water index) in R\nndwi_fun = function(nir, green){\n  (green - nir) / (nir + green)\n}\n\n# Create a new raster with NDVI values using terra::lapp()\nlandsat_ndwi &lt;- lapp(landsat[[c(4, 2)]], fun = ndwi_fun)\n\ncor(\n  values(landsat_ndvi),\n  values(landsat_ndwi),\n  use = \"complete.obs\"\n)\n\n# The correlation is -0.96. NDVI and NDWI are negatively correlated.\n\n\n###################### THE TIDY APPROACH #######################\n\n# Download the Zion National Park Raster File with layers of \n# Red, Green, Blue and NIR (Near Infra Red)\nlandsat &lt;- rast(system.file(\"raster/landsat.tif\", package = \"spDataLarge\")) |&gt;\n  \n  # Applying a scale factor to return values to actual ones,\n  # The data-set was scaled to save disk space.\n  multiply_by(0.0000275) |&gt;\n  subtract(0.2) |&gt; \n  \n  # Remove and replace negative values, since these were due to clouds\n  mutate(across(everything(), ~ ifelse(. &lt; 0, 0, .)))\n\n# Write a custom function for computing values of \n# NDVI (normalized difference vegetation index) in R\nndvi_fun &lt;- function(nir, red) {\n  (nir - red) / (nir + red)\n}\n\n# Write a custom function for computing values of \n# NDWI (normalized difference water index) in R\nndwi_fun &lt;- function(nir, green) {\n  (green - nir) / (green + nir)\n}\n\n# Doing the tidy data wrangling magic with tidyverse and tidyterra\nlandsat1 &lt;- landsat |&gt; \n  as_tibble(xy = TRUE) |&gt; \n  mutate(\n    ndvi = ndvi_fun(landsat_4, landsat_3),\n    ndwi = ndwi_fun(landsat_4, landsat_2)\n  ) |&gt; \n  select(-starts_with(\"landsat\")) |&gt; \n  tidyterra::as_spatraster(\n    crs = st_crs(landsat)\n  )\n\n# Labeller for the facets\nlyr_labels &lt;- c(\n  \"normalized difference vegetation index\",\n  \"normalized difference water index\"\n) |&gt; \n  str_to_title()\nnames(lyr_labels) &lt;- c(\"ndvi\", \"ndwi\")\n\nlayerCor(landsat1, fun = cor, use = \"complete.obs\") |&gt; \n  round(digits = 2)\n\n      [,1]  [,2]\n[1,]  1.00 -0.96\n[2,] -0.96  1.00\n\n\nThe ggplot2 visualization in Figure 16 uses facets to compare NDVI and NDWI values across the area, with clear labelling and a perceptually uniform colour scale.\n\n# The actual final plot\nggplot() +\n  geom_spatraster(data = landsat1) +\n  scale_fill_grass_c(\n    na.value = \"white\"\n  ) +\n  facet_wrap(~lyr, labeller = labeller(lyr = lyr_labels)) +\n  coord_sf(expand = FALSE) +\n  labs(\n    title = \"Comparing NDVI and NDWI values\",\n    subtitle = \"Zion National Park area SpatRaster\",\n    fill = \"Value\"\n  ) +\n  theme_minimal(\n    base_family = \"caption_font\"\n  ) +\n  theme(\n    legend.position = \"bottom\",\n    text = element_text(\n      hjust = 0.5,\n      vjust = 0.5\n    )\n  )\n\n\n\n\n\n\n\nFigure 16: Comparing NDVI and NDWI values\n\n\n\n\n\n\n\n\nE8.\nA StackOverflow post (stackoverflow.com/questions/35555709) shows how to compute distances to the nearest coastline using raster::distance(). Try to do something similar but with terra::distance(): retrieve a digital elevation model of Spain, and compute a raster which represents distances to the coast across the country (hint: use geodata::elevation_30s()). Convert the resulting distances from meters to kilometers. Note: it may be wise to increase the cell size of the input raster to reduce compute time during this operation (aggregate()).\nThis code demonstrates the steps to compute and visualize the distance to the nearest coastline for Spain. First, it loads elevation data for Spain and nearby areas ( Figure 17 (a) ), as well as for Spain’s political boundaries ( Figure 17 (b) ), ensuring the inclusion of surrounding countries and water bodies. The raster is then aggregated for efficiency.\nInitial visualizations are created: one showing elevation for Spain and neighbouring areas, and another isolating only Spain.\nA binary raster is created where water is marked as TRUE (1) and land as NA. The distance() function calculates the distance of each land cell to the nearest water cell, with values converted to kilometres. ( Figure 17 (c) )\nFinally, the raw distance raster is masked to display only distances within Spain, producing a final visualization of Spain with distances to its nearest coastline ( Figure 17 (d) ). The Figure 17 includes multiple stages of the process, from raw data to the final processed map.\n\n# Full Spain and nearby Land Data\nspain_land &lt;- geodata::elevation_30s(\n  country = \"Spain\", \n  path = tempdir(),\n  \n  # Use mask = FALSE to ensure that other countries are not shown as NA\n  mask = FALSE)\n\n# Data for only Sapin Political Boundaries Land\nspain_only &lt;- geodata::elevation_30s(\n  country = \"Spain\", \n  path = tempdir()\n  )\n\nspain_working_land &lt;- spain_land |&gt; \n  aggregate(fact = 5)\n\nspain_working_only &lt;- spain_only |&gt; \n  aggregate(fact = 5)\n\nggplot() +\n  geom_spatraster(data = spain_working_land) +\n  scale_fill_terrain_c(\n    direction = -1\n  ) +\n  labs(\n    title = \"Land map of Spain and nearby areas\",\n    subtitle = \"Water / Sea is shown as transparent values (NA)\",\n    fill = \"Elevation (m)\"\n  ) \n\nggplot() +\n  geom_spatraster(data = spain_working_only) +\n  scale_fill_terrain_c(\n    direction = -1\n  ) +\n  labs(\n    title = \"Land map of only Spain\",\n    subtitle = \"Water + nearby countries are shown as transparent values (NA)\",\n    fill  = \"Elevation (m)\"\n  ) \n\n# Start with a simple raster where only water is TRUE (1) \n# and land is FALSE (0)\ntemp &lt;- is.na(spain_working_land)\n\n# Convert land (i.e. FALSE) into NA\ntemp[temp == 0] &lt;- NA\n\n# Compute distance of from nearest non-NA (i.e. Water / Sea)\ntemp &lt;- distance(temp)\n\n\n|---------|---------|---------|---------|\n=========================================\n                                          \n\n# Divide by 1000 to convert into KM\ntemp &lt;- temp / 1000\n\nggplot() +\n  geom_spatraster(data = temp) +\n  paletteer::scale_fill_paletteer_c(\n    \"grDevices::heat.colors\",\n    direction = -1,\n  ) +\n  \n  labs(\n    fill = \"Distance from\\nwater (km)\",\n    title = \"Raw Spatraster of distance from Sea / Ocean\"\n  )\n\n# Convert this raw distance vector to mask and only show Spain\ntemp_spain &lt;- temp |&gt; \n  # Mask it with only the map of Spain Raster\n  mask(spain_working_only) \n\nggplot() +\n  geom_spatraster(data = temp_spain) +\n  paletteer::scale_fill_paletteer_c(\n    \"grDevices::heat.colors\",\n    direction = -1,\n    na.value = \"transparent\"\n  ) +\n  labs(\n    fill = \"Distance\\n(km)\",\n    title = \"Spain: distances to nearest Coastline\"\n  )\n\n\n\n\n\n\n\n\n\n\n(a) Land map of Spain and nearby areas\n\n\n\n\n\n\n\n\n\n\n\n(b) Land map of only Spain\n\n\n\n\n\n\n\n\n\n\n\n(c) Raw Spatraster of distance from coastline for entire landmass\n\n\n\n\n\n\n\n\n\n\n\n(d) Final product: Spain with distances to nearest Coastline\n\n\n\n\n\n\nFigure 17: Steps in Computing the distance to nearest Coastline for Spain\n\n\n\n\n\n\n\nE9.\nTry to modify the approach used in the above exercise by weighting the distance raster with the elevation raster; every 100 altitudinal meters should increase the distance to the coast by 10 km. Next, compute and visualize the difference between the raster created using the Euclidean distance (E7) and the raster weighted by elevation.\nThe code below performs a spatial analysis and visualization of the relationship between elevation and distance to the coastline for Spain. It begins by visualizing Spain’s elevation using a raster dataset (spain_working_only). It then calculates and visualizes the Euclidean distance from each point to the nearest coastline (temp_spain), as already done in Exercise E7.\nA new raster (spain_weighted) is computed by weighting the Euclidean distance with elevation, where every 100 meters of elevation increases the effective distance to the coastline by 10 km.\nThe difference between the Euclidean distance raster and the elevation-weighted distance raster is then calculated and visualized (spain_difference).\nThe code uses the ggplot2 package to display these rasters as separate maps, with clear titles and color scales to interpret the elevation, distances, and differences.\n\nggplot() +\n  geom_spatraster(data = spain_working_only) +\n  scale_fill_wiki_c() +\n  labs(\n    fill = \"Altitude (m)\",\n    title = \"1. Elevation map of Spain\"\n  )\n\nggplot() +\n  geom_spatraster(data = temp_spain) +\n  paletteer::scale_fill_paletteer_c(\n    \"grDevices::heat.colors\",\n    direction = -1,\n    na.value = \"transparent\"\n  ) +\n  labs(\n    fill = \"Distance\\n(km)\",\n    title = \"2. Spain: euclidean distances to nearest Coastline\"\n  )\n\nspain_weighted &lt;- temp_spain + ((spain_working_only/100) * 10)\n\nggplot() +\n  geom_spatraster(data = spain_weighted) +\n  paletteer::scale_fill_paletteer_c(\n    \"grDevices::heat.colors\",\n    direction = -1,\n    na.value = \"transparent\"\n  ) +\n  labs(\n    fill = \"Distance\\n(km)\",\n    title = \"3. Spain: distance to coastline weighted by elevation\"\n  )\n\nspain_difference &lt;- spain_weighted - temp_spain\n\nggplot() +\n  geom_spatraster(data = spain_difference) +\n  paletteer::scale_fill_paletteer_c(\n    \"grDevices::heat.colors\",\n    direction = -1,\n    na.value = \"transparent\"\n  ) +\n  labs(\n    fill = \"Difference\\nin Distance\\n(km)\",\n    title = \"4. Difference between 2nd and 3rd maps\"\n  )\n\n\n\n\n\n\n\n\n\n\n(a) Elevation map of Spain\n\n\n\n\n\n\n\n\n\n\n\n(b) Spain: euclidean distances to nearest Coastline\n\n\n\n\n\n\n\n\n\n\n\n(c) Spain: distance to coastline weighted by elevation\n\n\n\n\n\n\n\n\n\n\n\n(d) Difference between 2nd and 3rd maps\n\n\n\n\n\n\nFigure 18: Algebra on Rasters"
  },
  {
    "objectID": "book_solutions/chapter2.html",
    "href": "book_solutions/chapter2.html",
    "title": "Chapter 2: Geographic data in R",
    "section": "",
    "text": "Geographic Data Models: Vector and raster models are foundational.\n\nVector Model: Represents geographic data as points, lines, and polygons with precise boundaries; commonly used in social sciences for features like human settlements.\nRaster Model: Divides surfaces into cells; useful in environmental sciences, often based on remote sensing and aerial data. Scalable and consistent over large areas.\n\nChoosing a Model:\n\nVector is often used in social sciences.\nRaster is prevalent in environmental studies.\n\nR Implementation:\n\nUse sf for vector data.\nUse terra for raster data.\n\n\n\nlibrary(sf)           # Simple Features in R\nlibrary(terra)        # Raster Data in R\nlibrary(spData)       # Spatial Datasets\nlibrary(spDataLarge)  # Large Spatial Datasets\nlibrary(tidyverse)    # Data Wrangling and Visualization"
  },
  {
    "objectID": "book_solutions/chapter2.html#introduction",
    "href": "book_solutions/chapter2.html#introduction",
    "title": "Chapter 2: Geographic data in R",
    "section": "",
    "text": "Geographic Data Models: Vector and raster models are foundational.\n\nVector Model: Represents geographic data as points, lines, and polygons with precise boundaries; commonly used in social sciences for features like human settlements.\nRaster Model: Divides surfaces into cells; useful in environmental sciences, often based on remote sensing and aerial data. Scalable and consistent over large areas.\n\nChoosing a Model:\n\nVector is often used in social sciences.\nRaster is prevalent in environmental studies.\n\nR Implementation:\n\nUse sf for vector data.\nUse terra for raster data.\n\n\n\nlibrary(sf)           # Simple Features in R\nlibrary(terra)        # Raster Data in R\nlibrary(spData)       # Spatial Datasets\nlibrary(spDataLarge)  # Large Spatial Datasets\nlibrary(tidyverse)    # Data Wrangling and Visualization"
  },
  {
    "objectID": "book_solutions/chapter2.html#vector-data",
    "href": "book_solutions/chapter2.html#vector-data",
    "title": "Chapter 2: Geographic data in R",
    "section": "2.2 Vector Data",
    "text": "2.2 Vector Data\n\nVector Data: Represents geographic features using points, lines, and polygons based on coordinate reference systems (CRS).\n\nExample: London’s coordinates c(-0.1, 51.5) in geographic CRS or c(530000, 180000) in projected CRS (British National Grid).\n\nCRS Overview:\n\nGeographic CRS uses lon/lat (0° longitude and latitude origin).\nProjected CRS, like the British National Grid, is based on Easting/Northing coordinates with positive values.\n\nKey dependencies / libraries used by the sf Package:\n\nGDAL: Handles geographic data formats\nPROJ: For CRS transformations\nGEOS: Supports planar geometry for projected data\nS2: Manages spherical geometry for unprojected data (e.g., lon/lat), toggleable with sf::sf_use_s2(FALSE).\n\nGeometry Engines:\n\nPlanar (GEOS): For 2D projected data.\nSpherical (S2): For 3D unprojected data.\n\n\n\n2.2.1 Introduction to Simple Features\n\nSimple Features (SF): Hierarchical model by OGC (Open Geospatial Consortium); supports multiple geometry types.\nCore Types: sf package in R supports 7 core geometry types (points, lines, polygons, and their “multi” versions).\nLibrary Integration: sf replaces sp, rgdal, rgeos; unified interface for GEOS (geometry), GDAL (data I/O), PROJ (CRS).\nNon-Planar Support: Integrates s2 for geographic (lon/lat) operations, used by default for accuracy on spherical geometries.\nData Storage: SF objects are data frames with a spatial column (geometry or geom).\nVignettes: Documentation accessible with vignette(package = \"sf\") for practical use and examples.\nPlotting: plot(sf_object) maps all variables, unlike single-map GIS tools.\nSummary: summary() gives spatial and attribute data insights.\nSubset: SF objects subsettable like data frames, retaining spatial metadata.\n\n\nworld\n\nSimple feature collection with 177 features and 10 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -180 ymin: -89.9 xmax: 180 ymax: 83.64513\nGeodetic CRS:  WGS 84\n# A tibble: 177 × 11\n   iso_a2 name_long continent region_un subregion type  area_km2     pop lifeExp\n * &lt;chr&gt;  &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1 FJ     Fiji      Oceania   Oceania   Melanesia Sove…   1.93e4  8.86e5    70.0\n 2 TZ     Tanzania  Africa    Africa    Eastern … Sove…   9.33e5  5.22e7    64.2\n 3 EH     Western … Africa    Africa    Northern… Inde…   9.63e4 NA         NA  \n 4 CA     Canada    North Am… Americas  Northern… Sove…   1.00e7  3.55e7    82.0\n 5 US     United S… North Am… Americas  Northern… Coun…   9.51e6  3.19e8    78.8\n 6 KZ     Kazakhst… Asia      Asia      Central … Sove…   2.73e6  1.73e7    71.6\n 7 UZ     Uzbekist… Asia      Asia      Central … Sove…   4.61e5  3.08e7    71.0\n 8 PG     Papua Ne… Oceania   Oceania   Melanesia Sove…   4.65e5  7.76e6    65.2\n 9 ID     Indonesia Asia      Asia      South-Ea… Sove…   1.82e6  2.55e8    68.9\n10 AR     Argentina South Am… Americas  South Am… Sove…   2.78e6  4.30e7    76.3\n# ℹ 167 more rows\n# ℹ 2 more variables: gdpPercap &lt;dbl&gt;, geom &lt;MULTIPOLYGON [°]&gt;\n\nnames(world)\n\n [1] \"iso_a2\"    \"name_long\" \"continent\" \"region_un\" \"subregion\" \"type\"     \n [7] \"area_km2\"  \"pop\"       \"lifeExp\"   \"gdpPercap\" \"geom\"     \n\nclass(world)\n\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n########### THE GEOMETRY COLUMN IS STICKY ################\nsummary(world[\"lifeExp\"])\n\n    lifeExp                 geom    \n Min.   :50.62   MULTIPOLYGON :177  \n 1st Qu.:64.96   epsg:4326    :  0  \n Median :72.87   +proj=long...:  0  \n Mean   :70.85                      \n 3rd Qu.:76.78                      \n Max.   :83.59                      \n NA's   :10                         \n\n\n\n\nCode\nplot(world)\n\n\n\n\n\n\n\n\nFigure 1: The basic plot() function on a sf object produced multiple plots, one for each of the non-geometry variables (columns) in the plotted dataset.\n\n\n\n\n\n\n\n2.2.2 Why Simple Features?\n\nCross-Compatibility: SF model is compatible with many GIS tools (e.g., QGIS, PostGIS), enabling easy data transfer.\nAdvantages of sf in R:\n\nData Handling: Fast reading/writing of spatial data.\nPlotting: Improved plotting speed and performance.\nData Frame-Like: sf objects behave like data frames.\nConsistent Naming: sf functions are intuitive, starting with st_.\nTidyverse-Friendly: Works well with |&gt; and integrates with tidyverse packages.\n\nData Import Options:\n\nread_sf(): Imports data as a tidy tibble (quietly).\nst_read(): Imports data as a base R data frame (verbose).\n\nPopularity: sf is the primary package for spatial vector data in R, preferred over alternatives like spatstat and terra.\n\n\nworld_dfr &lt;- st_read(system.file(\"shapes/world.shp\", package = \"spData\"))\n## Reading layer `world' from data source \n##   `C:\\Users\\dradi\\AppData\\Local\\R\\win-library\\4.3\\spData\\shapes\\world.shp' \n##   using driver `ESRI Shapefile'\n## Simple feature collection with 177 features and 10 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -180 ymin: -89.9 xmax: 180 ymax: 83.64513\n## Geodetic CRS:  WGS 84\nworld_dfr &lt;- read_sf(system.file(\"shapes/world.shp\", package = \"spData\"))\n\nclass(world_dfr)\n## [1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\n\n2.2.3 Basic Maps\n\nPlotting in sf:\n\nplot() creates multi-panel plots for multiple variables or a single-panel plot for one variable.\nSupports fixed color customization using col and border arguments.\n\n\n\n\nCode\nplot(world)\n\n\n\n\n\n\n\n\nFigure 2: The base plot() function creates a faceted output with a map for each variable other than geometry\n\n\n\n\n\n\nLayering Plots: Add layers to existing plots with add = TRUE. Use reset = FALSE for plots with a key.\nOverlaying Data: Circles representing population size can be plotted using cex and st_centroid().\nBounding Box Expansion: expandBB adjusts the plot boundaries (bottom, left, top, right).\nLimitations: Base plot() is simple but limited in functionality; use tmap for advanced maps.\n\n\n\n2.2.4 Geometry Types\n\nGeometry Basics:\n\nCore components of simple features; sf supports 18 types.\nFocus on 7 common types: POINT, LINESTRING, POLYGON, MULTIPOINT, MULTILINESTRING, MULTIPOLYGON, GEOMETRYCOLLECTION.\n\nEncoding Standards:\n\nWKB (Well-known binary): Hexadecimal, computer-friendly format.\nWKT (Well-known text): Human-readable format, often shown for explanation.\n\nCommon Geometries:\n\nPOINT: Single coordinate (e.g., POINT (5 2)).\nLINESTRING: Connected sequence of points (e.g., LINESTRING (1 5, 4 4, 4 1, 2 2, 3 2)).\nPOLYGON: Closed ring of points (e.g., POLYGON ((1 5, 2 2, 4 1, 4 4, 1 5))).\n\nMulti-Geometries:\n\nMULTIPOINT: Multiple points (e.g., MULTIPOINT (5 2, 1 3, 3 4, 3 2)).\nMULTILINESTRING: Multiple linestrings (e.g., MULTILINESTRING ((1 5, 4 4, 4 1, 2 2, 3 2), (1 2, 2 4))).\nMULTIPOLYGON: Multiple polygons (e.g., MULTIPOLYGON (((1 5, 2 2, 4 1, 4 4, 1 5), (0 2, 1 2, 1 3, 0 3, 0 2)))).\n\nGeometry Collection:\n\nMix of geometry types (e.g., GEOMETRYCOLLECTION (MULTIPOINT (5 2, 1 3, 3 4, 3 2), LINESTRING (1 5, 4 4, 4 1, 2 2, 3 2))).\n\n\n\n\n2.2.5 The sf Class\n\nStructure of sf Objects: Composed of geometries (sfc object) and non-geographic attributes (data.frame or tibble).\nCreation of sf Objects: Steps:\n\nCreate geometry (sfg) with functions like st_point()\nConvert to geometry column (sfc) with CRS using function st_sfc(..., crs = \"...\")\nCombine attributes (data.frame) with sfc using function st_sf(..., geometry = ...)\n\n\n\n\nCharacteristics:\n\nsf objects have dual class: sf and data.frame.\nSpatial attributes stored in a geometry column.\nsf behaves like a data.frame but with spatial extension.\n\n\n\n\n2.2.6 Simple Feature Geometries (sfg)\nAn sfg object represents a single simple feature geometry. A simple feature geometry column (sfc) is a collection of sfg objects and can also include information about the coordinate reference system (CRS) being used.\nGeometries can be created using st_ functions or imported from existing spatial files.\n\nsfg Creation Functions:\n\nst_point(): Create a single point.\nst_linestring(): Create a linestring.\nst_polygon(): Create a polygon.\nst_multipoint(): Create a multipoint.\nst_multilinestring(): Create a multilinestring.\nst_multipolygon(): Create a multipolygon.\nst_geometrycollection(): Create a geometry collection.\n\nInput Data Types:\n\nNumeric Vector: Single points.\nMatrix: Sets of points for multipoint or linestring.\nList: Complex structures for multilinestrings, (multi)polygons, or geometry collections.\n\nExamples:\n\n\nCode\n\n# Create a point\npoint &lt;- st_point(c(8, 3))  # POINT (8 3)\nprint(point)\nggplot(point) +\n  geom_sf()\n\n# Create a multipoint\nmultipoint_matrix &lt;- rbind(c(8, 3), c(2, 5), c(5, 7), c(7, 3))\nmultipoint &lt;- st_multipoint(multipoint_matrix)  # MULTIPOINT ((8 3), (2 5), (5 7), (7 3))\nprint(multipoint)\nggplot(multipoint) +\n  geom_sf()\n\n# Create a linestring\nlinestring_matrix &lt;- rbind(c(2, 8), c(6, 6), c(7, 2), c(5, 3), c(8, 4))\nlinestring &lt;- st_linestring(linestring_matrix)  # LINESTRING (2 8, 6 6, 7 2, 5 3, 8 4)\nprint(linestring)\nggplot(linestring) +\n  geom_sf()\n\n# Create a polygon\npolygon_list &lt;- list(rbind(c(2, 8), c(4, 3), c(7, 2), c(6, 7), c(2, 8)))\npolygon &lt;- st_polygon(polygon_list)  # POLYGON ((2 8, 4 3, 7 2, 6 7, 2 8))\nprint(polygon)\nggplot(polygon) +\n  geom_sf()\n\n# Polygon with a hole\npolygon_border &lt;- rbind(c(2, 8), c(4, 3), c(7, 2), c(6, 7), c(2, 8))\npolygon_hole &lt;- rbind(c(4, 6), c(5, 6), c(5, 5), c(4, 5), c(4, 6))\npolygon_with_hole_list &lt;- list(polygon_border, polygon_hole)\npolygon_with_hole &lt;- st_polygon(polygon_with_hole_list)  # POLYGON with a hole\nprint(polygon_with_hole)\nggplot(polygon_with_hole) +\n  geom_sf()\n\n# Create a multilinestring\nmultilinestring_list = list(\n  rbind(c(2, 8), c(6, 6), c(7, 2), c(5, 3), c(8, 4)),\n  rbind(c(3, 2), c(5, 8))\n)\nmultilinestring = st_multilinestring(multilinestring_list)  # MULTILINESTRING\nprint(multilinestring)\nggplot(multilinestring) +\n  geom_sf()\n\n# Create a multipolygon\nmultipolygon_list = list(\n  list(rbind(c(2, 8), c(4, 3), c(7, 2), c(6, 7), c(2, 8))),\n  list(rbind(c(0, 3), c(2, 3), c(2, 4), c(0, 4), c(0, 3)))\n)\nmultipolygon = st_multipolygon(multipolygon_list)  # MULTIPOLYGON\nprint(multipolygon)\nggplot(multipolygon) +\n  geom_sf()\n\n# Create a geometry collection\ngeometrycollection_list = list(st_multipoint(multipoint_matrix), st_linestring(linestring_matrix))\ngeometry_collection = st_geometrycollection(geometrycollection_list)  # GEOMETRYCOLLECTION\nprint(geometry_collection)\nggplot(geometry_collection) +\n  geom_sf()\n\n\n\n\n\n\n\n\n\n\n\n\n(a) A point\n\n\n\n\n\n\n\n\n\n\n\n(b) A multipoint\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) A linestring\n\n\n\n\n\n\n\n\n\n\n\n(d) A polygon\n\n\n\n\n\n\n\n\n\n\n\n\n\n(e) Polygon with a hole\n\n\n\n\n\n\n\n\n\n\n\n(f) Multilinestring\n\n\n\n\n\n\n\n\n\n\n\n\n\n(g) Multipolygon\n\n\n\n\n\n\n\n\n\n\n\n(h) Geometry Collection\n\n\n\n\n\n\n\nFigure 3: Creating different sample geometry objects in R with {sf}\n\n\n\n\n\n2.2.8 The sfheaders Package\n\nOverview:\n\nsfheaders (Cooley 2024) is an R package designed to efficiently create and manipulate sf objects from vectors, matrices, and data frames.\nIt does not rely on the sf library and instead uses underlying C++ code, enabling faster operations and the potential for further development with compiled code.\n\nCompatibility:\n\nAlthough separate from sf, it is fully compatible, producing valid sf objects like sfg, sfc, and sf.\n\nKey Functionality:\n\nConverts:\n\nVector → sfg_POINT\nMatrix → sfg_LINESTRING\nData Frame → sfg_POLYGON\n\nCreates sfc and sf objects using similar syntax.\n\nAdvantages:\n\nsfheaders is optimized for high-speed ‘deconstruction’ and ‘reconstruction’ of sf objects and casting between geometry types, offering faster performance than sf in many cases.\n\n\n\n\n2.2.9 Spherical Geometry Operations with S2\n\nConcept:\n\nSpherical geometry operations acknowledge Earth’s roundness, as opposed to planar operations that assume flat surfaces.\nSince sf version 1.0.0, R integrates with Google’s S2 spherical geometry engine, enabling accurate global spatial operations.\nS2 supports operations like distance, buffer, and area calculations, allowing accurate geocomputation on a spherical Earth model.\nKnown as a Discrete Global Grid System (DGGS), S2 is similar to other systems like H3, which is a global hexagonal index.\n\nS2 Mode:\n\nBy default, S2 is enabled in sf. Verify with:\nsf_use_s2()\nTurning Off S2:\nsf_use_s2(FALSE)\n\nS2 Limitations and Edge Cases:\n\nSome operations may fail due to S2’s stricter definitions, potentially affecting legacy code. Error messages such as Error in s2_geography_from_wkb ... might require turning off S2.\n\nRecommendation:\n\nKeep S2 enabled for accurate global calculations unless specific operations necessitate its deactivation."
  },
  {
    "objectID": "book_solutions/chapter2.html#raster-data",
    "href": "book_solutions/chapter2.html#raster-data",
    "title": "Chapter 2: Geographic data in R",
    "section": "2.3 Raster Data",
    "text": "2.3 Raster Data\n\nThe raster data model represents the world as a continuous grid of cells (pixels). Focuses on regular grids, where each cell is of constant size, though other grid types (e.g., rotated, sheared) exist.\nStructure:\n\nComprises a raster header and a matrix of equally spaced cells.\nThe raster header includes:\n\nCRS (Coordinate Reference System)\nExtent (geographical area covered)\nOrigin (starting point, often the lower left corner; the terra package defaults to the upper left).\n\nExtent is defined by:\n\nNumber of columns (ncol)\nNumber of rows (nrow)\nCell size resolution\n\n\nCell Access and Modification:\n\nCells can be accessed and modified by:\n\nCell ID\nExplicitly specifying row and column indices.\n\nThis matrix representation is efficient as it avoids storing corner coordinates (unlike vector polygons).\n\nData Characteristics:\n\nEach cell can hold a single value, which can be either:\n\nContinuous (e.g., elevation, temperature)\nCategorical (e.g., land cover classes).\n\n\nApplications:\n\nRaster maps are useful for continuous phenomena (e.g., temperature, population density) and can also represent discrete features (e.g., soil classes).\n\n\n\n2.3.1 R Packages for Working with Raster Data\n\nSeveral R packages for reading and processing raster datasets have emerged over the last two decades. The raster package was the first significant advancement in R’s raster capabilities when launched in 2010. It was the premier package until the development of terra and stars, both offering powerful functions for raster data.\nThis book emphasizes terra, which replaces the older, slower raster package.\nComparison of terra and stars:\n\n\n\n\n\n\n\n\n\nFeature\nterra\nstars\n\n\n\n\nPrimary Focus\nRegular grids\nSupports regular, rotated, sheared, rectilinear, and curvilinear grids\n\n\nData Structure\nOne or multi-layered rasters\nRaster data cubes with multiple layers, time steps, and attributes\n\n\nMemory Management\nUses C++ code and pointers for data storage\nUses lists of arrays for smaller rasters; file paths for larger ones\n\n\nVector Data Integration\nUses its own class SpatVector but supports sf objects\nClosely related to vector objects/functions in sf\n\n\nFunctions & Methods\nLarge number of built-in, purpose-specific functions (e.g., re-sampling, cropping)\nMix of built-in functions (st_ prefix), existing dplyr functions, and custom methods for R functions\n\n\nConversion Between Packages\nConversion to stars with st_as_stars()\nConversion to terra with rast()\n\n\nPerformance\nGenerally optimized for speed and memory efficiency\nFlexible, but performance varies based on data type and structure\n\n\nBest Use Cases\nSingle or multi-layer rasters; fast processing\nComplex data cubes with layers over time and multiple attributes\n\n\nProgramming Language Basis\nPrimarily C++\nR with some C++ integration\n\n\n\n\n\n2.3.2 Introduction to terra\n\nThe terra package is designed for handling raster objects in R, supporting a range of functions to create, read, export, manipulate, and process raster datasets.\n\nWhile its functionality is similar to the older raster package, terra offers improved computational efficiency.\nDespite terra’s advantages, the raster class system remains popular due to its widespread use in other R packages.\nterra provides seamless translation between the two object types using functions like raster(), stack(), and brick() for backward compatibility.\n\nKey Features:\n\nLow-Level Functionality: Includes functions that help in building new tools for raster data processing.\nMemory Management: Supports processing of large raster datasets by dividing them into smaller chunks for iterative processing, allowing operations beyond available RAM capacity.\n\n\n\n\nCode\nraster_filepath &lt;- system.file(\"raster/srtm.tif\", \n                              package = \"spDataLarge\")\nmy_rast &lt;- rast(raster_filepath)\n\nclass(my_rast)\n## [1] \"SpatRaster\"\n## attr(,\"package\")\n## [1] \"terra\"\n\next(my_rast)\n## SpatExtent : -113.239583212784, -112.85208321281, 37.1320834298579, 37.5129167631658 (xmin, xmax, ymin, ymax)\n\nprint(my_rast)\n## class       : SpatRaster \n## dimensions  : 457, 465, 1  (nrow, ncol, nlyr)\n## resolution  : 0.0008333333, 0.0008333333  (x, y)\n## extent      : -113.2396, -112.8521, 37.13208, 37.51292  (xmin, xmax, ymin, ymax)\n## coord. ref. : lon/lat WGS 84 (EPSG:4326) \n## source      : srtm.tif \n## name        : srtm \n## min value   : 1024 \n## max value   : 2892\n\n\n\nDedicated Reporting Functions:\n\ndim(): Number of rows, columns, and layers.\nncell(): Total number of cells (pixels).\nres(): Spatial resolution.\next(): Spatial extent.\ncrs(): Coordinate reference system (CRS).\ninMemory(): Checks if data is stored in memory or on disk.\nsources: Shows file location.\n\nAccessing Full Function List:\n\nRun help(\"terra-package\") to see all available terra functions.\n\n\n\n\n2.3.3 Basic Map-Making\n\nPlotting with terra:\n\nThe terra package offers a simple way to create basic visualizations using the plot() function, specifically designed for SpatRaster objects.\n\n\n\n\nCode\nplot(my_rast)\n\n\n\n\n\n\n\n\nFigure 4: An example raster data displayed with {terra} using plot()\n\n\n\n\n\n\nAdvanced Plotting Options:\n\nplotRGB(): A specialized function in terra for creating color composite plots using three layers (e.g., red, green, blue bands) from a SpatRaster object.\ntmap Package (Tennekes 2018): Useful for creating both static and interactive maps for raster and vector data.\nrasterVis Package (2023): Includes functions such as levelplot() to create advanced visualizations, including faceted plots for displaying changes over time.\n\n\n\n\n2.3.4 Raster Classes\n\nThe SpatRaster class in terra represents raster objects. Rasters are commonly created by reading a file using rast()\n\nterra supports reading various formats via GDAL, only loading the header and a file pointer into RAM.\n\nCreating Rasters from Scratch: Use rast() to make new raster objects:\n\nFills values row-wise from the top left corner.\nResolution depends on rows, columns, and extent; defaults to degrees (WGS84 CRS).\n\n\n\n\nCode\n# Create a new SpatRaster object: a checkerboard design\nnew_raster = rast(nrows = 50, ncols = 50, \n                  xmin = 0, xmax = 50, \n                  ymin = 0, ymax = 50,\n                  vals = rep(c(1, 0.25, 0.75, 0.5), \n                             times = 12)) \n\n\n# Plot the new raster\nplot(new_raster, \n     col = c(\"darkblue\", \n             \"white\",\n             \"blue\",\n             \"lightblue\"), # Use blue and white for the design\n     axes = TRUE, \n     box = FALSE)\n\n\n\n\n\n\n\n\nFigure 5: Creating a new raster from scratch\n\n\n\n\n\n\nHandling Multi-Layer Rasters:\n\nSpatRaster supports multi-layer rasters, such as satellite or time-series data:\n\nUse nlyr() to get the number of layers:\nAccess layers with [[ or $.\nUse subset() for layer extraction:\n\n\nCombining Raster Layers:\n\nMerge SpatRaster layers using c():\n\nSaving SpatRaster Objects:\n\nSince they often point to files, direct saving to .rds or .rda isn’t feasible.\nSolutions:\n\nwrap(): Creates a temporary object for saving or cluster use.\nwriteRaster(): Saves as a regular raster file."
  },
  {
    "objectID": "book_solutions/chapter2.html#coordinate-reference-systems",
    "href": "book_solutions/chapter2.html#coordinate-reference-systems",
    "title": "Chapter 2: Geographic data in R",
    "section": "2.4 Coordinate Reference Systems",
    "text": "2.4 Coordinate Reference Systems\n\nCRSs (Coordinate Reference Systems) are essential for spatial data, defining how spatial elements correspond to the Earth’s surface (or other celestial bodies).\nTypes of CRSs:\n\nGeographic CRSs:\n\nRepresent data on a three-dimensional surface (e.g., latitude and longitude).\nCoordinate units are typically degrees.\n\nProjected CRSs:\n\nRepresent data on a two-dimensional, flat plane.\nTransform spherical Earth data into a flat map.\nCoordinate units can be in meters, feet, etc.\n\n\n\n\n2.4.1 Geographic Coordinate Reference Systems\n\nGeographic CRSs use longitude and latitude to identify locations on Earth.\n\nLongitude: Measures East-West position relative to the Prime Meridian.\nLatitude: Measures North-South position relative to the equatorial plane.\nDistances are measured in angular units (degrees), not meters, impacting spatial measurements (explored further in Section 7).\n\nThe Earth can be modeled as spherical or ellipsoidal.\n\nSpherical models: Simplify calculations by assuming Earth is a perfect sphere.\nEllipsoidal models: More accurately represent Earth with distinct equatorial and polar radii. The equatorial radius is about 11.5 km longer than the polar radius due to Earth’s compression.\n\nDatum refers to the model describing the relationship between coordinate values and actual locations on Earth. A datum consists of:\n\nEllipsoid: An idealized mathematical model of the Earth’s shape, which helps to approximate the Earth’s surface.\nOrigin Point: A fixed starting point for the coordinate system, where the ellipsoid is anchored to Earth.\nOffset and Orientation: How the ellipsoid is aligned with respect to the actual shape of the Earth.\n\n\n\n\nThe two types of Datums are: —\n\nGeocentric datum (e.g., WGS84): Centered at Earth’s center of gravity, providing global consistency but less local accuracy.\nLocal datum (e.g., NAD83): Adjusted for specific regions to better align with the Earth’s surface, accounting for local geographic variations (e.g., mountain ranges).\n\n\n\n\n2.4.2 Projected Coordinate Reference Systems\n\nProjected CRSs are based on geographic CRSs and use map projections to represent Earth’s three-dimensional surface in Easting and Northing (x and y) values. These CRSs rely on Cartesian coordinates on a flat surface, with an origin and linear units (e.g., meters).\nDeformations:\n\nThe conversion from 3D to 2D inherently introduces distortions. Projected CRSs can only preserve one or two of the following properties:\n\nArea: Preserved in equal-area projections.\nDirection: Preserved in azimuthal projections.\nDistance: Preserved in equidistant projections.\nShape: Preserved in conformal projections.\n\n\n\n\n\nTypes of Projections and Their Characteristics\n\n\n\n\n\n\n\n\n\nType of Projection\nDescription\nCommon Properties Preserved\nBest Used For\n\n\n\n\nConic\nProjects Earth’s surface onto a cone.\nArea, shape\nMaps of mid-latitude regions\n\n\nCylindrical\nProjects Earth’s surface onto a cylinder.\nDirection, shape\nWorld maps\n\n\nPlanar (Azimuthal)\nProjects onto a flat surface at a point or line.\nDistance, direction\nPolar region maps\n\n\n\n\n\nDeformations by Projection Type\n\n\n\n\n\n\n\n\nProperty\nDefinition\nProjection Type That Preserves It\n\n\n\n\nArea\nThe relative size of regions is maintained.\nEqual-area projections (e.g., Albers)\n\n\nDirection\nBearings from the center are accurate.\nAzimuthal projections (e.g., Lambert)\n\n\nDistance\nCorrect distances are preserved along specific lines or from specific points.\nEquidistant projections (e.g., Equirectangular)\n\n\nShape\nLocal angles and shapes are maintained, though areas are distorted.\nConformal projections (e.g., Mercator)\n\n\n\n\nUse the Map Projection Explorer for details.\nUse st_crs() for querying CRSs in sf objects and crs() for terra objects.\n\n\n\nCode\nsf_proj_info(type = \"proj\") |&gt; \n  as_tibble() |&gt; \n  gt::gt() |&gt; \n  gt::cols_label_with(fn = snakecase::to_title_case) |&gt; \n  gtExtras::gt_theme_espn() |&gt; \n  gt::opt_interactive()\n\n\n\n\nTable 1: A list of the available projections supported by the PROJ library"
  },
  {
    "objectID": "book_solutions/chapter2.html#units",
    "href": "book_solutions/chapter2.html#units",
    "title": "Chapter 2: Geographic data in R",
    "section": "2.5 Units",
    "text": "2.5 Units\n\nCRSs include spatial units information, which is crucial for accurately interpreting distance and area.\nCartographic best practices suggest adding scale indicators on maps to show the relationship between map and ground distances.\nUnits in sf Objects:\n\nsf objects natively support units for geometric data, ensuring outputs from functions like st_area() come with a units attribute.\nThis feature, supported by the units package, avoids confusion across different CRSs, which may use meters, feet, etc.\nTo convert units, use units::set_units()\n\nUnits in Raster Data:\n\nUnlike sf, raster packages do not natively support units.\nUsers should be cautious when working with raster data to convert units properly.\nAn example to calculate the area of India in square meters and then, square kilometres\n\n\n\n# Load required libraries\nlibrary(sf)\nlibrary(units)\n\n# Calculate the area of India in square meters\nindia_area &lt;- rnaturalearth::ne_countries() |&gt; \n  filter(admin == \"India\") |&gt; \n  st_area()\nindia_area\n\n3.150428e+12 [m^2]\n\n# Convert area to square kilometers\nprint(paste(\"Area of India in square kilometers:\", format(set_units(india_area, km^2))))\n\n[1] \"Area of India in square kilometers: 3150428 [km^2]\"\n\n# Convert area to hectares\nprint(paste(\"Area of India in hectares:\", format(set_units(india_area, ha))))\n\n[1] \"Area of India in hectares: 315042827 [ha]\"\n\n# Convert area to acres\nprint(paste(\"Area of India in acres:\", format(set_units(india_area, acre))))\n\n[1] \"Area of India in acres: 778484666 [acre]\""
  },
  {
    "objectID": "book_solutions/chapter2.html#exercises",
    "href": "book_solutions/chapter2.html#exercises",
    "title": "Chapter 2: Geographic data in R",
    "section": "2.6 Exercises",
    "text": "2.6 Exercises\n\n\nE1\nUsing summary() on the geometry column of the world data object in the spData package provides valuable information about the spatial characteristics of the dataset:\n\nGeometry Type:\n\nThe output will indicate the type of geometries present in the world data object. Here, it is MULTIPOLYGON suggesting that the dataset represents the outlines of countries or regions in MULTIPLOYGON formats.\n\nNumber of Countries:\n\nThe summary will show the number of geometries or features present, which corresponds to the number of countries or regions represented in the world dataset. Here, it is 177 countries.\n\nCoordinate Reference System (CRS):\n\nThe output will include details about the CRS, and in the present case it is EPSG:4326.\n\n\n\nsummary((spData::world$geom))\n\n MULTIPOLYGON     epsg:4326 +proj=long... \n          177             0             0 \n\n\n\n\n\nE2\nTo generate the world map, you can run the following code (as shown in Section 2.2.3):\n\nCode\nlibrary(spData)\nplot(world[3:6])\nplot(world[\"pop\"])\n\n\n\n\n\n\n\n\n\n\nFigure 6: Reproducing Figure 2.4 of the book\n\n\n\n\n\n\n\n\n\n\n\nFigure 7: Reproducing Figure 2.4 of the book\n\n\n\n\n\n\n\nSimilarities:\n\nThe map displays country boundaries and highlights the global population distribution as shown in the book.\nThe color scale representing population data is consistent with that described in the book, with larger populations shown with more intense colors.\n\nDifferences:\n\nThe aspect ratio or positioning of the map might vary depending on your screen resolution and window size.\nThe color theme and legend display may differ if your R setup or graphic device uses default settings different from those in the book.\n\ncex Argument: This parameter controls the size of plotting symbols in R. It is a numeric value that acts as a multiplier for the default size of symbols.\n\nSetting cex to values larger than 1 enlarges symbols, while values less than 1 shrink them.\n\nReason for cex = sqrt(world$pop) / 10000 : The code sets cex to sqrt(world$pop) / 10000 to scale the size of the points on the map in proportion to the population of each country. This square root transformation is used to moderate the variation in symbol sizes because population values can vary significantly between countries. Dividing by 10,000 helps to reduce the symbol size to a reasonable range for plotting.\n\nOther Ideas: —\n\nBubble Plot: Overlay a bubble plot on the map with points sized by population.\n\n\n\nCode\nplot(world[\"pop\"])\npoints(st_coordinates(st_centroid(world$geom)), \n       cex = sqrt(world$pop) / 5000, \n       col = \"red\", pch = 19)\n\n\n\n\n\n\n\n\n\n\nChoropleth Map: Use color gradients to represent population density.\n\n\n\nCode\nlibrary(tmap)\ntm_shape(world) +\n  tm_polygons(\"pop\", style = \"jenks\", \n              palette = \"Blues\", \n              title = \"Population\")\n\n\n\n\n\n\n\n\n\n\nLog Transformation: Visualize population using a log scale for better differentiation.\n\n\n\nCode\nworld$log_pop = log10(world$pop + 1)\nplot(world[\"log_pop\"])\n\n\n\n\n\n\n\n\n\n\n\n\nE3\nTo create a map of Nigeria in context and customize it using the plot() function, you can follow these steps:\nStep 1: Load Necessary Libraries and Data: Make sure you have the spData package loaded and access to the world spatial data.\nStep 2: Plotting Nigeria in Context: You can plot Nigeria by subsetting the world data and adjusting parameters such as lwd (line width), col (color), and expandBB (expanding the bounding box). Here’s an example code snippet:\nStep 3: Annotating the Map: To annotate the map with text labels, you can use the text() function. Here’s an example where we add the name of Nigeria and its capital, Abuja:\nStep 4: Exploring the text() Documentation\n\nlwd: This argument controls the line width for the borders of the countries.\ncol: This argument sets the fill color for the countries. You can customize it based on your preference.\nexpandBB: This argument expands the bounding box of the plot, which can help visualize nearby areas more clearly.\n\n\n\n\nE4\nTo create an empty SpatRaster object with 10 columns and 10 rows, assign random values between 0 and 10, and then plot it, you can use the terra package in R. Here’s how you can do it:\n\n\nCode\nlibrary(terra)\n\n# Create an empty SpatRaster object with 10 columns and 10 rows\nmy_raster &lt;- rast(nrows = 10, ncols = 10)\n\n# Assign random values between 0 and 10\nvalues(my_raster) &lt;- runif(ncell(my_raster), min = 0, max = 10)\n\n# Plot the raster\nplot(my_raster, main = \"Random Values Raster\")\n\n\n\n\n\n\n\n\n\n\n\n\nE5\nTo read in the raster/nlcd.tif file from the spDataLarge package and examine its properties, you can follow these steps in R:\n\nlibrary(spDataLarge)\nlibrary(terra)\n\n# Read the raster file\nnlcd_raster &lt;- rast(system.file(\"raster/nlcd.tif\", package = \"spDataLarge\"))\n\nInformation You Can Obtain: —\n\nBasic Properties: The print(nlcd_raster) command will provide you with information about the raster, including its dimensions, number of layers, and type of data.\n\n# Check the basic properties of the raster\nprint(nlcd_raster)\n\nclass       : SpatRaster \ndimensions  : 1359, 1073, 1  (nrow, ncol, nlyr)\nresolution  : 31.5303, 31.52466  (x, y)\nextent      : 301903.3, 335735.4, 4111244, 4154086  (xmin, xmax, ymin, ymax)\ncoord. ref. : NAD83 / UTM zone 12N (EPSG:26912) \nsource      : nlcd.tif \ncolor table : 1 \ncategories  : levels \nname        :   levels \nmin value   :    Water \nmax value   : Wetlands \n\n\nSummary Statistics: The summary(nlcd_raster) function will give you basic statistics about the raster values, such as minimum, maximum, and mean values. In this case, it tells the number of cells with Forest, Shrubland, Barren, Developed, Cultivated, Wetlands and Other land-use types.\n\n# Get summary statistics\nsummary(nlcd_raster)\n\n        levels     \n Forest    :52620  \n Shrubland :37463  \n Barren    : 7290  \n Developed : 1203  \n Cultivated:  596  \n Wetlands  :  443  \n (Other)   :  421  \n\n\nExtent: The ext(nlcd_raster) command will provide the geographical extent of the raster, showing the minimum and maximum x and y coordinates.\n\n# Check the extent of the raster\next(nlcd_raster)\n\nSpatExtent : 301903.344386758, 335735.354381954, 4111244.46098842, 4154086.47216415 (xmin, xmax, ymin, ymax)\n\n\nRows and Columns: You can find the number of rows and columns in the raster using nrow(nlcd_raster) and ncol(nlcd_raster).\n\n# Get the number of rows and columns\nnrow(nlcd_raster)\n\n[1] 1359\n\nncol(nlcd_raster)\n\n[1] 1073\n\n\nCoordinate Reference System (CRS): The crs(nlcd_raster) command will return the CRS of the raster, which is essential for spatial analyses.\n\n# Get the coordinate reference system (CRS)\nstr_view(crs(nlcd_raster))\n\n[1] │ PROJCRS[\"NAD83 / UTM zone 12N\",\n    │     BASEGEOGCRS[\"NAD83\",\n    │         DATUM[\"North American Datum 1983\",\n    │             ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n    │                 LENGTHUNIT[\"metre\",1]]],\n    │         PRIMEM[\"Greenwich\",0,\n    │             ANGLEUNIT[\"degree\",0.0174532925199433]],\n    │         ID[\"EPSG\",4269]],\n    │     CONVERSION[\"UTM zone 12N\",\n    │         METHOD[\"Transverse Mercator\",\n    │             ID[\"EPSG\",9807]],\n    │         PARAMETER[\"Latitude of natural origin\",0,\n    │             ANGLEUNIT[\"degree\",0.0174532925199433],\n    │             ID[\"EPSG\",8801]],\n    │         PARAMETER[\"Longitude of natural origin\",-111,\n    │             ANGLEUNIT[\"degree\",0.0174532925199433],\n    │             ID[\"EPSG\",8802]],\n    │         PARAMETER[\"Scale factor at natural origin\",0.9996,\n    │             SCALEUNIT[\"unity\",1],\n    │             ID[\"EPSG\",8805]],\n    │         PARAMETER[\"False easting\",500000,\n    │             LENGTHUNIT[\"metre\",1],\n    │             ID[\"EPSG\",8806]],\n    │         PARAMETER[\"False northing\",0,\n    │             LENGTHUNIT[\"metre\",1],\n    │             ID[\"EPSG\",8807]]],\n    │     CS[Cartesian,2],\n    │         AXIS[\"(E)\",east,\n    │             ORDER[1],\n    │             LENGTHUNIT[\"metre\",1]],\n    │         AXIS[\"(N)\",north,\n    │             ORDER[2],\n    │             LENGTHUNIT[\"metre\",1]],\n    │     USAGE[\n    │         SCOPE[\"Engineering survey, topographic mapping.\"],\n    │         AREA[\"North America - between 114°W and 108°W - onshore and offshore. Canada - Alberta; Northwest Territories; Nunavut; Saskatchewan. United States (USA) - Arizona; Colorado; Idaho; Montana; New Mexico; Utah; Wyoming.\"],\n    │         BBOX[31.33,-114,84,-108]],\n    │     ID[\"EPSG\",26912]]\n\n\nResolution: You can check the resolution of the raster with the res(nlcd_raster) function, which will indicate the size of each pixel.\n\n# Check the resolution of the raster\nres(nlcd_raster)\n\n[1] 31.53030 31.52466\n\n\nValues: The values(nlcd_raster) command allows you to access the actual values contained in the raster. Here, I am printing only the first few values.\n\n# Get the values of the raster\nvalues(nlcd_raster) |&gt; head()\n\n     levels\n[1,]      4\n[2,]      4\n[3,]      5\n[4,]      4\n[5,]      4\n[6,]      4\n\n\n\n\n\n\nE6\nTo check the Coordinate Reference System (CRS) of the raster/nlcd.tif file from the spDataLarge package, you can use the following steps in R. The CRS provides essential information about how the spatial data is projected on the Earth’s surface.\n\nlibrary(spDataLarge)\nlibrary(terra)\n\n# Read the raster file\nnlcd_raster &lt;- rast(system.file(\"raster/nlcd.tif\", package = \"spDataLarge\"))\n\n# Check the coordinate reference system (CRS)\nnlcd_crs &lt;- crs(nlcd_raster)\nnlcd_crs |&gt; str_view()\n\n[1] │ PROJCRS[\"NAD83 / UTM zone 12N\",\n    │     BASEGEOGCRS[\"NAD83\",\n    │         DATUM[\"North American Datum 1983\",\n    │             ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n    │                 LENGTHUNIT[\"metre\",1]]],\n    │         PRIMEM[\"Greenwich\",0,\n    │             ANGLEUNIT[\"degree\",0.0174532925199433]],\n    │         ID[\"EPSG\",4269]],\n    │     CONVERSION[\"UTM zone 12N\",\n    │         METHOD[\"Transverse Mercator\",\n    │             ID[\"EPSG\",9807]],\n    │         PARAMETER[\"Latitude of natural origin\",0,\n    │             ANGLEUNIT[\"degree\",0.0174532925199433],\n    │             ID[\"EPSG\",8801]],\n    │         PARAMETER[\"Longitude of natural origin\",-111,\n    │             ANGLEUNIT[\"degree\",0.0174532925199433],\n    │             ID[\"EPSG\",8802]],\n    │         PARAMETER[\"Scale factor at natural origin\",0.9996,\n    │             SCALEUNIT[\"unity\",1],\n    │             ID[\"EPSG\",8805]],\n    │         PARAMETER[\"False easting\",500000,\n    │             LENGTHUNIT[\"metre\",1],\n    │             ID[\"EPSG\",8806]],\n    │         PARAMETER[\"False northing\",0,\n    │             LENGTHUNIT[\"metre\",1],\n    │             ID[\"EPSG\",8807]]],\n    │     CS[Cartesian,2],\n    │         AXIS[\"(E)\",east,\n    │             ORDER[1],\n    │             LENGTHUNIT[\"metre\",1]],\n    │         AXIS[\"(N)\",north,\n    │             ORDER[2],\n    │             LENGTHUNIT[\"metre\",1]],\n    │     USAGE[\n    │         SCOPE[\"Engineering survey, topographic mapping.\"],\n    │         AREA[\"North America - between 114°W and 108°W - onshore and offshore. Canada - Alberta; Northwest Territories; Nunavut; Saskatchewan. United States (USA) - Arizona; Colorado; Idaho; Montana; New Mexico; Utah; Wyoming.\"],\n    │         BBOX[31.33,-114,84,-108]],\n    │     ID[\"EPSG\",26912]]\n\n\nUnderstanding the CRS Information: —\nThe output from the crs(nlcd_raster) command will typically include details such as:\n\nProjection Type: Indicates whether the CRS is geographic (latitude and longitude) or projected (a flat representation). Here, it is North American NAD83 / UTM Zone 12 N\nDatum: Information about the geodetic datum used, which is crucial for accurately locating points on the Earth’s surface. Here, it is North American Datum 1983.\nCoordinate Units: Specifies the units of measurement used for the coordinates, such as degrees (for geographic CRSs) or meters (for projected CRSs). Here, it is in metres, as shown in:\nLENGTHUNIT[\"metre\",1]\nEPSG Code: If applicable, the output might include an EPSG code, which is a standardized reference number for a specific CRS. This code can be used to look up more detailed information about the CRS. Here, it is: —\nID[\"EPSG\",26912]\nTransformation Parameters: If it’s a projected CRS, the output may include parameters related to the projection method, such as central meridian, standard parallels, and false easting/northing. Here, they are: —\n|         PRIMEM[\"Greenwich\",0,     \n│             ANGLEUNIT[\"degree\",0.0174532925199433]],     \n│         ID[\"EPSG\",4269]], \n|\n|\n│     CONVERSION[\"UTM zone 12N\",     \n│         METHOD[\"Transverse Mercator\",     \n│             ID[\"EPSG\",9807]],     \n│         PARAMETER[\"Latitude of natural origin\",0,     \n│             ANGLEUNIT[\"degree\",0.0174532925199433],     \n│             ID[\"EPSG\",8801]],     \n│         PARAMETER[\"Longitude of natural origin\",-111,     \n|             ANGLEUNIT[\"degree\",0.0174532925199433],     \n│             ID[\"EPSG\",8802]],     \n│         PARAMETER[\"Scale factor at natural origin\",0.9996,\n│             SCALEUNIT[\"unity\",1],     \n│             ID[\"EPSG\",8805]],     \n│         PARAMETER[\"False easting\",500000,     \n│             LENGTHUNIT[\"metre\",1],     \n│             ID[\"EPSG\",8806]],     \n│         PARAMETER[\"False northing\",0,     \n│             LENGTHUNIT[\"metre\",1],     \n│             ID[\"EPSG\",8807]]],"
  },
  {
    "objectID": "book_solutions.html",
    "href": "book_solutions.html",
    "title": "Book Solutions",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nSubtitle\n\n\n\n\n\n\nDec 16, 2024\n\n\nChapter 5: Geometry operations\n\n\nKey Learnings from, and Solutions to the exercises in Chapter 4 of the book Geocomputation with R by Robin Lovelace, Jakub Nowosad and Jannes Muenchow.\n\n\n\n\nNov 16, 2024\n\n\nChapter 4: Spatial data operations\n\n\nKey Learnings from, and Solutions to the exercises in Chapter 4 of the book Geocomputation with R by Robin Lovelace, Jakub Nowosad and Jannes Muenchow.\n\n\n\n\nNov 8, 2024\n\n\nChapter 3: Attribute data operations\n\n\nKey Learnings from, and Solutions to the exercises in Chapter 3 of the book Geocomputation with R by Robin Lovelace, Jakub Nowosad and Jannes Muenchow.\n\n\n\n\nNov 3, 2024\n\n\nChapter 2: Geographic data in R\n\n\nKey Learnings from, and Solutions to the exercises in Chapter 2 of the book Geocomputation with R by Robin Lovelace, Jakub Nowosad and Jannes Muenchow.\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "book_solutions/chapter3.html",
    "href": "book_solutions/chapter3.html",
    "title": "Chapter 3: Attribute data operations",
    "section": "",
    "text": "sf for vector data manipulation (link)\nterra for raster data manipulation (link)\ndplyr for data frame operations (link)\nspData for example datasets (link)"
  },
  {
    "objectID": "book_solutions/chapter3.html#introduction",
    "href": "book_solutions/chapter3.html#introduction",
    "title": "Chapter 3: Attribute data operations",
    "section": "3.1 Introduction",
    "text": "3.1 Introduction\n\nAttribute Data: Non-spatial info tied to geographic data (e.g., bus stop name or elevation).\n\nVector Example: A bus stop’s location as POINT (-0.098 51.495) with attributes like its name.\nRaster Example: Pixel values represent attributes (e.g., elevation); location defined by matrix indices and resolution.\n\nChapter Focus:\n\nManipulating geographic objects using attributes (e.g., names, elevations).\nTechniques: subsetting, aggregation, joining data, creating new variables.\nVector and raster data operations are similar and interchangeable (e.g., subsetting, spatial joins).\n\n\n\n\nCode\nlibrary(sf)        # Handling Simple Features in R\nlibrary(terra)     # Handling Rasters in R\nlibrary(tidyverse) # Data Wrangling\n\nlibrary(spData)    # Spatial Data-sets"
  },
  {
    "objectID": "book_solutions/chapter3.html#vector-attribute-manipulation",
    "href": "book_solutions/chapter3.html#vector-attribute-manipulation",
    "title": "Chapter 3: Attribute data operations",
    "section": "3.2 Vector Attribute Manipulation",
    "text": "3.2 Vector Attribute Manipulation\n\nsf Package:\n\nExtends base R’s data.frame with a geometry column (sfc class) for spatial features (points, lines, polygons).\nGeometry column often named geometry or geom, but customizable.\n\nManipulation Methods:\n\n\nCode\nmethods(class = \"sf\") |&gt; \n  as_tibble() |&gt;\n  rename(methods = x) |&gt; \n  mutate(methods = str_replace_all(methods, \",sf\", \"  \")) |&gt; \n  mutate(methods = str_replace_all(methods, \".sf\", \"  \")) |&gt; \n  gt::gt() |&gt; \n  gt::tab_header(\n    title = \"Methods available\"\n  ) |&gt; \n  gt::opt_interactive()\n\n\n\n\nTable 1: Methods available for the class ‘sf’ in R using {sf} package\n\n\n\n\n\n\nMethods available\n\n\n\n\n\n\n\n\n\n\n\nMethods like aggregate(), cbind(), merge(), and rbind() work seamlessly with sf objects.\nCompatible with tidyverse functions (dplyr, tidyr) and can be used with data.table (partial compatibility noted in issue #2273).\nDropping geometry (st_drop_geometry()) can speed up attribute data operations when spatial data is not required.\n\n\n# Original 'world' dataset\ndim(world)\n## [1] 177  11\nclass(world)\n## [1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n# Dropping the geometry column: Effects\nst_drop_geometry(world) |&gt; \n  dim()\n## [1] 177  10\nst_drop_geometry(world) |&gt; \n  class()\n## [1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\nAdvantages:\n\nsf’s integration with the tidyverse allows robust, efficient data manipulation.\nCompatible with tidyverse functions (e.g., dplyr), making it versatile for data analysis.\n\n\n\n\n\n\n\n\nRelevant Topic\n\n\n\nMajor Pitfalls of Using Spatial Data with the Tidyverse\n\nName Clashes\n\nFunctions like select() from dplyr can mask similar functions from the raster package.\nUse fully qualified names (e.g., dplyr::select()) to avoid conflicts.\n\nCompatibility Issues with sp Package\n\nThe older sp package does not integrate well with tidyverse functions.\nRequires conversion between sp to sf object types using functions like st_as_sf().\n\nHandling Multipolygon Objects\n\nMultiple geometries in objects can cause unexpected plotting results.\nResolve issues by casting to simpler geometry types using st_cast(to = \"POLYGON\").\n\nSpatial Subsetting Challenges\n\nVerbose syntax when using tidyverse functions like filter() with spatial predicates like st_intersects().\nMay result in altered row names, complicating joins and comparisons.\nOther option is spatial subsetting using base R\n\nlnd_buff = lnd[1, ] %&gt;% \n  st_transform(crs = 27700) %&gt;%  # uk CRS\n  st_buffer(500000) %&gt;%\n  st_transform(crs = 4326)\nnear_lnd = world[lnd_buff, ]\nworld_poly = world %&gt;% \n  st_cast(to = \"POLYGON\")\nnear_lnd_new = world_poly[lnd_buff, ]\nnear_lnd_tidy = world %&gt;% \n  filter(st_intersects(., lnd_buff, sparse = FALSE))\n\n\nRow Name Alterations\n\nTidyverse operations may drop or alter row names, affecting joins and comparisons. See related discussion in tidyverse/dplyr#366.\n\nAttribute Alteration Pitfall\n\nResults from tidyverse functions may differ from base R operations due to row name discrepancies.\nExample functions: filter() vs base R subsetting ([]).\n\nIssues with bind_rows()\n\nbind_rows() fails on spatial objects; use alternatives like setting geometries to NULL with st_set_geometry() before combining.\n\nLimited Raster Data Support\n\nTidyverse integration with raster data is minimal.\nInitial efforts like tabularaster, sfraster, and stars aim to enhance support.\n\n\n\n\n\n3.2.1 Vector Attribute Sub-setting\n\nBase R Sub-setting:\n\nUses [ operator and subset() function for rows and columns selection.\nSyntax: object[i, j] returns rows indexed by i and columns by j.\n\ndplyr Sub-setting Functions:\n\nfilter() and slice() for rows, select() for columns.\nselect(): Subsets columns by name or position.\nHelper functions in select() like contains(), starts_with(), num_range().\n\nExtracting a Single Column:\n\nUse pull() (dplyr), $, or [[ (base R).\n\nRow Selection:\n\nslice(): Selects rows by index.\nfilter(): Filters rows based on conditions.\n\nComparison Operators:\n\nStandard operators can be used in filter(): &lt;, &gt;, &lt;=, &gt;=, ==, !=.\n\n\nThe dplyr functions (filter(), select(), pull()) are intuitive and integrate well with the tidyverse workflows.\n\n\n3.2.2 Chaining Commands with Pipes\n\nPipe Operator:\n\n%&gt;% (from the magrittr package) and native |&gt; (from R 4.1.0 onwards) enable chaining commands, improving readability and flow of code.\nThe output of one function becomes the input of the next.\nAlternative: Nested Function Calls: The same operation without pipes uses nested functions, which is harder to read.\n\nSplitting into Multiple Lines:\n\nUseful for debugging and inspecting intermediate results but can clutter the environment.\n\nKey Packages:\n\ndplyr: Provides verbs like filter(), select(), slice(), and supports pipe workflows.\nmagrittr: Provides %&gt;% operator for chaining functions.\n\n\n\n\n3.2.3 Vector Attribute Aggregation\n\nAggregation is summarizing data using one or more grouping variables, often leading to a smaller dataset. It is useful for data reduction, especially when working with large datasets.\nBase R Approach\n\nUsing aggregate():\n\naggregate() groups data and applies a function (e.g., sum). Result: A non-spatial data frame with two columns (continent, pop).\n\nUsing aggregate.sf():\n\nFor spatial objects (sf), use aggregate() with by argument. This results in an sf object with eight features representing continents.\n\n\ndplyr Approach\n\nUsing group_by() and summarize():\n\nEquivalent to aggregate(), but offers flexibility and control:\n\ngroup_by() defines grouping variables.\nsummarize() applies aggregation functions.\n\n\n\n\n\n\nCode\nlibrary(dplyr)\nworld |&gt;\n  group_by(continent) |&gt;\n  summarize(pop = sum(pop, na.rm = TRUE))\n\n\nSimple feature collection with 8 features and 2 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: -180 ymin: -89.9 xmax: 180 ymax: 83.64513\nGeodetic CRS:  WGS 84\n# A tibble: 8 × 3\n  continent                      pop                                        geom\n  &lt;chr&gt;                        &lt;dbl&gt;                              &lt;GEOMETRY [°]&gt;\n1 Africa                  1154946633 MULTIPOLYGON (((36.86623 22, 36.69069 22.2…\n2 Antarctica                       0 MULTIPOLYGON (((-180 -89.9, 180 -89.9, 180…\n3 Asia                    4311408059 MULTIPOLYGON (((36.14976 35.82153, 35.9050…\n4 Europe                   669036256 MULTIPOLYGON (((26.29 35.29999, 25.74502 3…\n5 North America            565028684 MULTIPOLYGON (((-82.26815 23.18861, -82.51…\n6 Oceania                   37757833 MULTIPOLYGON (((166.7932 -15.66881, 167.00…\n7 Seven seas (open ocean)          0 POLYGON ((68.935 -48.625, 68.8675 -48.83, …\n8 South America            412060811 MULTIPOLYGON (((-66.95992 -54.89681, -66.4…\n\n\n\nMore details on grouped data and summarize() from the dplyr package vignettes.\n\n\n\n\n\n\n\nRelevant Topic\n\n\n\ndplyr functions are highly effective when applied to grouped data frames (grouped_df objects). Here are the main points covered:\n\nGrouping Data: Use group_by() to create groups within a data frame based on one or more variables.\n\nTo count rows in each group, use tally().\n\nAccessing Group Metadata:\n\ngroup_keys(): Shows underlying group data. Details here.\ngroup_vars(): Retrieves names of the grouping variables. Details here.\n\nModifying Groups:\n\nTo overwrite or add grouping variables, use .add = TRUE with group_by(). Read more.\nTo remove groups, use ungroup().\n\nVerbs and Grouping:\n\nsummarise(): Computes summary statistics per group. The .groups argument controls grouping structure. More on summarise().\n\nColumn Manipulation:\n\nselect() retains grouping variables by default. More on select().\nrename() and relocate() function the same way for grouped and ungrouped data. Details here.\n\nSorting Groups:\n\narrange(): Sorts data, with .by_group = TRUE option to sort within groups. More on arrange().\n\n\n\n\n\nCheck out Chapter 5 of R for Data Science.\n\n\n\n3.2.4 Vector Attribute Joining\n\nJoining involves combining tables based on a shared key variable. In R, dplyr functions like left_join() and inner_join() are commonly used for this purpose.\n\nThe join functions in dplyr (left_join, inner_join, etc.) follow conventions from SQL, allowing easy and consistent data merging.\nThese functions work similarly for both non-spatial (data.frame) and spatial (sf) objects. The geometry list column in sf objects is the key difference.\n\nWhen merging an sf object with a data.frame\n\nThe resulting object remains an sf object, keeping its spatial features intact while adding new columns for coffee production.\n\nHandling Key Variables:\n\nIf datasets have key variables with matching names (e.g., name_long), joining works automatically.\nIf the key variables differ, either:\n\nRename the variable to match, or\nUse the by argument to specify the joining variables explicitly.\n\n\nInner Joins:\n\nAn inner join keeps only the rows with matching key variables in both datasets. This reduces the number of rows, depending on the overlap in key variables.\n\nTroubleshooting Joins:\n\nIf some rows are missing in the result (e.g., due to differing key names like “Congo, Dem. Rep. of”), identify mismatches using setdiff().\nUse regex matching from the stringr package to identify correct key names for adjustments.\n\nReversing Joins:\n\nYou can also join starting with a non-spatial dataset and adding spatial variables from an sf object.\nThe result will be a non-spatial data.frame (tibble), unless explicitly converted to an sf object using st_as_sf().\n\nFurther Resources:\n\nChapter 13 on Relational Data in R for Data Science by Grolemund and Wickham (2016)\nThe documentation describing joins with data.table package.\nThe join vignette in the geocompkg package, which is summarized below: —\n\n\n\n\n\n\n\n\nRelevant Topic\n\n\n\nSpatial Joins Extended\n\nSpatial Joins: Combines attributes from different datasets based on a common key, useful for integrating non-spatial (attribute) data with spatial data.\n\n\nLeft Join\n\nAdds attributes to all observations from the left dataset with matched values from the right.\n\n\n\nJoining by Different Column Names\n\nCase: If key columns have different names, use a named vector to specify the keys\nIssue: Duplicate columns (e.g., tbl_1_var.x and tbl_2_var.y). Resolved by specifying all keys.\n\n\n\nJoining with a Non-Spatial First Argument\n\nDropping Geometry: st_drop_geometry() removes spatial attributes, allowing joins with standard data frames.\n\n\n\nInner Join\n\nKeeps only rows with matching keys in both datasets.\n\n\n\n\n\n\n3.2.5 Creating attributes and removing spatial information\n\nCreating new attributes:\n\nCalculate a new attribute using mutate() from dplyr. Example: population / area.\nUse mutate() to add the new column without overwriting the geometry column.\n\nCombining columns:\n\nUse unite() from tidyr to merge two or more columns into one (e.g., continent and region_un).\nunite() allows setting a separator (e.g., :) and can optionally remove the original columns.\n\nSplitting columns:\n\nUse separate_wider_position() and separate_wider_delim()from tidyr to split a combined column back into its original components.\n\nRenaming columns:\n\nUse rename() from dplyr for renaming specific columns.\nFor renaming all columns, use setNames() with a character vector for new names.\n\nRemoving geometry:\n\nUse st_drop_geometry() to drop the spatial information while retaining the attributes in a non-spatial data.frame. This method is preferred over manually selecting non-geometry columns as it avoids unintended issues."
  },
  {
    "objectID": "book_solutions/chapter3.html#manipulating-raster-objects",
    "href": "book_solutions/chapter3.html#manipulating-raster-objects",
    "title": "Chapter 3: Attribute data operations",
    "section": "3.3 Manipulating Raster Objects",
    "text": "3.3 Manipulating Raster Objects\n\nRaster Data Model:\n\nRepresents continuous surfaces, unlike vector data which use discrete entities (points, lines, polygons).\nUseful for representing spatial phenomena like elevation, temperature, and land cover.\n\nCreating a Raster Object:\n\nUse rast() function to create raster objects.\nThe vals argument assigns numeric values to each cell.\n\nCategorical Raster Values:\n\nCan hold logical or factor (categorical) values.\nExample: Creating a raster for soil types (clay, silt, sand).\n\nRaster Attribute Table (RAT):\n\nStores additional information about raster values, accessible with cats().\nEach layer’s attribute data can be modified with levels().\n\nColor Table:\n\nCategorical rasters can store color information using a color table with RGB (Red, Green, Blue) or RGBA (Red, Green, Blue, Alpha) columns.\nUse coltab() to view or set color tables.\nSaving the raster (e.g., as GeoTIFF) includes the color table information.\n\n\n\n3.3.1 Raster subsetting\n\nRaster Subsetting:\n\nInvolves selecting specific parts of a raster dataset using the base R subsetting operator [ , ].\nSubsetting Methods:\n\nRow-Column Indexing: Accesses cells using specific row and column coordinates.\nCell IDs: Accesses cells using unique numeric identifiers for each raster cell.\nCoordinates and Spatial Objects: These methods are used for spatial subsetting, using another spatial object to subset a raster.\n\n\nExamples:\n\nAccessing the top-left pixel value using row-column indexing:\n\n\n\n\nCode\n# A simple raster\n  elev &lt;- rast(\n    nrows = 10, ncols = 10,\n    xmin = -1.5, xmax = 1.5, ymin = -1.5, ymax = 1.5,\n    vals = 1:100\n    ) \n\n# A raster with categorical levels\ngrain &lt;- rast(\n  nrows = 10, ncols = 10,\n  xmin = -1.5, xmax = 1.5, ymin = -1.5, ymax = 1.5,\n  vals = sample(\n    x = c(\"Wheat\", \"Rice\", \"Maize\", \"Others\"),\n    size = 100,\n    replace = TRUE\n  )\n)\n\n    # Print the \"elev\" object to visualize the design\n    print(elev)\n## class       : SpatRaster \n## dimensions  : 10, 10, 1  (nrow, ncol, nlyr)\n## resolution  : 0.3, 0.3  (x, y)\n## extent      : -1.5, 1.5, -1.5, 1.5  (xmin, xmax, ymin, ymax)\n## coord. ref. : lon/lat WGS 84 (CRS84) (OGC:CRS84) \n## source(s)   : memory\n## name        : lyr.1 \n## min value   :     1 \n## max value   :   100\n\n    # Plot the raster object to visualize the matrix as an image\n    plot(\n      elev, \n      main = \"Raster Object with a Sequential Pattern\"\n    )\n\n\n\n\n\n\n\n\n\nCode\n\n    # Accessing using row number and column number\n    elev[1, 1]\n##   lyr.1\n## 1     1\n\n    elev[10,5]\n##   lyr.1\n## 1    95\n\n    plot(\n      grain,\n      main = \"Raster Object with 4 categorical levels\"\n    )\n\n\n\n\n\n\n\n\n\nCode\n\n    # Accessing using row number and column number\n\n    grain[1,1]\n##   lyr.1\n## 1  Rice\n\n    grain[10, 10]\n##    lyr.1\n## 1 Others\n\n    # A multilayered raster - combining both\n    two_layers &lt;- c(elev, grain)\n\n    print(two_layers)\n## class       : SpatRaster \n## dimensions  : 10, 10, 2  (nrow, ncol, nlyr)\n## resolution  : 0.3, 0.3  (x, y)\n## extent      : -1.5, 1.5, -1.5, 1.5  (xmin, xmax, ymin, ymax)\n## coord. ref. : lon/lat WGS 84 (CRS84) (OGC:CRS84) \n## source(s)   : memory\n## names       : lyr.1, lyr.1 \n## min values  :     1, Maize \n## max values  :   100, Wheat\n    names(two_layers) &lt;- c(\"Continuous variable\", \n                           \"Categorical variable\")\n    plot(\n      two_layers\n    )\n\n\n\n\n\n\n\n\n\n\nAccessing the first cell using its Cell ID:\n\n\n\nCode\n# Accessing raster values using cell ID\nelev[1]\n##   lyr.1\n## 1     1\nelev[95]\n##   lyr.1\n## 1    95\n\n\n\nSubsetting Multi-layered Rasters:\n\nFor multi-layer raster objects (e.g., two_layers = c(grain, elev)), subsetting returns values from each layer:\n\n\n\ntwo_layers[1]\n\n  Continuous variable Categorical variable\n1                   1                 Rice\n\n\n\nTo extract all cell values from a raster:\n\n\n# Extracting all values - single layer raster\nelev[][1:10]  \n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n# It is Equivalent to using the values() function\nvalues(elev)[1:10]\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n# Extracting all values - multi-layer raster\n# It returns a data.frame\nvalues(two_layers) |&gt; \n  as_tibble()\n\n# A tibble: 100 × 2\n   `Continuous variable` `Categorical variable`\n                   &lt;int&gt;                  &lt;int&gt;\n 1                     1                      3\n 2                     2                      3\n 3                     3                      3\n 4                     4                      2\n 5                     5                      1\n 6                     6                      1\n 7                     7                      3\n 8                     8                      3\n 9                     9                      1\n10                    10                      2\n# ℹ 90 more rows\n\n\n\nModifying Raster Values:\n\nChange specific cell values by combining subsetting with assignment:\n\n\n\nelev[5, 5] = 0  # Sets the value of the 1 central cells to 0\n\nplot(elev)\n\n\n\n\n\n\n\n\n\nModify multiple cells simultaneously:\n\n\nelev[5, c(5,6)] = 0  # Sets the value of the central 2 cells to 0\n\nplot(elev)\n\n\n\n\n\n\n\n\n\nReplacing Values in Multi-layered Rasters:\n\nModify cell values in a multi-layer raster using a matrix with corresponding layers and cell indices:\n\n\n\n# Assigns new values for Cell ID 1 in both layers\ntwo_layers[45] = cbind(c(1), c(4))  \n\nplot(two_layers)\n\n\n\n\n\n\n\n\nThis subsetting approach allows efficient extraction and manipulation of raster cell values, enabling the customization of raster datasets for specific analytical needs.\n\n\n3.3.2 Summarizing Raster Objects\n\nDescriptive Statistics:\n\nThe terra package provides functions for summarizing raster objects.\nPrinting a raster object directly shows the minimum and maximum values.\nThe summary() function provides detailed statistics:\n\nFor continuous rasters: Minimum, maximum, quartiles, and count of NAs.\nFor categorical rasters: Counts of each unique class.\n\n\n\n\nsummary(two_layers)\n##  Continuous.variable Categorical.variable\n##  Min.   :  1.00      Maize :18           \n##  1st Qu.: 24.75      Others:26           \n##  Median : 50.50      Rice  :31           \n##  Mean   : 50.06      Wheat :25           \n##  3rd Qu.: 75.25                          \n##  Max.   :100.00\n\n\nCustom Summary Statistics:\n\nThe global() function calculates additional statistics like standard deviation and can be used to apply custom summary statistics.\n\n\n\nglobal(two_layers, sum)\n\n                      sum\nContinuous variable  5006\nCategorical variable  263\n\nglobal(two_layers, mean)\n\n                      mean\nContinuous variable  50.06\nCategorical variable  2.63\n\n\n\nFrequency Table:\n\nThe freq() function generates a frequency table for categorical raster values, showing counts of each category.\n\n\n\n\nCode\nfreq(two_layers$`Categorical variable`) |&gt; \n  gt::gt() |&gt; \n  gtExtras::gt_theme_538()\n\n\n\n\nTable 2: Frequency table using freq() on raster objects\n\n\n\n\n\n\n\n\n\nlayer\nvalue\ncount\n\n\n\n\n1\nMaize\n18\n\n\n1\nOthers\n26\n\n\n1\nRice\n31\n\n\n1\nWheat\n25\n\n\n\n\n\n\n\n\n\n\n\nVisualization of Raster Statistics:\n\nSeveral functions like hist(), boxplot(), and density() work directly with raster objects to visualize statistics.\nIf visualization functions do not support raster objects, values can be extracted using values() for further plotting.\n\nHandling Function Name Clashes:\n\nSome functions (e.g., extract()) exist in multiple packages like terra and tidyr, leading to conflicts.\nTo avoid issues, call functions with full namespaces (e.g., tidyr::extract()).\n\nUse detach() to unload conflicting packages, but be cautious as it may impact dependent packages."
  },
  {
    "objectID": "book_solutions/chapter3.html#exercises",
    "href": "book_solutions/chapter3.html#exercises",
    "title": "Chapter 3: Attribute data operations",
    "section": "3.4 Exercises",
    "text": "3.4 Exercises\n\nlibrary(sf)\nlibrary(dplyr)\nlibrary(terra)\nlibrary(spData)\ndata(us_states)\ndata(us_states_df)\n\n\nE1\nCreate a new object called us_states_name that contains only the NAME column from the us_states object using either base R ([) or tidyverse (select()) syntax. What is the class of the new object and what makes it geographic?\n\nus_states_name &lt;- us_states |&gt; \n  select(NAME)\n\nclass(us_states_name)\n\n[1] \"sf\"         \"data.frame\"\n\n\nThe new object of the class sf, and the stickiness of the geometry column makes it a geographical dataset.\n\n\n\nE2\nSelect columns from the us_states object which contain population data. Obtain the same result using a different command (bonus: try to find three ways of obtaining the same result). Hint: try to use helper functions, such as contains or matches from dplyr (see ?contains).\n\nus_states |&gt; \n  select(contains(\"pop\"))\n\nus_states |&gt; \n  select(where(is.double)) |&gt; \n  select(-AREA)\n\nus_states |&gt; \n  select(5:6)\n\nThe above three methods all select the columns total_pop_10 and total_pop_15 . Notice that the column geometry is sticky, and can be removed using st_drop_geometry().\n\n\n\nE3\nFind all states with the following characteristics (bonus: find and plot them):\n\nBelong to the Midwest region.\nThe code shown below gives out the names of all such states.\n\n\nus_states |&gt; \n  filter(REGION == \"Midwest\") |&gt; \n  pull(NAME) |&gt; \n  paste(collapse = \", \")\n\n[1] \"Indiana, Kansas, Minnesota, Missouri, North Dakota, South Dakota, Illinois, Iowa, Michigan, Nebraska, Ohio, Wisconsin\"\n\n\n\nBelong to the West region, have an area below 250,000 km2and in 2015 a population greater than 5,000,000 residents (hint: you may need to use the function units::set_units() or as.numeric()).\nOnly Washington State qualifies all three conditions. Code is shown below.\n\n\nus_states |&gt; \n  filter(REGION == \"West\") |&gt; \n  filter(total_pop_15 &gt; 5e6) |&gt; \n  filter(as.numeric(AREA) &lt; 250000)\n\nSimple feature collection with 1 feature and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -124.7042 ymin: 45.54774 xmax: -116.916 ymax: 49.00236\nGeodetic CRS:  NAD83\n  GEOID       NAME REGION          AREA total_pop_10 total_pop_15\n1    53 Washington   West 175436 [km^2]      6561297      6985464\n                        geometry\n1 MULTIPOLYGON (((-122.7699 4...\n\nus_states |&gt; \n  filter(REGION == \"West\") |&gt; \n  filter(total_pop_15 &gt; 5e6) |&gt; \n  filter(AREA &lt; units::set_units(250000, \"km2\"))\n\nSimple feature collection with 1 feature and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -124.7042 ymin: 45.54774 xmax: -116.916 ymax: 49.00236\nGeodetic CRS:  NAD83\n  GEOID       NAME REGION          AREA total_pop_10 total_pop_15\n1    53 Washington   West 175436 [km^2]      6561297      6985464\n                        geometry\n1 MULTIPOLYGON (((-122.7699 4...\n\n\n\nBelong to the South region, had an area larger than 150,000 km2 and a total population in 2015 larger than 7,000,000 residents.\nThe states that fulfil these conditions are Florida, Georgia and Texas.\n\n\n\nCode\nus_states |&gt; \n  filter(REGION == \"South\") |&gt; \n  filter(AREA &gt; units::set_units(150000, \"km2\")) |&gt; \n  filter(total_pop_15 &gt; 7e6) |&gt; \n  pull(NAME)\n\n\n[1] \"Florida\" \"Georgia\" \"Texas\"  \n\n\n\n\n\nE4\nWhat was the total population in 2015 in the us_states dataset? What was the minimum and maximum total population in 2015?\nThe total population in the us_states dataset in the year 2015 was 314,375,347. The minimum total population in 2015 was 579,679 (Wyoming), and the maximum total population was 38,421,464 (California).\n\nus_states |&gt; \n  st_drop_geometry() |&gt; \n  as_tibble() |&gt; \n  summarise(\n    total_pop_15 = sum(total_pop_15)\n  )\n## # A tibble: 1 × 1\n##   total_pop_15\n##          &lt;dbl&gt;\n## 1    314375347\n\nus_states |&gt; \n  st_drop_geometry() |&gt; \n  slice_min(order_by = total_pop_15, n = 1)\n##   GEOID    NAME REGION            AREA total_pop_10 total_pop_15\n## 1    56 Wyoming   West 253309.6 [km^2]       545579       579679\n\nus_states |&gt; \n  st_drop_geometry() |&gt; \n  slice_max(order_by = total_pop_15, n = 1)\n##   GEOID       NAME REGION            AREA total_pop_10 total_pop_15\n## 1    06 California   West 409747.1 [km^2]     36637290     38421464\n\n\n\n\nE5\nHow many states are there in each region?\nThe number of states in each region are shown in Table 3 below.\n\n\nCode\nus_states |&gt; \n  st_drop_geometry() |&gt; \n  count(REGION, name = \"Number of States\") |&gt; \n  gt::gt() |&gt; \n  gtExtras::gt_theme_538()\n\n\n\n\nTable 3: Table showing number of states in each region.\n\n\n\n\n\n\n\n\n\nREGION\nNumber of States\n\n\n\n\nNorteast\n9\n\n\nMidwest\n12\n\n\nSouth\n17\n\n\nWest\n11\n\n\n\n\n\n\n\n\n\n\n\n\n\nE6\nWhat was the minimum and maximum total population in 2015 in each region? What was the total population in 2015 in each region?\nThe minimum and maximum total population in 2015 in each region is shown in Table 4 (a). The total population in each region in 2015 is shown in Table 4 (b).\n\n\nCode\nus_states |&gt; \n  as_tibble() |&gt; \n  group_by(REGION) |&gt; \n  slice_min(order_by = total_pop_15, n = 1) |&gt; \n  select(REGION, NAME, total_pop_15) |&gt; \n  ungroup() |&gt; \n  gt::gt() |&gt; \n  gt::fmt_number(\n    columns = total_pop_15,\n    decimals = 0\n  ) |&gt; \n  gt::cols_label_with(fn = snakecase::to_title_case) |&gt; \n  gtExtras::gt_theme_538()\nus_states |&gt; \n  as_tibble() |&gt; \n  group_by(REGION) |&gt; \n  summarise(\n    total_population_2015 = sum(total_pop_15)\n  ) |&gt; \n  select(REGION, total_population_2015) |&gt; \n  ungroup() |&gt; \n  gt::gt() |&gt; \n  gt::fmt_number(\n    columns = total_population_2015,\n    decimals = 0\n  ) |&gt; \n  gt::cols_label_with(fn = snakecase::to_title_case) |&gt; \n  gtExtras::gt_theme_538()\n\n\n\n\nTable 4: Region-wise total and minimum-maximum populations\n\n\n\n\n\n\n\n\n\n(a) Minimum and maximum populations, region-wise, in 2015\n\n\n\n\n\nRegion\nName\nTotal Pop 15\n\n\n\n\nNorteast\nVermont\n626,604\n\n\nMidwest\nNorth Dakota\n721,640\n\n\nSouth\nDistrict of Columbia\n647,484\n\n\nWest\nWyoming\n579,679\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Total population, region-wise, in 2015\n\n\n\n\n\nRegion\nTotal Population 2015\n\n\n\n\nNorteast\n55,989,520\n\n\nMidwest\n67,546,398\n\n\nSouth\n118,575,377\n\n\nWest\n72,264,052\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nE7\nAdd variables from us_states_df to us_states, and create a new object called us_states_stats. What function did you use and why? Which variable is the key in both datasets? What is the class of the new object?\nThe function we use to accomplish this task is left_join() and the key in both datasets are the state names, called NAME in us_states dataset, and state in us_states_df dataset.\nThe class of the new object depends on which object is used first on the left_join() function, if us_states (an sf object) is used first, the class of new object is sf . However, if the us_states_df (a data frame) is used first, the resulting object is a data.frame or tibble.\n\nus_states |&gt; \n  left_join(us_states_df, by = join_by(NAME == state)) |&gt; \n  class()\n## [1] \"sf\"         \"data.frame\"\n\nus_states_df |&gt; \n  left_join(us_states, by = join_by(state == NAME)) |&gt; \n  class()\n## [1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\n\n\nE8\nus_states_df has two more rows than us_states. How can you find them? (Hint: try to use the dplyr::anti_join() function.)\nThe two rows that more more in us_states_df are shown below: —\n\nus_states_df |&gt; \n  anti_join(us_states, by = join_by(state == NAME)) |&gt; \n  gt::gt() |&gt; \n  gtExtras::gt_theme_538() |&gt; \n  gt::cols_label_with(fn = snakecase::to_title_case)\n\n\n\nTable 5: The two extra rows in us_states_df\n\n\n\n\n\n\n\n\n\nState\nMedian Income 10\nMedian Income 15\nPoverty Level 10\nPoverty Level 15\n\n\n\n\nAlaska\n29509\n31455\n64245\n72957\n\n\nHawaii\n29945\n31051\n124627\n153944\n\n\n\n\n\n\n\n\n\n\n\n\n\nE9\nWhat was the population density in 2015 in each state? What was the population density in 2010 in each state?\nThe Table 6 shows the population density.\n\n\nCode\nus_states |&gt; \n  st_drop_geometry() |&gt; \n  as_tibble() |&gt; \n  mutate(\n    population_density_2010 = total_pop_10 / as.numeric(AREA),\n    population_density_2015 = total_pop_15 / as.numeric(AREA),\n    .keep = \"unused\"\n  ) |&gt; \n  select(-GEOID) |&gt; \n  gt::gt() |&gt; \n  gt::opt_interactive() |&gt; \n  gtExtras::gt_theme_espn() |&gt; \n  gt::fmt_number(\n    decimals = 1\n  ) |&gt; \n  gt::cols_label_with(fn = snakecase::to_title_case)\n\n\n\n\nTable 6: A table showing population density in 2010 and 2015 in each state\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nE10\nHow much has population density changed between 2010 and 2015 in each state? Calculate the change in percentages and map them.\nThe Table 7 shows how much the population density has changed between 2010 and 2015 in each state. The Figure 1 shows the percentage change in a map of the US.\n\n\nCode\nus_states |&gt; \n  st_drop_geometry() |&gt; \n  as_tibble() |&gt; \n  mutate(\n    population_density_2010 = total_pop_10 / as.numeric(AREA),\n    population_density_2015 = total_pop_15 / as.numeric(AREA),\n    change_in_density = (population_density_2015 - population_density_2010)/population_density_2010,\n    .keep = \"unused\"\n  ) |&gt; \n  select(-GEOID) |&gt; \n  gt::gt() |&gt; \n  gt::opt_interactive() |&gt; \n  gtExtras::gt_theme_espn() |&gt; \n  gt::fmt_number(\n    decimals = 1\n  ) |&gt; \n  gt::fmt_percent(\n    columns = change_in_density\n  ) |&gt; \n  gt::cols_label_with(fn = snakecase::to_title_case)\n\n\n\n\nTable 7: Table showing change in population density between 2010 and 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nus_states |&gt; \n  mutate(\n    population_density_2010 = total_pop_10 / as.numeric(AREA),\n    population_density_2015 = total_pop_15 / as.numeric(AREA),\n    change_in_density = (population_density_2015 - population_density_2010)/population_density_2010,\n    .keep = \"unused\"\n  ) |&gt; \n  ggplot() +\n  geom_sf(\n    mapping = aes(\n      fill = change_in_density\n    )\n  ) +\n  geom_sf_text(\n    mapping = aes(\n      label = paste0(\n        round(\n          change_in_density * 100,\n          1\n        ),\n        \"%\"\n      )\n    ),\n    size = 3\n  ) +\n  paletteer::scale_fill_paletteer_c(\n    \"ggthemes::Red-Green Diverging\",\n    labels = scales::label_percent(),\n    name = \"Change in population density between 2010 and 2015\",\n    limits = c(-0.05, 0.1)\n  ) +\n  ggthemes::theme_map() +\n  theme(\n    legend.position = \"bottom\",\n    legend.title.position = \"top\"\n  )\n\n\n\n\n\n\n\n\nFigure 1: Map of the change in population density\n\n\n\n\n\n\n\n\nE11\nChange the columns’ names in us_states to lowercase. (Hint: helper functions - tolower() and colnames() may help.)\nA very easy method is using the janitor package and the function clean_names()\n\n\nCode\nus_states |&gt; \n  janitor::clean_names() |&gt; \n  as_tibble() |&gt; \n  print(n = 5)\n\n\n# A tibble: 49 × 7\n  geoid name   region   area total_pop_10 total_pop_15                  geometry\n  &lt;chr&gt; &lt;chr&gt;  &lt;fct&gt;  [km^2]        &lt;dbl&gt;        &lt;dbl&gt;        &lt;MULTIPOLYGON [°]&gt;\n1 01    Alaba… South  1.34e5      4712651      4830620 (((-88.20006 34.99563, -…\n2 04    Arizo… West   2.95e5      6246816      6641928 (((-114.7196 32.71876, -…\n3 08    Color… West   2.70e5      4887061      5278906 (((-109.0501 41.00066, -…\n4 09    Conne… Norte… 1.30e4      3545837      3593222 (((-73.48731 42.04964, -…\n5 12    Flori… South  1.51e5     18511620     19645772 (((-81.81169 24.56874, -…\n# ℹ 44 more rows\n\n\n\n\n\nE12\nUsing us_states and us_states_df create a new object called us_states_sel. The new object should have only two variables: median_income_15 and geometry. Change the name of the median_income_15 column to Income.\nThe new object us_states_sel is created as shown below.\n\n\nCode\nus_states_sel &lt;- us_states |&gt; \n  left_join(us_states_df, by = join_by(NAME == state)) |&gt; \n  select(Income = median_income_15, geometry)\n\nus_states_sel\n\n\nSimple feature collection with 49 features and 1 field\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -124.7042 ymin: 24.55868 xmax: -66.9824 ymax: 49.38436\nGeodetic CRS:  NAD83\nFirst 10 features:\n   Income                       geometry\n1   22890 MULTIPOLYGON (((-88.20006 3...\n2   26156 MULTIPOLYGON (((-114.7196 3...\n3   30752 MULTIPOLYGON (((-109.0501 4...\n4   33226 MULTIPOLYGON (((-73.48731 4...\n5   24654 MULTIPOLYGON (((-81.81169 2...\n6   25588 MULTIPOLYGON (((-85.60516 3...\n7   23558 MULTIPOLYGON (((-116.916 45...\n8   25834 MULTIPOLYGON (((-87.52404 4...\n9   27315 MULTIPOLYGON (((-102.0517 4...\n10  24014 MULTIPOLYGON (((-92.01783 2...\n\n\n\n\n\nE13\nCalculate the change in the number of residents living below the poverty level between 2010 and 2015 for each state. (Hint: See ?us_states_df for documentation on the poverty level columns.) Bonus: Calculate the change in the percentage of residents living below the poverty level in each state.\nThe Table 8 shows the change in the number of residents living below the poverty level between 2010 and 2015 for each state.\n\n\nCode\nus_states_df |&gt; \n  mutate(\n    change_in_poverty = poverty_level_15 - poverty_level_10\n  ) |&gt; \n  select(state, change_in_poverty) |&gt; \n  gt::gt() |&gt; \n  gt::fmt_number(decimals = 0) |&gt; \n  gt::cols_label_with(fn = snakecase::to_title_case) |&gt; \n  gt::opt_interactive() \n\n\n\n\nTable 8: The change in the number of residents living below the poverty level between 2010 and 2015 for each state\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Table 9 shows the change in the percentage of residents living below the poverty level in each state.\n\n\nCode\nus_states |&gt; \n  st_drop_geometry() |&gt; \n  left_join(us_states_df, by = join_by(NAME == state)) |&gt; \n  as_tibble() |&gt; \n  mutate(\n    state = NAME,\n    poverty_2010 = poverty_level_10 / total_pop_10,\n    poverty_2015 = poverty_level_15 / total_pop_15,\n    change_in_poverty = poverty_2015 - poverty_2010,\n    .keep = \"none\"\n  ) |&gt; \n  gt::gt() |&gt; \n  gt::fmt_percent() |&gt; \n  gt::cols_label_with(fn = snakecase::to_title_case) |&gt; \n  gt::opt_interactive()\n\n\n\n\nTable 9: Table showing the change in the percentage of residents living below the poverty level in each state.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nE14\nWhat was the minimum, average and maximum state’s number of people living below the poverty line in 2015 for each region? Bonus: What is the region with the largest increase in people living below the poverty line?\nThe the minimum, average and maximum state’s number of people living below the poverty line in 2015 for each region are shown in Table 10 below.\n\n\nCode\nus_states |&gt; \n  st_drop_geometry() |&gt; \n  select(state = NAME, region = REGION) |&gt; \n  left_join(us_states_df) |&gt; \n  as_tibble() |&gt; \n  group_by(region) |&gt; \n  summarise(\n    minimum_poverty_2015 = min(poverty_level_15),\n    maximum_poverty_2015 = max(poverty_level_15),\n    average_poverty_2015 = mean(poverty_level_15)\n  ) |&gt; \n  gt::gt() |&gt; \n  gt::cols_label_with(fn = snakecase::to_title_case) |&gt; \n  gt::fmt_number(decimals = 0)\n\n\n\n\nTable 10: A table showing the minimum, average and maximum state’s number of people living below the poverty line in 2015 for each region\n\n\n\n\n\n\n\n\n\nRegion\nMinimum Poverty 2015\nMaximum Poverty 2015\nAverage Poverty 2015\n\n\n\n\nNorteast\n69,233\n3,005,943\n804,465\n\n\nMidwest\n79,758\n1,801,118\n799,155\n\n\nSouth\n108,315\n4,472,451\n1,147,575\n\n\nWest\n64,995\n6,135,142\n1,016,665\n\n\n\n\n\n\n\n\n\n\nAs evident in Table 11, the region with the largest increase in people living below the poverty line is the South Region.\n\n\nCode\nus_states |&gt; \n  st_drop_geometry() |&gt; \n  select(state = NAME, region = REGION) |&gt; \n  as_tibble() |&gt; \n  left_join(us_states_df) |&gt; \n  group_by(region) |&gt; \n  summarise(\n    change_total_poverty = sum(poverty_level_15) - sum(poverty_level_10)\n  ) |&gt; \n  arrange(desc(change_total_poverty)) |&gt; \n  gt::gt() |&gt; \n  gt::cols_label_with(fn = snakecase::to_title_case) |&gt; \n  gt::fmt_number(decimals = 0)\n\n\n\n\nTable 11: Table showing the region with the largest increase in people living below the poverty line\n\n\n\n\n\n\n\n\n\nRegion\nChange Total Poverty\n\n\n\n\nSouth\n2,718,396\n\n\nWest\n2,102,479\n\n\nMidwest\n1,095,133\n\n\nNorteast\n877,493\n\n\n\n\n\n\n\n\n\n\n\n\n\nE15\nCreate a raster from scratch, with nine rows and columns and a resolution of 0.5 decimal degrees (WGS84). Fill it with random numbers. Extract the values of the four corner cells.\n\n# Load the terra package\nlibrary(terra)\n\n# Create a raster with 9 rows and 9 columns, resolution of 0.5 degrees\nr &lt;- rast(nrows = 9, ncols = 9, \n          resolution = 0.5, \n          crs = \"EPSG:4326\")\n\n# Fill the raster with random numbers\nvalues(r) &lt;- runif(ncell(r))\n\n# Print the raster\nprint(r)\n## class       : SpatRaster \n## dimensions  : 360, 720, 1  (nrow, ncol, nlyr)\n## resolution  : 0.5, 0.5  (x, y)\n## extent      : -180, 180, -90, 90  (xmin, xmax, ymin, ymax)\n## coord. ref. : lon/lat WGS 84 (EPSG:4326) \n## source(s)   : memory\n## name        :        lyr.1 \n## min value   : 4.599569e-06 \n## max value   : 9.999993e-01\n\nplot(r)\n\n\n\n\n\n\n\n# Extract the values of the four corner cells\n# Top-left (1, 1), Top-right (1, 9), Bottom-left (9, 1), \n# # Bottom-right (9, 9)\n\nr[1,1]\n##       lyr.1\n## 1 0.3572785\nr[1,9]\n##       lyr.1\n## 1 0.2861174\nr[9,1]\n##       lyr.1\n## 1 0.2665531\nr[9,9]\n##       lyr.1\n## 1 0.5069412\n\n\n\n\nE16\nWhat is the most common class of our example raster grain?\n\n\nCode\ngrain_order &lt;-  c(\"clay\", \"silt\", \"sand\")\ngrain_char &lt;- sample(grain_order, 36, replace = TRUE)\ngrain_fact &lt;-  factor(grain_char, levels = grain_order)\ngrain &lt;-rast(nrows = 6, ncols = 6, \n             xmin = -1.5, xmax = 1.5, \n             ymin = -1.5, ymax = 1.5,\n             vals = grain_fact)\n\nanswer &lt;- freq(grain) |&gt; \n  arrange(desc(count))\n\ngt::gt(answer) |&gt; \n  gt::cols_label_with(fn = snakecase::to_title_case)\n\n\n\n\nTable 12: The count of different classes in the example raster grain.\n\n\n\n\n\n\n\n\n\nLayer\nValue\nCount\n\n\n\n\n1\nsilt\n14\n\n\n1\nclay\n13\n\n\n1\nsand\n9\n\n\n\n\n\n\n\n\n\n\nThe most common class is the silt .\n\n\n\nE17\nPlot the histogram and the boxplot of the dem.tif file from the spDataLarge package (system.file(\"raster/dem.tif\", package = \"spDataLarge\")).\nThe plots are shown in Figure 2\n\ntemp_rast &lt;- rast(system.file(\"raster/dem.tif\", package = \"spDataLarge\"))\n\nhist(temp_rast)\n\nboxplot(temp_rast)\n\n# Using ggplot2 methods\n\ntemp_rast |&gt; \n  values() |&gt; \n  as_tibble() |&gt; \n  ggplot(aes(dem)) +\n  geom_histogram(\n    fill = \"white\",\n    colour = \"grey20\"\n  )\n\ntemp_rast |&gt; \n  values() |&gt; \n  as_tibble() |&gt; \n  ggplot(aes(dem)) +\n  geom_boxplot(\n    fill = \"white\",\n    colour = \"grey20\",\n    staplewidth = 0.5\n  )\n\n\n\n\n\n\n\n\n\n\n(a) Histogram of the raster dem.tif using base R hist()\n\n\n\n\n\n\n\n\n\n\n\n(b) Boxplot of the raster dem.tif using base R boxplot()\n\n\n\n\n\n\n\n\n\n\n\n(c) Histogram of the values in raster dem.tif using ggplot2\n\n\n\n\n\n\n\n\n\n\n\n(d) Boxplot of the values in raster dem.tif using ggplot2\n\n\n\n\n\n\nFigure 2: Plots produced for question E17"
  },
  {
    "objectID": "book_solutions/chapter5.html",
    "href": "book_solutions/chapter5.html",
    "title": "Chapter 5: Geometry operations",
    "section": "",
    "text": "library(sf)        # Simple Features in R\nlibrary(terra)     # Handling rasters in R\nlibrary(tidyterra) # For plotting rasters in ggplot2\nlibrary(magrittr)  # Using pipes with raster objects\nlibrary(tidyverse) # All things tidy; Data Wrangling\nlibrary(spData)    # Spatial Datasets\nlibrary(patchwork) # Composing plots"
  },
  {
    "objectID": "book_solutions/chapter5.html#introduction",
    "href": "book_solutions/chapter5.html#introduction",
    "title": "Chapter 5: Geometry operations",
    "section": "5.1 Introduction",
    "text": "5.1 Introduction\n\nPrevious chapters introduced geographic datasets’ structure (Chapter 2), attribute-based manipulation (Chapter 3), and spatial relations (Chapter 4).\nFocus of this chapter: Manipulating geographic elements of spatial objects.\n\nExamples: Creating buffers, simplifying/converting vector geometries, and raster aggregation/resampling.\n\nSection 5.2: Transforming vector geometries using:\n\nUnary operations: Simplifications, buffers, centroids, and affine transformations (Sections 5.2.1–5.2.4).\nBinary operations: Modifying geometries through clipping and unions (Sections 5.2.5–5.2.7).\nType transformations: Converting geometry types, e.g., polygons to lines (Section 5.2.8).\n\nSection 5.3: Raster transformations:\n\nAlter pixel size, resolution, extent, and origin.\nAlign raster datasets for map algebra."
  },
  {
    "objectID": "book_solutions/chapter5.html#geometric-operations-on-vector-data",
    "href": "book_solutions/chapter5.html#geometric-operations-on-vector-data",
    "title": "Chapter 5: Geometry operations",
    "section": "5.2 Geometric operations on vector data",
    "text": "5.2 Geometric operations on vector data\n\nFocus: Operations that modify the geometry of vector (sf) objects.\nKey distinction: Works directly on geometry-level objects of class sfc, in addition to sf objects.\nExamples: Drilling into geometry to transform, simplify, or reshape vector data.\n\n\n5.2.1 Simplification\n\nGeneralizes vector geometries (lines/polygons) for smaller scale maps, reducing memory, disk space, and bandwidth usage. Useful for publishing interactive maps by simplifying complex geometries.\nKey Functions and Algorithms:\n\nst_simplify() from the sf package (Pebesma and Bivand 2023):\n\nImplements the Douglas-Peucker algorithm (Douglas and Peucker 1973).\nControlled by dTolerance (generalization level in metres, or map units).\nSimplifies individual geometries but does not preserve topology, leading to overlaps or holes.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\ntopology (noun): the way in which parts of something are organized, arranged or connected\n\n\n\nms_simplify() from the rmapshaper package (Teucher and Russell 2023):\n\nUses the Visvalingam algorithm (Visvalingam and Whyatt 1993).\nRetains topology by default (keep_shapes = TRUE) and allows fine control over the vertex retention (keep: the % of vertices that are to be retained, given as a proportion).\n\nsmooth() from the smoothr package:\n\nSmooths edges using techniques like Gaussian kernel regression, Chaikin’s algorithm, or spline interpolation.\nDoes not reduce vertex count and does not preserve topology.\nKey parameter: smoothness (controls Gaussian bandwidth).\n\nExamples of Simplification are shown in Figure 1\nApplications of Smoothing:\n\nSuitable for geometries derived from raster vectorization (e.g., Chapter 6).\n\n\n\n\nCode\n# Download India's Official states' map from\n# https://github.com/Aditya-Dahiya/projects_presentations/tree/main/data/india_map\n\n#### Base Map\nindia_states &lt;- read_sf(\"India_State_Boundary.shp\")\n\ng &lt;- india_states |&gt; \n  ggplot() +\n  geom_sf() +\n  theme_minimal() +\n  labs(\n    title = \"Base Map of India: in full detail\",\n    subtitle = \"Source: Census of India\"\n  )\n\nggsave(\n  filename = here::here(\"book_solutions\", \"images\",\n                        \"ch5-2-1_1.png\"),\n  plot = g,\n  height = 1600,\n  width = 1200,\n  units = \"px\"\n)\n\n#### st_simplify()\ng &lt;- india_states |&gt; \n  st_simplify(dTolerance = 100000) |&gt;    # 100 km tolerance\n  ggplot() +\n  geom_sf() +\n  theme_minimal() +\n  labs(\n    title = \"India: st_simplify(dTolerance = 100000)\",\n    subtitle = \"Douglas-Peucker algorithm. Topology is lost.\"\n  )\n\nggsave(\n  filename = here::here(\"book_solutions\", \"images\",\n                        \"ch5-2-1_2.png\"),\n  plot = g,\n  height = 1600,\n  width = 1200,\n  units = \"px\"\n)\n\n#### rmapshaper::ms_simplify()\ng &lt;- india_states |&gt; \n  rmapshaper::ms_simplify(keep = 0.0001, keep_shapes = TRUE) |&gt;    \n  ggplot() +\n  geom_sf() +\n  theme_minimal() +\n  labs(\n    title = \"India: rmapshaper::ms_simplify(keep_shapes = TRUE)\",\n    subtitle = \"Visvalingam algorithm. Topology is retained.\"\n  )\n\nggsave(\n  filename = here::here(\"book_solutions\", \"images\",\n                        \"ch5-2-1_3.png\"),\n  plot = g,\n  height = 1600,\n  width = 1200,\n  units = \"px\"\n)\n\n#### smoothr::smooth() - 3 methods\ng &lt;- india_states |&gt; \n  st_simplify(dTolerance = 10000) |&gt;  # To save computing time\n  smoothr::smooth(method = \"ksmooth\",\n                  smoothness = 5) |&gt;    \n  ggplot() +\n  geom_sf() +\n  theme_minimal() +\n  labs(\n    title = \"smoothr::smooth(method = \\\"ksmooth\\\")\",\n    subtitle = \"Gaussian kernel regression. Topology is lost.\"\n  )\n\nggsave(\n  filename = here::here(\"book_solutions\", \"images\",\n                        \"ch5-2-1_4.png\"),\n  plot = g,\n  height = 1600,\n  width = 1200,\n  units = \"px\"\n)\n\ng &lt;- india_states |&gt; \n  st_simplify(dTolerance = 50000) |&gt;  # To save computing time\n  smoothr::smooth(method = \"chaikin\") |&gt;    \n  ggplot() +\n  geom_sf() +\n  theme_minimal() +\n  labs(\n    title = \"smoothr::smooth(method = \\\"chaikin\\\")\",\n    subtitle = \"Chaikin’s corner cutting algorithm. Topology is lost.\"\n  )\n\nggsave(\n  filename = here::here(\"book_solutions\", \"images\",\n                        \"ch5-2-1_5.png\"),\n  plot = g,\n  height = 1600,\n  width = 1200,\n  units = \"px\"\n)\n\ng &lt;- india_states |&gt; \n  st_simplify(dTolerance = 50000) |&gt;  # To save computing time\n  smoothr::smooth(method = \"spline\") |&gt;    \n  ggplot() +\n  geom_sf() +\n  theme_minimal() +\n  labs(\n    title = \"smoothr::smooth(method = \\\"spline\\\")\",\n    subtitle = \"Spline interpolation. Topology is lost.\"\n  )\n\nggsave(\n  filename = here::here(\"book_solutions\", \"images\",\n                        \"ch5-2-1_6.png\"),\n  plot = g,\n  height = 1600,\n  width = 1200,\n  units = \"px\"\n)\n\n\n\n\n\n\n\n\n\n\nOfficial Map of India (full details)\n\n\n\n\n\n\n\nUsing st_simplify(dTolerance = 100000), i.e. 100 km resolution\n\n\n\n\n\n\n\n\n\nUsing rmapshaper::ms_simplify(keep_shape = TRUE) to retain topology\n\n\n\n\n\n\n\nUsing gaussian kernel regression with smoothr::smooth(method = “ksmooth”)\n\n\n\n\n\n\n\n\n\nUsing Chalkin’s corner cutting algorithm with smoothr::smooth(method = “chalkin”)\n\n\n\n\n\n\n\nUsing spline interpolation with smoothr::smooth(method = “spline”)\n\n\n\n\n\n\nFigure 1\n\n\n\n\nsmoothr\nA short note on the {smoothr} package (Strimas-Mackey 2023), which uses three different types of algorithms:-.\n\n\n\n\n\n\nNote\n\n\n\n\n\nCode\nlibrary(sf)\nlibrary(smoothr)\nlibrary(tidyverse)\n\n# Smooth polygons using different methods\np_smooth_chaikin &lt;- smooth(jagged_polygons, method = \"chaikin\")\np_smooth_ksmooth &lt;- smooth(jagged_polygons, method = \"ksmooth\")\np_smooth_spline &lt;- smooth(jagged_polygons, method = \"spline\")\n\n# Combine data for plotting\nplot_data &lt;- bind_rows(\n  mutate(st_as_sf(p_smooth_chaikin), method = \"chaikin\"),\n  mutate(st_as_sf(p_smooth_ksmooth), method = \"ksmooth\"),\n  mutate(st_as_sf(p_smooth_spline), method = \"spline\"),\n  mutate(st_as_sf(jagged_polygons), method = \"original\")\n)\n\n# Assign colors to methods\nmethod_colors &lt;- c(\n  chaikin = \"#E41A1C\",\n  ksmooth = \"#4DAF4A\",\n  spline = \"#377EB8\"\n)\n\n# Convert geometry for plotting\nplot_data &lt;- plot_data |&gt; \n  mutate(geometry = st_sfc(geometry)) |&gt; \n  st_as_sf()\n\np2 &lt;- plot_data |&gt; \n  filter(method != \"original\")\n\np1 &lt;- plot_data |&gt; \n  filter(method == \"original\") |&gt; \n  select(-method)\n\n# Plot with ggplot2\ng &lt;- ggplot(data = p2) +\n  geom_sf(aes(geometry = geometry, \n              color = method),\n          size = 0.7,\n          linewidth = 0.5,\n          fill = \"transparent\") +\n  geom_sf(\n    data = p1,\n    fill = alpha(\"grey50\", 0.5),\n    colour = \"transparent\"\n  ) +\n  scale_color_manual(values = method_colors) +\n  facet_grid(id ~ method) +\n  guides(fill = \"none\") +\n  theme_void() +\n  theme(\n    legend.position = \"none\",\n    plot.title.position = \"plot\",\n    strip.text.y = element_blank()\n    ) +\n  labs(\n    title = \"Simplification with {smoothr}\",\n    colour = \"Method\"\n  )\n\nggsave(\n  filename = here::here(\"book_solutions\", \"images\",\n                        \"ch5-2-1_7.png\"),\n  plot = g,\n  height = 2000,\n  width = 1200,\n  units = \"px\"\n)\n\n\n\n\n\n\n\n\n5.2.2 Centroids\n\nIdentify the center of geographic objects, creating single-point representations of complex geometries using st_centroid()\nTypes of Centroids: (shown in Figure 2)\n\nGeographic Centroid (center of mass):\n\nBalances a spatial object (like balancing a plate).\nUseful for creating simple point representations or estimating distances between polygons.\nCalculated with st_centroid() from the sf package.\nLimitation: Centroids may fall outside the object (e.g., doughnut-shaped polygons).\n\nPoint on Surface:\n\nEnsures the point lies within the object boundaries.\nUseful for labeling irregular polygons, such as islands or multipolygon geometries.\nCalculated with st_point_on_surface().\n\n\nOther Centroid Types: Chebyshev center and visual center\n\n\n\nCode\nsysfonts::font_add_google(\"Saira Extra Condensed\", \"caption_font\")\nshowtext::showtext_auto()\n\nggplot2::theme_set(\n  theme_minimal(\n    base_size = 30,\n    base_family = \"caption_font\"\n  ) +\n    theme(\n      text = element_text(\n        lineheight = 0.3,\n        hjust = 0.5\n      ),\n      plot.title.position = \"plot\"\n    )\n)\n\n# Focussing on the Island Chains of India\nandaman &lt;- india_states |&gt; \n  filter(\n    State_Name == \"Andaman & Nicobar\"\n  )\n  \ng1 &lt;- ggplot(andaman) +\n  geom_sf() +\n  labs(\n    title = \"Base Map\",\n    subtitle = \"Andaman & Nicobar\\nIslands (India)\"\n  )\n\ng2 &lt;- ggplot() +\n  geom_sf(\n    data = andaman\n    ) +\n  geom_sf(\n    data = st_centroid(andaman),\n    colour = \"red\",\n    size = 4, \n    pch = 1,\n    stroke = 2\n  ) +\n  labs(\n    title = \"st_centroid()\",\n    subtitle = \"Andaman & Nicobar\\nIslands (India)\"\n  )\n\ng3 &lt;- ggplot() +\n  geom_sf(\n    data = andaman\n    ) +\n  geom_sf(\n    data = st_centroid(andaman, of_largest_polygon = TRUE),\n    colour = \"red\",\n    size = 4, \n    pch = 1,\n    stroke = 2,\n    fill = \"transparent\"\n  ) +\n  labs(\n    title = \"st_centroid\\n(of_largest_polygon = TRUE)\",\n    subtitle = \"Andaman & Nicobar\\nIslands (India)\"\n  )\n\ng4 &lt;- ggplot() +\n  geom_sf(\n    data = andaman\n    ) +\n  geom_sf(\n    data = st_point_on_surface(andaman),\n    colour = \"red\",\n    size = 4, \n    pch = 1,\n    stroke = 2,\n    fill = \"transparent\"\n  ) +\n  labs(\n    title = \"st_point_on_surface()\",\n    subtitle = \"Andaman & Nicobar\\nIslands (India)\"\n  )\n\nggsave(\n  filename = here::here(\"book_solutions\", \n                        \"images\", \n                        \"chapter5-2-2_1.png\"),\n  plot = patchwork::wrap_plots(g1, g2, g3, g4, nrow = 1),\n  height = 1900,\n  width = 2400,\n  units = \"px\"\n)\n\n\n\n\n\n\n\n\nFigure 2: Various centroids using st_centroid() and st_point_on_surface()\n\n\n\n\n\n5.2.3 Buffers\n\nBuffers are polygons representing areas within a specified distance from a geometric feature (point, line, or polygon).\nPurpose: Used for geographic data analysis (not just visualization). Examples:\n\nHow many points are within a given distance of a line?\nWhich demographic groups are within travel range of a new shop?\n\nst_buffer() from the sf package. Example Visualization is shown in Figure 3\n\nInput: Geometry and dist (distance in CRS units, e.g., meters).\nOutput: One buffer polygon per geometry feature.\n\nOther Key Arguments in st_buffer():\n\nnQuadSegs (GEOS engine):\n\nNumber of segments per quadrant (default: 30).\nAdjust: Decrease for memory concerns, or increase for high resolution output.\n\nmax_cells (S2 engine):\n\nHigher values create smoother buffers (slower computation).\n\nendCapStyle and joinStyle (GEOS engine):\n\nControl buffer edge appearance (useful for lines).\n\nsingleSide (GEOS engine):\n\nBuffer on one or both sides of the geometry.\n\n\n\n\n\nCode\na1 &lt;- andaman |&gt; \n  st_cast(\"POLYGON\")\n\na2 &lt;- st_buffer(a1, dist = 20000) |&gt; \n  mutate(id = as_factor(row_number()))\n\na3 &lt;- st_buffer(a1, dist = 20000, nQuadSegs = 0.5) |&gt; \n  mutate(id = as_factor(row_number()))\n\ng1 &lt;- ggplot() +\n  geom_sf(data = a1) +\n  labs(\n    title = \"Base Map with\\nst_cast(\\\"POLYGON\\\")\",\n    subtitle = \"Nicobar Islands\"\n  ) +\n  coord_sf(\n    ylim = c(6.5, 9.5),\n    default_crs = 4326\n  )\n\ng2 &lt;- ggplot() +\n  geom_sf(\n    data = a2,\n    mapping = aes(fill = id),\n    alpha = 0.2,\n    colour = \"transparent\"\n  ) +\n  geom_sf(\n    data = a1\n  ) +\n  labs(\n    title = \"With 20 km buffer\\n around each island\",\n    subtitle = \"Nicobar Islands; each\\nbuffer in separate colour\"\n  ) +\n  theme(legend.position = \"none\") +\n  coord_sf(\n    ylim = c(6.5, 9.5),\n    default_crs = 4326\n  )\n\n\ng3 &lt;- ggplot() +\n  geom_sf(\n    data = a3,\n    mapping = aes(fill = id),\n    alpha = 0.2,\n    colour = \"transparent\"\n  ) +\n  geom_sf(\n    data = a1\n  ) +\n  labs(\n    title = \"With 20 km buffer\\n around each island\",\n    subtitle = \"Nicobar Islands;\\narugment (nQuadSegs = 1)\"\n  ) +\n  theme(legend.position = \"none\") +\n  coord_sf(\n    ylim = c(6.5, 9.5),\n    default_crs = 4326\n  )\n\nggsave(\n  filename = here::here(\"book_solutions\", \n                        \"images\", \n                        \"chapter5-2-3_1.png\"),\n  plot = patchwork::wrap_plots(g1, g2, g3, nrow = 1),\n  height = 1200,\n  width = 2000,\n  units = \"px\"\n)\n\n\n\n\n\n\n\n\nFigure 3: Use of st_buffer()\n\n\n\n\n\n5.2.4 Affine Transformations\n\nDefinition: Transformations that preserve lines and parallelism but not necessarily angles or lengths.\nTypes of Affine Transformations:\n\nShifting (Translation): Moves every point by a constant distance.\n\nExample: Adding a vector to shift all y-coordinates north by 400 km distance while keeping x-coordinates unchanged using:\nn_shift &lt;- n1 |&gt; \n  add(c(0, 400000)) |&gt; \n  st_set_crs(st_crs(n1))\nNote: This converts the CRS of the new sfc object to NA and thus needs st_set_crs() to return it back to the original CRS.\n\nScaling: Enlarges or shrinks geometries.\n\nGlobal Scaling:\n\nMultiplies all coordinates relative to the origin, preserving topological relations.\n\nLocal Scaling:\n\nScales geometries around specific points (e.g., centroids).\nSteps:\n\nShift geometries so the centroid becomes (0,0).\nScale by a factor.\nShift back to original centroid coordinates.\n\nExample: Enlarge the geometries by a factor of 2.5.\nn1_scale &lt;- (n1 - n1_centroid) |&gt; \n  multiply_by(2.5) |&gt; \n  add(n1_centroid) |&gt; \n  st_set_crs(st_crs(n1))\n\n\nRotation: Rotates coordinates using a rotation matrix.\n\nRotation matrix: Define a function to create the rotation matrix and apply it to the geometry. R=[cosθ/sinθ​ − sinθ/cosθ​]\n\n\nReplacing Old Geometry: Use st_set_geometry() from the sf package to finally Replace original geometry with scaled versions (shifted, rotated or scaled)\nApplications:\n\nShifting: For label placement.\nScaling: In non-contiguous cartograms (see Section 9.6).\nRotation: Correcting distorted geometries during re-projection.\n\n\n\n\nCode\nsysfonts::font_add_google(\"Saira Extra Condensed\", \"caption_font\")\nshowtext::showtext_auto()\n\nggplot2::theme_set(\n  theme_minimal(\n    base_size = 30,\n    base_family = \"caption_font\"\n  ) +\n    theme(\n      text = element_text(\n        lineheight = 0.3,\n        hjust = 0.5\n      ),\n      plot.title.position = \"plot\",\n      plot.title = element_text(hjust = 1),\n      plot.subtitle = element_text(hjust = 1),\n      panel.grid = element_line(\n        linewidth = 0.2\n      )\n    )\n)\n\ndf1 &lt;- andaman |&gt; \n  st_cast(\"POLYGON\") |&gt; \n  mutate(id = row_number()) |&gt; \n  filter(id &lt; 10) |&gt; \n  mutate(\n    name = case_when(\n      id %in% c(4,8, 9, 7) ~ \"Nicobar Islands\",\n      .default = \"Andaman Islands\"\n    )\n  )\n\n\n# Pull out only sfc class (i.e. geometry for Andaman Islands)\na1 &lt;- df1 |&gt; \n  filter(name == \"Andaman Islands\") |&gt; \n  st_geometry()\n\n# Pull out only sfc class (i.e. geometry for Nicobar Islands)\nn1 &lt;- df1 |&gt; \n  filter(name == \"Nicobar Islands\") |&gt; \n  st_geometry()\n\n\ng1 &lt;- df1 |&gt; \n  ggplot(aes(fill = name)) +\n  geom_sf(colour = \"transparent\") +\n  geom_sf_text(aes(label = id)) +\n  coord_sf(\n    ylim = c(7, 13.5),\n    default_crs = 4326\n  ) +\n  labs(\n    title = \"Base Map\",\n    subtitle = \"10 Largest Islands amongst\\nAndamand and Nicobar Island chain\",\n    fill = NULL, x = NULL, y = NULL\n  ) +\n  scale_fill_manual(values = c(\"#89973DFF\", \"#E8B92FFF\")) +\n  theme(\n    legend.position = \"left\"\n  )\n\ng2 &lt;- ggplot() +\n  geom_sf(data = a1, fill = \"#89973DFF\", colour = \"transparent\") +\n  geom_sf(data = n1, fill = \"#E8B92FFF\", colour = \"transparent\") +\n  coord_sf(\n    ylim = c(7, 13.5),\n    default_crs = 4326\n  ) + \n  labs(\n    title = \"Plotting as separate\\nsfc objects\",\n    subtitle = \"10 Largest Islands\"\n  )\n\n#################### Shifting #########################\n\nn_shift &lt;- n1 |&gt; \n  add(c(0, 400000)) |&gt; \n  st_set_crs(st_crs(n1))\n\ng3 &lt;- ggplot() +\n  geom_sf(data = a1, fill = \"#89973DFF\", colour = \"transparent\") +\n  geom_sf(\n    data = n_shift, \n    fill = \"#E8B92FFF\", \n    colour = \"transparent\"\n    ) +\n  coord_sf(\n    ylim = c(7, 13.5),\n    default_crs = 4326\n  ) +\n  labs(\n    title = \"Shifting sfc objects\",\n    subtitle = \"Bring Nicobar Islands\\ncloser to the Andamans\"\n  )\n\n#################### Scaling ##########################\n\nn1_centroid &lt;- st_centroid(n1)\n\nn1_scale &lt;- (n1 - n1_centroid) |&gt; \n  multiply_by(2.5) |&gt; \n  add(n1_centroid) |&gt; \n  st_set_crs(st_crs(n1))\n\ng4 &lt;- ggplot() +\n  geom_sf(data = a1, fill = \"#89973DFF\", colour = \"transparent\") +\n  geom_sf(\n    data = n1_scale, \n    fill = \"#E8B92FFF\", \n    colour = \"transparent\"\n    ) +\n  coord_sf(\n    ylim = c(7, 13.5),\n    default_crs = 4326\n  ) + \n  labs(\n    title = \"Scaling sfc objects\",\n    subtitle = \"Enlarging Nicobar Islands\\nby 2.5 times.\"\n  )\n\n##################### Rotation ########################\nrotation = function(a){\n  r = a * pi / 180 #degrees to radians\n  matrix(c(cos(r), sin(r), -sin(r), cos(r)), nrow = 2, ncol = 2)\n} \n\nn1_rotate &lt;- (n1 - n1_centroid) |&gt; \n  multiply_by(rotation(90)) |&gt; \n  add(n1_centroid) |&gt; \n  st_set_crs(st_crs(n1))\n\n\ng5 &lt;- ggplot() +\n  geom_sf(data = a1, fill = \"#89973DFF\", colour = \"transparent\") +\n  geom_sf(\n    data = n1_rotate, \n    fill = \"#E8B92FFF\", \n    colour = \"transparent\"\n    ) +\n  coord_sf(\n    ylim = c(7, 13.5),\n    default_crs = 4326\n  ) + \n  labs(\n    title = \"Rotating sfc objects\",\n    subtitle = \"Rotating Nicobar Islands\\nclockwise by 90 degrees\"\n  )\n\ng &lt;- patchwork::wrap_plots(g1, g3, g4, g5) +\n  patchwork::plot_layout(widths = c(1,1,1,1,1), nrow = 1)\n\nggsave(\n  filename = here::here(\"book_solutions\", \n                        \"images\", \n                        \"chapter5-2-4_1.png\"),\n  plot = g,\n  height = 1200,\n  width = 2500,\n  units = \"px\"\n)\n\n\n\n\n\nData Viz demonstration\nHere’s a more visually appealing version of the same graphic, produced using complete code given on this page.\n\n\n\nThis plot demonstrates the application of spatial transformations on the Andaman and Nicobar Islands using the `sf` package in R. It showcases four techniques: base mapping, northward shifting, scaling (enlargement), and rotation (90° clockwise), highlighting their effects on spatial geometries. The `facet_wrap` function neatly organizes the transformations for comparison, while `geom_sf` and custom labels enhance the visualization.\n\n\n\n\n5.2.5 Clipping\n\nDefinition: A form of spatial subsetting that modifies the geometry column of affected features. Applies to lines, polygons, and their multi equivalents (not points).\nPurpose: Identifies or extracts areas of overlap or subsets of spatial features. Commonly used in geographic data analysis to focus on regions of interest.\nLogical Operations and Spatial Equivalents. Inspired by Figure 12.1 of R for Data Science (2e). Spatial equivalents to logical operators (e.g., AND, OR, NOT) allow flexible geometry subsetting (as shown in Figure 4)\n\nIntersection (AND): st_intersection()\nUnion (OR): st_union()\nDifference (NOT): st_difference()\nExclusive OR (XOR): st_sym_difference()\n\nApplications:\n\nIdentifying overlapping regions.\nCreating subsets of spatial data for specific analysis or visualization.\n\n\n\n\nCode\nsysfonts::font_add_google(\"Nova Mono\", \"body_font\")\nshowtext::showtext_auto()\n\ntheme_custom &lt;- function(...) {\n  ggthemes::theme_map(\n    base_size = 20,\n    base_family = \"body_font\"\n    ) +\n    labs(\n      x = NULL, y = NULL\n    ) +\n    theme(\n      plot.title = element_text(\n        hjust = 0.5,\n        lineheight = 0.3,\n        margin = margin(5,0,2,0, \"mm\")\n      ),\n      plot.margin = margin(0,0,0,0, \"mm\"),\n      ...\n    )\n}\n# Define the center points of the circles\nsf_circles &lt;- tibble(\n  x = c(0, 2, 4, 1, 3),\n  y = c(0, 0, 0, -1, -1),\n  colour_var = c(\"blue\", \"black\", \"red\", \"yellow\", \"green\"),\n  label_var = LETTERS[1:5]\n  ) |&gt; \n  # Convert the points to an sf object\n  st_as_sf(\n  coords = c(\"x\", \"y\"), \n  crs = NA\n  ) |&gt; \n  # Create circular geometries using st_buffer\n  mutate(geometry = st_buffer(geometry, dist = 1))\n\ng1 &lt;- sf_circles |&gt; \n  ggplot(\n    mapping = aes(\n      label = label_var\n      )\n    ) +\n  geom_sf(\n    fill = \"transparent\",\n    linewidth = 0.5,\n    colour = \"grey10\"\n  ) +\n  geom_sf_text(\n    colour = \"grey10\",\n    fontface = \"bold\",\n    size = 16,\n    family = \"body_font\"\n  ) +\n  labs(\n    title = \"5 overlapping circles plotted with {sf}\"\n  ) + \n  theme_custom()\n\n# Naming the individual circles\n\npull_a_circle &lt;- function(ch_pick){\n  sf_circles |&gt; \n    filter(label_var == ch_pick)\n}\na1 &lt;- pull_a_circle(\"A\")  \nb1 &lt;- pull_a_circle(\"B\")  \nc1 &lt;- pull_a_circle(\"C\")  \nd1 &lt;- pull_a_circle(\"D\")  \ne1 &lt;- pull_a_circle(\"E\")  \n\ng2 &lt;- g1 +\n  geom_sf(\n    data = a1 |&gt; st_difference(d1),\n    fill = alpha(\"grey\", 0.7)\n  ) +\n  ggtitle(\"A |&gt; st_difference(D)\")\n\ng3 &lt;- g1 +\n  geom_sf(\n    data = d1 |&gt; st_difference(a1),\n    fill = alpha(\"grey\", 0.7)\n  ) +\n  ggtitle(\"D |&gt; st_difference(A)\")\n\ng4 &lt;- g1 +\n  geom_sf(\n    data = d1 |&gt; st_difference(a1) |&gt; st_difference(b1),\n    fill = alpha(\"grey\", 0.7)\n  ) +\n  ggtitle(\"D |&gt; st_difference(A) |&gt;\\nst_difference(B)\")\n\ng5 &lt;- g1 +\n  geom_sf(\n    data = a1 |&gt; st_union(d1),\n    fill = alpha(\"grey\", 0.7)\n  ) +\n  ggtitle(\"st_union(A, D)\")\n\ng6 &lt;- g1 +\n  geom_sf(\n    data = a1 |&gt; st_intersection(d1),\n    fill = alpha(\"grey\", 0.7)\n  ) +\n  ggtitle(\"st_intersection(A, D)\")\n\ng7 &lt;- g1 +\n  geom_sf(\n    data = st_sym_difference(a1, d1),\n    fill = alpha(\"grey\", 0.7)\n  ) +\n  ggtitle(\"st_sym_difference(A, D)\")\n\nnon_overlap &lt;- a1 |&gt; \n            st_sym_difference(d1) |&gt; \n            st_sym_difference(b1) |&gt; \n            st_sym_difference(c1) |&gt; \n            st_sym_difference(e1)\ng8 &lt;- g1 +\n  geom_sf(\n    data = non_overlap,\n    fill = alpha(\"grey\", 0.7)\n  ) +\n  labs(title = \"An st_sym_difference() chain\")\n\noverlap &lt;- a1 |&gt; \n  st_intersection(d1) |&gt; \n  st_union(st_intersection(d1, b1)) |&gt; \n  st_union(st_intersection(b1, e1)) |&gt; \n  st_union(st_intersection(e1, c1))\n\ng9 &lt;- g1 +\n  geom_sf(\n    data = overlap,\n    fill = alpha(\"grey\", 0.7)\n  ) +\n  labs(title = \"A st_union() and\\nst_interaction() chain\")\n\ncustom_layout_design &lt;- \"\n  AAAAAA\n  AAAAAA\n  BBCCDD\n  BBCCDD\n  EEFFGG\n  EEFFGG\n  HHHIII\n  HHHIII\n\"\n\ng &lt;- patchwork::wrap_plots(\n  g1, g2, g3, g4, g5, g6, g7, g8, g9\n  ) + \n  patchwork::plot_layout(\n    design = custom_layout_design\n  ) +\n  patchwork::plot_annotation(\n    title = \"Clipping {sf} objects\\n(Boolean Algebra examples)\",\n    subtitle = \"Using functions like st_intersection(), st_union(), st_difference()\\n& st_sym_difference()\",\n    theme = theme(\n      plot.title = element_text(\n        family = \"body_font\",\n        size = 54, \n        lineheight = 0.3,\n        hjust = 0.5,\n        face = \"bold\"\n      ),\n      plot.subtitle = element_text(\n        family = \"body_font\",\n        size = 30, \n        lineheight = 0.3,\n        hjust = 0.5\n      )\n    )\n  )\n\n\nggsave(\n  filename = here::here(\"book_solutions\", \n                        \"images\", \n                        \"chapter5-2-5_1.png\"),\n  plot = g,\n  height = 2000,\n  width = 1600,\n  units = \"px\",\n  bg = \"white\"\n)\n\n\n\n\n\n\n\n\nFigure 4: Various methods and examples (inspired by Boolean Algebra) for clipping {sf} objects in R\n\n\n\n\n\n5.2.6 Sub-setting and Clipping\n\nClipping: Modifies geometry to match a subsetting object. Subsetting: Selects features that intersect or partly intersect with a clipping object. An example: Points randomly distributed within the bounding box of the five concentric circles. Some points are inside one circle, some inside two circles, or neither. Then, we subset points intersecting with one, two or no circles.\nKey Functions:\n\nst_sample(): Generates random points within a geometry.\nClipping and Subsetting Approaches:\n\nWay #1: Use the intersection of x and y (x_and_y) as a direct subsetting object: p[x_and_y]\nWay #2: Find the intersection between points (p) and x_and_y, modifying overlapping geometries: st_intersection(p, x_and_y) , or, using st_interesects() when working in a pipe (|&gt;) chain.\nWay #3: Use st_intersects() to determine logical overlap between p and the subsetting objects: sel_p_xy = st_intersects(p, x, sparse = FALSE)[, 1] & st_intersects(p, y, sparse = FALSE)[, 1] and then subset, using p_xy3 = p[sel_p_xy]\n\n\nPreferred Implementation:\n\nWay #2 (concise and efficient) and it is the tidyverse approach with |&gt; compatibility. Example shown in Figure 5\n\n\n\n\nCode\nsysfonts::font_add_google(\"Fira Sans Condensed\", \"body_font\")\nshowtext::showtext_auto()\n\ntheme_custom &lt;- function(...) {\n  ggthemes::theme_map(\n    base_size = 20,\n    base_family = \"body_font\"\n    ) +\n    labs(\n      x = NULL, y = NULL\n    ) +\n    theme(\n      plot.title = element_text(\n        hjust = 0.5,\n        lineheight = 0.3,\n        margin = margin(5,0,2,0, \"mm\")\n      ),\n      plot.margin = margin(0,0,0,0, \"mm\"),\n      ...\n    )\n}\n# Define the center points of the circles\nsf_circles &lt;- tibble(\n  x = c(0, 2, 4, 1, 3),\n  y = c(0, 0, 0, -1, -1),\n  colour_var = c(\"blue\", \"black\", \"red\", \"yellow\", \"green\"),\n  label_var = LETTERS[1:5]\n  ) |&gt; \n  # Convert the points to an sf object\n  st_as_sf(\n  coords = c(\"x\", \"y\"), \n  crs = NA\n  ) |&gt; \n  # Create circular geometries using st_buffer\n  mutate(geometry = st_buffer(geometry, dist = 1))\n\n# Naming the individual circles\npull_a_circle &lt;- function(ch_pick){\n  sf_circles |&gt; \n    filter(label_var == ch_pick)\n}\na1 &lt;- pull_a_circle(\"A\")  \nb1 &lt;- pull_a_circle(\"B\")  \nc1 &lt;- pull_a_circle(\"C\")  \nd1 &lt;- pull_a_circle(\"D\")  \ne1 &lt;- pull_a_circle(\"E\")  \n\none_circle &lt;- a1 |&gt; \n            st_sym_difference(d1) |&gt; \n            st_sym_difference(b1) |&gt; \n            st_sym_difference(c1) |&gt; \n            st_sym_difference(e1)\noverlap &lt;- a1 |&gt; \n  st_intersection(d1) |&gt; \n  st_union(st_intersection(d1, b1)) |&gt; \n  st_union(st_intersection(b1, e1)) |&gt; \n  st_union(st_intersection(e1, c1))\nrm(a1, b1, c1, d1, e1)\n\nset.seed(42)\n\nrandom_points &lt;- sf_circles |&gt; \n  # Get a bounding box\n  st_bbox() |&gt; \n  # Covert it into a polygon\n  st_as_sfc() |&gt; \n  \n  # Get a sample of points within this polygon\n  st_sample(size = 100) |&gt; \n  \n  # Convert into a sf object\n  st_as_sf() |&gt; \n  \n  # Add identifiers for where the points fall\n  mutate(\n    colour_var = case_when(\n      st_intersects(x, overlap, sparse = F) ~ \"Two Circles\",\n      st_intersects(x, one_circle, sparse = F) ~ \"One Circle\",\n      .default = \"Outside\"\n    ),\n    colour_var = fct(\n      colour_var,\n      levels = c(\n        \"Outside\",\n        \"One Circle\",\n        \"Two Circles\"\n      )\n    )\n  )\n\ng &lt;- ggplot() +\n  geom_sf(\n    data = sf_circles, \n    fill = \"transparent\",\n    linewidth = 0.2,\n    colour = \"grey10\"\n    ) +\n  geom_sf(\n    data = random_points,\n    mapping = aes(\n      geometry = x,\n      colour = colour_var\n    ),\n    alpha = 0.75,\n    size = 0.7,\n    stroke = 0.1\n  ) +\n  labs(\n    title = \"Clipping and Subsetting\",\n    subtitle = \"Subsetting random points into those that overlap none, one or two circles\",\n    colour = \"Point lies within\"\n  ) +\n  paletteer::scale_colour_paletteer_d(\"khroma::highcontrast\") +\n  ggthemes::theme_map(\n    base_family = \"body_font\",\n    base_size = 16\n  ) +\n  theme(\n    plot.title = element_text(\n      size = 24,\n      hjust = 0.5,\n      margin = margin(0,0,0,0, \"mm\")\n    ),\n    plot.subtitle = element_text(\n      hjust = 0.5,\n      lineheight = 0.3,\n      margin = margin(0,0,0,0, \"mm\")\n    ),\n    legend.position = \"inside\",\n    legend.position.inside = c(0.5, 0),\n    legend.justification = c(0.5, 1),\n    legend.direction = \"horizontal\",\n    legend.text = element_text(\n      margin = margin(0,0,0,0, \"mm\")\n    ),\n    legend.title = element_text(\n      margin = margin(0,0,0,0, \"mm\"),\n      hjust = 0.5\n    ),\n    legend.margin = margin(0,0,0,0, \"mm\"),\n    legend.key.size = unit(5, \"pt\"),\n    legend.title.position = \"top\"\n  )\n\nggsave(\n  filename = here::here(\"book_solutions\", \n                        \"images\", \n                        \"chapter5-2-6_1.png\"),\n  plot = g,\n  height = 500,\n  width = 800,\n  units = \"px\",\n  bg = \"white\"\n)\n\n\n\n\n\n\n\n\nFigure 5: Sub-setting points with clipped {sf} objects - an example"
  }
]